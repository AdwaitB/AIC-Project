{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Data Reading \n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Data Processing \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import albumentations as A\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Modeling & Model Evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, recall_score, accuracy_score, precision_score, f1_score\n",
    "\n",
    "# Grad-CAM\n",
    "\n",
    "import keras\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Total Samples: 13808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_file</th>\n",
       "      <th>corona_result</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal/Normal-6196.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>./COVID-19_Radiography_Dataset/Normal/Normal-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal/Normal-7288.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>./COVID-19_Radiography_Dataset/Normal/Normal-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal/Normal-1821.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>./COVID-19_Radiography_Dataset/Normal/Normal-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal/Normal-4781.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>./COVID-19_Radiography_Dataset/Normal/Normal-4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal/Normal-4959.png</td>\n",
       "      <td>Negative</td>\n",
       "      <td>./COVID-19_Radiography_Dataset/Normal/Normal-4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_file corona_result  \\\n",
       "0  Normal/Normal-6196.png      Negative   \n",
       "1  Normal/Normal-7288.png      Negative   \n",
       "2  Normal/Normal-1821.png      Negative   \n",
       "3  Normal/Normal-4781.png      Negative   \n",
       "4  Normal/Normal-4959.png      Negative   \n",
       "\n",
       "                                                path  \n",
       "0  ./COVID-19_Radiography_Dataset/Normal/Normal-6...  \n",
       "1  ./COVID-19_Radiography_Dataset/Normal/Normal-7...  \n",
       "2  ./COVID-19_Radiography_Dataset/Normal/Normal-1...  \n",
       "3  ./COVID-19_Radiography_Dataset/Normal/Normal-4...  \n",
       "4  ./COVID-19_Radiography_Dataset/Normal/Normal-4...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = ['Normal', 'COVID']\n",
    "path = \"./COVID-19_Radiography_Dataset\"\n",
    "data_dir = os.path.join(path)\n",
    "\n",
    "data = []\n",
    "for id, level in enumerate(levels):\n",
    "    for file in os.listdir(os.path.join(data_dir, level)):\n",
    "        data.append(['{}/{}'.format(level, file), level])\n",
    "\n",
    "data = pd.DataFrame(data, columns = ['image_file', 'corona_result'])\n",
    "\n",
    "data['path'] = path + '/' + data['image_file']\n",
    "data['corona_result'] = data['corona_result'].map({'Normal': 'Negative', 'COVID': 'Positive'})\n",
    "samples = 13808\n",
    "\n",
    "\n",
    "print('Number of Total Samples: %d'%(data.isnull().value_counts()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "# Storing images and their labels into a list for further Train Test split\n",
    "\n",
    "for i in range(len(data)):\n",
    "    image = cv2.imread(data['path'][i])\n",
    "    image = cv2.resize(image, (70, 70)) / 255.0\n",
    "    label = 1 if data['corona_result'][i] == \"Positive\" else 0\n",
    "    all_data.append([image, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   image  label\n",
      "3475   [[[0.6588235294117647, 0.6588235294117647, 0.6...      0\n",
      "1714   [[[0.00392156862745098, 0.00392156862745098, 0...      0\n",
      "5351   [[[0.050980392156862744, 0.050980392156862744,...      0\n",
      "2591   [[[0.0, 0.0, 0.0], [0.07058823529411765, 0.070...      0\n",
      "12585  [[[0.2, 0.2, 0.2], [0.09803921568627451, 0.098...      1\n",
      "...                                                  ...    ...\n",
      "13632  [[[0.00392156862745098, 0.00392156862745098, 0...      1\n",
      "779    [[[0.6823529411764706, 0.6823529411764706, 0.6...      0\n",
      "10131  [[[0.00392156862745098, 0.00392156862745098, 0...      0\n",
      "3807   [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...      0\n",
      "2639   [[[0.011764705882352941, 0.011764705882352941,...      0\n",
      "\n",
      "[2762 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.DataFrame(all_data, columns=['image','label'])\n",
    "master = all_data.sample(frac=0.2)\n",
    "node1 = all_data.sample(frac=0.2)\n",
    "node2 = all_data.sample(frac=0.2)\n",
    "node3 = all_data.sample(frac=0.2)\n",
    "val = all_data.sample(frac=0.3) #evaluation data\n",
    "print(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valx = val['image']\n",
    "valy = val['label']\n",
    "valx = np.array(valx)\n",
    "valy = np.array(valy)\n",
    "valx = np.stack(valx,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data): #return cnn model\n",
    "    x = data['image']\n",
    "    y = data['label'] \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    x = np.stack(x,axis=0)\n",
    "    cnn_model = models.Sequential()\n",
    "    cnn_model.add(layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (70, 70, 3)))\n",
    "    cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "    cnn_model.add(layers.Dropout(0.3))\n",
    "\n",
    "    cnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "    cnn_model.add(layers.Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    cnn_model.add(layers.Flatten())\n",
    "    cnn_model.add(layers.Dense(units = 16, activation = 'relu'))\n",
    "    cnn_model.add(layers.Dropout(0.2))\n",
    "\n",
    "    cnn_model.add(layers.Dense(units = 2))\n",
    "\n",
    "    cnn_model.compile(optimizer = 'adam', \n",
    "               loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "               metrics = ['accuracy'])\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n",
    "\n",
    "    #tf.random.set_seed(42)\n",
    "    history = cnn_model.fit(x, y, \n",
    "                            epochs = 3, batch_size = 256,  \n",
    "                            validation_data = (valx, valy), \n",
    "                            callbacks = [es])\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_weight_ensemble(members, weights):\n",
    "    # determine how many layers need to be averaged\n",
    "    n_layers = len(members[0].get_weights())\n",
    "    # create an set of average model weights\n",
    "    avg_model_weights = list()\n",
    "    for layer in range(n_layers):\n",
    "        # collect this layer from each model\n",
    "        layer_weights = np.array([model.get_weights()[layer] for model in members])\n",
    "        # weighted average of weights for this layer\n",
    "        avg_layer_weights = np.average(layer_weights, axis=0, weights=weights)\n",
    "        # store average layer weights\n",
    "        avg_model_weights.append(avg_layer_weights)\n",
    "\n",
    "    model = keras.models.clone_model(members[0])\n",
    "    # set the weights in the new\n",
    "    model.set_weights(avg_model_weights)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "11/11 [==============================] - 74s 6s/step - loss: 0.7923 - accuracy: 0.7357 - val_loss: 0.5896 - val_accuracy: 0.7356\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 68s 6s/step - loss: 0.6073 - accuracy: 0.7382 - val_loss: 0.6237 - val_accuracy: 0.7356\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 63s 6s/step - loss: 0.5931 - accuracy: 0.7382 - val_loss: 0.6024 - val_accuracy: 0.7356\n"
     ]
    }
   ],
   "source": [
    "master_model = get_model(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "11/11 [==============================] - 65s 6s/step - loss: 0.6436 - accuracy: 0.6995 - val_loss: 0.6079 - val_accuracy: 0.7356\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 64s 6s/step - loss: 0.5925 - accuracy: 0.7346 - val_loss: 0.5895 - val_accuracy: 0.7356\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 60s 6s/step - loss: 0.5888 - accuracy: 0.7346 - val_loss: 0.5890 - val_accuracy: 0.7356\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 68, 68, 128)       3584      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 34, 34, 128)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 34, 34, 128)       0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                200720    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 315,058\n",
      "Trainable params: 315,058\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Accuracy on Val Data:  0.7356\n"
     ]
    }
   ],
   "source": [
    "members1 = list()\n",
    "members1.append(master_model)\n",
    "node1_model = get_model(node1)\n",
    "members1.append(node1_model)\n",
    "n_models = len(members1)\n",
    "weights = [1/n_models for i in range(1, n_models+1)]\n",
    "# create a new model with the weighted average of all model weights\n",
    "merge_model1 = model_weight_ensemble(members1, weights)\n",
    "# summarize the created model\n",
    "merge_model1.summary()\n",
    "yp_val = merge_model1.predict(valx)\n",
    "yp_val = np.argmax(yp_val, axis = 1)\n",
    "print(\"Accuracy on Val Data: \", round(accuracy_score(valy, yp_val),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "11/11 [==============================] - 63s 6s/step - loss: 0.6267 - accuracy: 0.7024 - val_loss: 0.5964 - val_accuracy: 0.7356\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 60s 6s/step - loss: 0.5757 - accuracy: 0.7404 - val_loss: 0.5705 - val_accuracy: 0.7356\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 74s 7s/step - loss: 0.5483 - accuracy: 0.7404 - val_loss: 0.5589 - val_accuracy: 0.7356\n",
      "Accuracy on Val Data:  0.7356\n"
     ]
    }
   ],
   "source": [
    "members2=list()\n",
    "members2.append(master_model)\n",
    "node2_model = get_model(node2)\n",
    "members2.append(node2_model) #append master and node2\n",
    "n_models = len(members2)\n",
    "weights = [1/n_models for i in range(1, n_models+1)]\n",
    "merge_model2 = model_weight_ensemble(members2, weights)\n",
    "yp_val = merge_model2.predict(valx)\n",
    "yp_val = np.argmax(yp_val, axis = 1)\n",
    "print(\"Accuracy on Val Data: \", round(accuracy_score(valy, yp_val),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "11/11 [==============================] - 837s 6s/step - loss: 0.6584 - accuracy: 0.7205 - val_loss: 0.6191 - val_accuracy: 0.7356\n",
      "Epoch 2/3\n",
      "11/11 [==============================] - 69s 6s/step - loss: 0.5805 - accuracy: 0.7466 - val_loss: 0.5956 - val_accuracy: 0.7356\n",
      "Epoch 3/3\n",
      "11/11 [==============================] - 93s 9s/step - loss: 0.5584 - accuracy: 0.7466 - val_loss: 0.5508 - val_accuracy: 0.7356\n",
      "Accuracy on Val Data:  0.7356\n"
     ]
    }
   ],
   "source": [
    "members3=list()\n",
    "members3.append(master_model)\n",
    "node3_model = get_model(node3)\n",
    "members3.append(node3_model) #append master and node3\n",
    "n_models = len(members3)\n",
    "weights = [1/n_models for i in range(1, n_models+1)]\n",
    "merge_model3 = model_weight_ensemble(members3, weights)\n",
    "yp_val = merge_model3.predict(valx)\n",
    "yp_val = np.argmax(yp_val, axis = 1)\n",
    "print(\"Accuracy on Val Data: \", round(accuracy_score(valy, yp_val),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Val Data:  0.7356\n"
     ]
    }
   ],
   "source": [
    "members_final=list() #Master merge\n",
    "members_final.append(merge_model1)\n",
    "members_final.append(merge_model2) \n",
    "members_final.append(merge_model3) \n",
    "n_models = len(members_final)\n",
    "weights = [1/n_models for i in range(1, n_models+1)]\n",
    "merge_mastermodel = model_weight_ensemble(members_final, weights)\n",
    "yp_val = merge_mastermodel.predict(valx)\n",
    "yp_val = np.argmax(yp_val, axis = 1)\n",
    "print(\"Accuracy on Val Data: \", round(accuracy_score(valy, yp_val),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
