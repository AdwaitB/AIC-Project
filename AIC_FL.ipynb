{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AdgWQiViX8Pr"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import os\n",
        "import random\n",
        "import math\n",
        "import random\n",
        "from itertools import product, chain\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import albumentations as A\n",
        "\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from keras.preprocessing import image\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from sklearn import preprocessing, metrics\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, make_scorer, precision_recall_curve, average_precision_score \n",
        "\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit, learning_curve, GridSearchCV, KFold, StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMeNRDa-Yjf6"
      },
      "source": [
        "# FL, Decentralized Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RTy4s1-jdu-n"
      },
      "outputs": [],
      "source": [
        "def create_data_chunks(data, no_chunks):\n",
        "    count_per_chunk = data.shape[0] // no_chunks\n",
        "    return [data[i:i+count_per_chunk] for i in range(0, data.shape[0], count_per_chunk)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RJ_U-z4phUhQ"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(x, y, z, title):\n",
        "    ax = sns.heatmap(\n",
        "        z, xticklabels=x, yticklabels=y, linewidth=0.5, \n",
        "        annot=True, cmap='YlGnBu', square=True\n",
        "    )\n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"No of clients per group\")\n",
        "    plt.ylabel(\"No of groups\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-adqJOI3N7Lr"
      },
      "outputs": [],
      "source": [
        "def plot_pair_metrics(n, x, y, title, y_axis):\n",
        "    df = pd.DataFrame({\n",
        "        'No of groups': x,\n",
        "        y_axis: y,\n",
        "        'Clients': n\n",
        "    })\n",
        "    if np.mean(y)<1:\n",
        "        ax = sns.lineplot(\n",
        "            data=df, x='No of groups', y=y_axis, hue='Clients', estimator=None, linewidth=4\n",
        "        ).set(title=title)\n",
        "    else:\n",
        "        y = np.where(y >=40, 41, y)\n",
        "        df = pd.DataFrame({\n",
        "        'No of groups': x,\n",
        "        y_axis: y,\n",
        "        'Clients': n\n",
        "        })\n",
        "        ax = sns.lineplot(\n",
        "            data=df, x='No of groups', y=y_axis, hue='Clients', estimator=None, linewidth=4\n",
        "        ).set(title=title)\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xticks(x)\n",
        "    plt.legend(loc='lower right', title='Total number of clients')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "uPVnANFGYmWn"
      },
      "outputs": [],
      "source": [
        "# Does a peer's learning work\n",
        "def model_learn(x, y, model, local_epochs, deep_copy_fn):\n",
        "    # print(f\"Peer: input: x={x.shape}, y={y.shape}\")\n",
        "    x_train, x_validate, y_train, y_validate = train_test_split(x, y, test_size=0.2)\n",
        "    # print(f\"Peer: splitting: x_train={x_train.shape}, y_train={y_train.shape}, x_validate={x_validate.shape}, y_validate={y_validate.shape}\")   \n",
        "    \n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n",
        "\n",
        "    model_copy = deep_copy_fn(model)\n",
        "\n",
        "    model_copy.fit(\n",
        "        x_train, y_train, epochs = local_epochs, batch_size = 16,  \n",
        "        validation_data = (x_validate, y_validate), callbacks = [es]\n",
        "    )\n",
        "    return model_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RkIQGaINCae5"
      },
      "outputs": [],
      "source": [
        "def pair_wise_post_process(acc, no_grps_list, total_clients, global_rounds, cutoffs):\n",
        "  accuracy_end = [max(acc[i]) for i in acc]\n",
        "  plot_pair_metrics([total_clients]*len(no_grps_list), no_grps_list, accuracy_end, f\"Accuracy after {global_rounds} rounds\", \"Accuracy\")\n",
        "  metrics_rounds_85 = np.zeros(len(no_grps_list))\n",
        "  metrics_rounds_75 = np.zeros(len(no_grps_list))\n",
        "  for j in cutoffs:\n",
        "      metrics_rounds_75 = np.zeros(len(no_grps_list))\n",
        "      for i in range(len(acc)):\n",
        "            if len(np.argwhere(np.array(acc[i])>=j)) > 0:\n",
        "              metrics_rounds_75[i] = np.argwhere(np.array(acc[i])>=j)[0][0]\n",
        "            else:\n",
        "              metrics_rounds_75[i] = 99\n",
        "      plot_pair_metrics([total_clients]*len(no_grps_list), no_grps_list, metrics_rounds_75, f\"Rounds to reach {j*100}% accuracy\", \"Rounds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mGmG5eqTcKp7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Ensemble the models from all peers\n",
        "def model_weight_ensemble(models, deep_copy_fn):\n",
        "    # determine how many layers need to be averaged\n",
        "    n_layers = len(models[0].get_weights())\n",
        "\n",
        "    # create an set of average model weights\n",
        "    avg_model_weights = list()\n",
        "    for layer in range(n_layers):\n",
        "        # collect this layer from each model\n",
        "        layer_weights = np.array([model.get_weights()[layer] for model in models])\n",
        "        # weighted average of weights for this layer\n",
        "        # avg_layer_weights = np.average(layer_weights, axis=0, weights=weights)\n",
        "        avg_layer_weights = np.average(layer_weights, axis=0)\n",
        "        # store average layer weights\n",
        "        avg_model_weights.append(avg_layer_weights)\n",
        "\n",
        "    model_copy = deep_copy_fn(models[0])\n",
        "    model_copy.set_weights(avg_model_weights)\n",
        "    return model_copy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "163RrLmSZGdH"
      },
      "outputs": [],
      "source": [
        "# Does a master's operation\n",
        "def master_work(x, y, model, no_peers, local_epochs, deep_copy_fn, sample_value = None):\n",
        "    # print(f\"master input = {len(x)}\")\n",
        "\n",
        "    x_chunks = create_data_chunks(x, no_peers)\n",
        "    y_chunks = create_data_chunks(y, no_peers)\n",
        "\n",
        "    client_models = []\n",
        "\n",
        "    if sample_value == None:\n",
        "        sample_value = no_peers\n",
        "    else:\n",
        "        sample_value = int(sample_value * no_peers)\n",
        "\n",
        "    sample_value = min(sample_value, 20)\n",
        "\n",
        "    peers_to_run = random.sample(range(no_peers), sample_value)\n",
        "    print(peers_to_run)\n",
        "\n",
        "    for i in peers_to_run:\n",
        "        print(f\"Masterwork: peer={i}\")\n",
        "        client_models.append(model_learn(x_chunks[i], y_chunks[i], deep_copy_fn(model), local_epochs, deep_copy_fn))\n",
        "\n",
        "    return model_weight_ensemble(client_models, deep_copy_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "amTGJAbNdFZG"
      },
      "outputs": [],
      "source": [
        "# The main publisher work\n",
        "def publisher(x, y, model, no_grps, peers_in_grp, global_rounds, local_epochs, deep_copy_fn, sample_value, random_state=1):\n",
        "    # print(f\"publisher input = {len(x)}\")\n",
        "    x_train, x_validate, y_train, y_validate = train_test_split(x, y, test_size=0.2, random_state=random_state) \n",
        "    # print(f\"Publisher: splitting: x_train={x_train.shape}, y_train={y_train.shape}, x_validate={x_validate.shape}, y_validate={y_validate.shape}\")   \n",
        "    x_groups = create_data_chunks(x_train, no_grps)\n",
        "    y_groups = create_data_chunks(y_train, no_grps)\n",
        "\n",
        "    # print(f\"Publisher: create groups: x_groups={len(x_groups)}, y_groups={len(y_groups)}\")\n",
        "    global_model = deep_copy_fn(model)\n",
        "    acc = []\n",
        "    for r in range(global_rounds):\n",
        "        print(f\"Publisher: global iteration={r}\")\n",
        "        master_models = []\n",
        "        for i in range(no_grps):\n",
        "            print(f\"Publisher: master={i}\")\n",
        "            # print(f\"Publisher: master={i}, x_groups[{i}]={x_groups[i].shape}, y_groups[{i}]={y_groups[i].shape}\")\n",
        "            master_models.append(\n",
        "                master_work(\n",
        "                    x_groups[i], y_groups[i], deep_copy_fn(global_model),\n",
        "                    peers_in_grp, local_epochs, deep_copy_fn, sample_value\n",
        "                )\n",
        "            )\n",
        "        global_model = model_weight_ensemble(master_models, deep_copy_fn)\n",
        "        y_validate_pred = global_model.predict(x_validate)\n",
        "        y_validate_pred = np.argmax(y_validate_pred, axis = 1)\n",
        "        acc.append(round(accuracy_score(y_validate_pred, y_validate), 4))\n",
        "\n",
        "    print(\"Publisher: finished all global\")\n",
        "    y_validate_pred = global_model.predict(x_validate)\n",
        "    y_validate_pred = np.argmax(y_validate_pred, axis = 1)\n",
        "\n",
        "    final_acc = round(accuracy_score(y_validate_pred, y_validate), 4)\n",
        "    print(\"Accuracy on Val Data: \", acc)\n",
        "\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9ZCo8ycrT1EV"
      },
      "outputs": [],
      "source": [
        "def get_metrics(acc, cutoffs):\n",
        "    x = 0\n",
        "    y = 0\n",
        "\n",
        "    for i, j in acc:\n",
        "        x = max(x, i)\n",
        "        y = max(y, j)\n",
        "    \n",
        "    final_acc = np.empty((x+1, y+1))\n",
        "    max_acc = np.empty((x+1, y+1))\n",
        "    cutoffs_reached = np.full((len(cutoffs), x+1, y+1), np.NaN)\n",
        "\n",
        "    for i, j in acc:\n",
        "        final_acc[i, j] = acc[i, j][-1]\n",
        "        max_acc[i, j] = max(acc[i, j])\n",
        "\n",
        "        for r in range(len(acc[i, j])):\n",
        "            for k in range(len(cutoffs)):\n",
        "                if np.isnan(cutoffs_reached[k][i, j]) and (acc[i, j][r] >= cutoffs[k]):\n",
        "                    cutoffs_reached[k][i, j] = int(r)\n",
        "    \n",
        "    return final_acc, max_acc, cutoffs_reached"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vCNuPLvbhdF6"
      },
      "outputs": [],
      "source": [
        " ## Run full XP\n",
        "def complete_xp(x, y, model, no_grps_list, peers_in_grp_list, global_rounds, local_epochs, deep_copy_fn, random_state=1, sample_value=None):\n",
        "    ret = {}\n",
        "\n",
        "    for i in range(len(peers_in_grp_list)):\n",
        "        for j in range(len(no_grps_list)):\n",
        "            print(\"------------------------------------------------------------------\")\n",
        "            print(f\"XP Parameters: peers in grp={peers_in_grp_list[i]}, no groups={no_grps_list[j]}\")\n",
        "            print(\"------------------------------------------------------------------\")\n",
        "            acc = publisher(\n",
        "                x, y, model, no_grps_list[j], peers_in_grp_list[i], \n",
        "                global_rounds, local_epochs, deep_copy_fn, sample_value,random_state\n",
        "            )\n",
        "            ret[i, j] = acc\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aM_L8TZwkR34"
      },
      "outputs": [],
      "source": [
        " ## Run pair_wise XP\n",
        "def pair_wise_xp(x, y, model, no_grps_list, total_clients, global_rounds, local_epochs, deep_copy_fn, random_state=1, sample_value=None):\n",
        "    ret = {}\n",
        "\n",
        "    for j in range(len(no_grps_list)):\n",
        "        number_of_peers_in_group = total_clients // no_grps_list[j]\n",
        "        print(\"------------------------------------------------------------------\")\n",
        "        print(f\"XP Parameters: peers in grp={number_of_peers_in_group}, no groups={no_grps_list[j]}\")\n",
        "        print(\"------------------------------------------------------------------\")\n",
        "        acc = publisher(\n",
        "            x, y, model, no_grps_list[j], number_of_peers_in_group, \n",
        "            global_rounds, local_epochs, deep_copy_fn, sample_value, random_state\n",
        "        )\n",
        "\n",
        "        ret[j] = acc\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3abGqtIXbM8b"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_curves(history, no_grps_list, total_clients):\n",
        "  rounds = [i+1 for i in range(len(list(history.values())[0]))]\n",
        "  idx = 0\n",
        "  fig, ax = plt.subplots(1,figsize=(10,5))\n",
        "  for combination in history:\n",
        "    ax.plot(rounds, history[combination], label = str(total_clients[idx]))\n",
        "    plt.xticks(rounds)\n",
        "    idx+=1\n",
        "  plt.legend(*[*zip(*{l:h for h,l in zip(*ax.get_legend_handles_labels())}.items())][::-1]).set_title(\"Total Peer Groups\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Global Rounds\")\n",
        "  plt.title(\"Accuracy Curve for \" + str(total_clients) + \" clients\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Hzqdbz7ffB4r"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_curves_cfl(history, total_clients):\n",
        "  rounds = [i+1 for i in range(len(list(history.values())[0]))]\n",
        "  idx = 0\n",
        "  fig, ax = plt.subplots(1,figsize=(10,5))\n",
        "  for combination in history:\n",
        "    ax.plot(rounds, history[combination], label = str(total_clients[idx]))\n",
        "    plt.xticks(rounds)\n",
        "    idx+=1\n",
        "  plt.legend(*[*zip(*{l:h for h,l in zip(*ax.get_legend_handles_labels())}.items())][::-1]).set_title(\"Clients\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Global Rounds\")\n",
        "  plt.title(\"Accuracy Curve for Centralized FL\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0ZmdBLwDso1S"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_curves_xp(history, no_grps_list, no_peers_list):\n",
        "  rounds = [i+1 for i in range(len(list(history.values())[0]))]\n",
        "  idx = 0\n",
        "  fig, ax = plt.subplots(1,figsize=(10,5))\n",
        "  for combination in history:\n",
        "    ax.plot(rounds, history[combination], label = str(no_grps_list[idx]) + \" groups, \" + str(no_peers_list[idx]) + \" peers/group \")\n",
        "    plt.xticks(rounds)\n",
        "    idx+=1\n",
        "  plt.legend(*[*zip(*{l:h for h,l in zip(*ax.get_legend_handles_labels())}.items())][::-1]).set_title(\"Peer and Groups\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.xlabel(\"Global Rounds\")\n",
        "  plt.title(\"Accuracy Curve\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPZRt8l8hqO0"
      },
      "source": [
        "# COVID Radiography Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhUS2Ie2htRq",
        "outputId": "edb68a03-23ef-4b0e-9366-5de8cdbf1ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7921.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7922.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7923.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7924.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7925.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7926.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7927.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7928.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7929.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-793.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7930.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7931.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7932.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7933.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7934.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7935.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7936.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7937.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7938.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7939.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-794.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7940.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7941.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7942.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7943.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7944.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7945.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7946.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7947.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7948.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7949.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-795.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7950.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7951.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7952.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7953.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7954.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7955.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7956.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7957.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7958.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7959.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-796.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7960.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7961.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7962.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7963.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7964.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7965.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7966.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7967.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7968.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7969.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-797.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7970.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7971.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7972.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7973.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7974.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7975.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7976.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7977.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7978.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7979.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-798.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7980.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7981.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7982.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7983.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7984.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7985.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7986.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7987.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7988.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7989.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-799.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7990.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7991.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7992.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7993.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7994.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7995.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7996.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7997.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7998.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-7999.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-80.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-800.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8000.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8001.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8002.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8003.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8004.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8005.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8006.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8007.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8008.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8009.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-801.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8010.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8011.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8012.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8013.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8014.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8015.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8016.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8017.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8018.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8019.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-802.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8020.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8021.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8022.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8023.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8024.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8025.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8026.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8027.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8028.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8029.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-803.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8030.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8031.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8032.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8033.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8034.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8035.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8036.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8037.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8038.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8039.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-804.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8040.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8041.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8042.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8043.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8044.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8045.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8046.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8047.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8048.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8049.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-805.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8050.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8051.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8052.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8053.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8054.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8055.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8056.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8057.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8058.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8059.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-806.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8060.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8061.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8062.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8063.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8064.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8065.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8066.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8067.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8068.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8069.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-807.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8070.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8071.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8072.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8073.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8074.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8075.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8076.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8077.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8078.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8079.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-808.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8080.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8081.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8082.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8083.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8084.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8085.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8086.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8087.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8088.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8089.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-809.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8090.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8091.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8092.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8093.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8094.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8095.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8096.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8097.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8098.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8099.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-81.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-810.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8100.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8101.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8102.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8103.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8104.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8105.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8106.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8107.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8108.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8109.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-811.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8110.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8111.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8112.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8113.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8114.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8115.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8116.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8117.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8118.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8119.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-812.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8120.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8121.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8122.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8123.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8124.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8125.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8126.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8127.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8128.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8129.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-813.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8130.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8131.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8132.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8133.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8134.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8135.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8136.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8137.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8138.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8139.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-814.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8140.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8141.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8142.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8143.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8144.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8145.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8146.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8147.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8148.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8149.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-815.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8150.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8151.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8152.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8153.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8154.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8155.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8156.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8157.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8158.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8159.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-816.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8160.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8161.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8162.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8163.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8164.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8165.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8166.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8167.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8168.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8169.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-817.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8170.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8171.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8172.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8173.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8174.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8175.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8176.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8177.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8178.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8179.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-818.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8180.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8181.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8182.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8183.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8184.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8185.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8186.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8187.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8188.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8189.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-819.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8190.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8191.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8192.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8193.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8194.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8195.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8196.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8197.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8198.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8199.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-82.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-820.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8200.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8201.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8202.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8203.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8204.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8205.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8206.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8207.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8208.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8209.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-821.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8210.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8211.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8212.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8213.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8214.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8215.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8216.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8217.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8218.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8219.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-822.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8220.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8221.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8222.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8223.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8224.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8225.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8226.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8227.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8228.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8229.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-823.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8230.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8231.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8232.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8233.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8234.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8235.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8236.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8237.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8238.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8239.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-824.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8240.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8241.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8242.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8243.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8244.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8245.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8246.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8247.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8248.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8249.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-825.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8250.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8251.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8252.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8253.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8254.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8255.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8256.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8257.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8258.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8259.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-826.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8260.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8261.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8262.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8263.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8264.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8265.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8266.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8267.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8268.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8269.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-827.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8270.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8271.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8272.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8273.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8274.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8275.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8276.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8277.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8278.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8279.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-828.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8280.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8281.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8282.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8283.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8284.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8285.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8286.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8287.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8288.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8289.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-829.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8290.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8291.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8292.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8293.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8294.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8295.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8296.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8297.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8298.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8299.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-83.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-830.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8300.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8301.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8302.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8303.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8304.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8305.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8306.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8307.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8308.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8309.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-831.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8310.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8311.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8312.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8313.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8314.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8315.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8316.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8317.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8318.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8319.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-832.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8320.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8321.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8322.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8323.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8324.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8325.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8326.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8327.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8328.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8329.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-833.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8330.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8331.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8332.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8333.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8334.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8335.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8336.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8337.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8338.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8339.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-834.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8340.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8341.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8342.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8343.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8344.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8345.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8346.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8347.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8348.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8349.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-835.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8350.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8351.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8352.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8353.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8354.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8355.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8356.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8357.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8358.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8359.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-836.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8360.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8361.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8362.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8363.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8364.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8365.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8366.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8367.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8368.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8369.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-837.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8370.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8371.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8372.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8373.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8374.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8375.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8376.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8377.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8378.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8379.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-838.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8380.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8381.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8382.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8383.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8384.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8385.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8386.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8387.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8388.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8389.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-839.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8390.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8391.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8392.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8393.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8394.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8395.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8396.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8397.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8398.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8399.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-84.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-840.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8400.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8401.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8402.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8403.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8404.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8405.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8406.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8407.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8408.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8409.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-841.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8410.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8411.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8412.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8413.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8414.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8415.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8416.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8417.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8418.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8419.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-842.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8420.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8421.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8422.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8423.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8424.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8425.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8426.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8427.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8428.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8429.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-843.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8430.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8431.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8432.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8433.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8434.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8435.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8436.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8437.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8438.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8439.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-844.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8440.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8441.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8442.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8443.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8444.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8445.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8446.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8447.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8448.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8449.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-845.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8450.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8451.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8452.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8453.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8454.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8455.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8456.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8457.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8458.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8459.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-846.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8460.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8461.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8462.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8463.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8464.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8465.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8466.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8467.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8468.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8469.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-847.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8470.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8471.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8472.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8473.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8474.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8475.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8476.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8477.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8478.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8479.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-848.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8480.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8481.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8482.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8483.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8484.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8485.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8486.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8487.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8488.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8489.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-849.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8490.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8491.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8492.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8493.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8494.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8495.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8496.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8497.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8498.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8499.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-85.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-850.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8500.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8501.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8502.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8503.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8504.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8505.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8506.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8507.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8508.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8509.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-851.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8510.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8511.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8512.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8513.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8514.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8515.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8516.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8517.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8518.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8519.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-852.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8520.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8521.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8522.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8523.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8524.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8525.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8526.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8527.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8528.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8529.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-853.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8530.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8531.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8532.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8533.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8534.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8535.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8536.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8537.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8538.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8539.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-854.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8540.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8541.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8542.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8543.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8544.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8545.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8546.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8547.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8548.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8549.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-855.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8550.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8551.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8552.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8553.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8554.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8555.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8556.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8557.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8558.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8559.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-856.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8560.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8561.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8562.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8563.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8564.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8565.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8566.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8567.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8568.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8569.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-857.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8570.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8571.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8572.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8573.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8574.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8575.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8576.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8577.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8578.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8579.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-858.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8580.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8581.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8582.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8583.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8584.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8585.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8586.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8587.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8588.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8589.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-859.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8590.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8591.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8592.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8593.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8594.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8595.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8596.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8597.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8598.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8599.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-86.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-860.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8600.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8601.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8602.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8603.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8604.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8605.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8606.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8607.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8608.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8609.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-861.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8610.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8611.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8612.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8613.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8614.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8615.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8616.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8617.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8618.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8619.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-862.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8620.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8621.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8622.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8623.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8624.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8625.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8626.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8627.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8628.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8629.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-863.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8630.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8631.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8632.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8633.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8634.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8635.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8636.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8637.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8638.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8639.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-864.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8640.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8641.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8642.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8643.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8644.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8645.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8646.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8647.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8648.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8649.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-865.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8650.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8651.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8652.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8653.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8654.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8655.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8656.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8657.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8658.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8659.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-866.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8660.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8661.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8662.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8663.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8664.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8665.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8666.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8667.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8668.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8669.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-867.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8670.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8671.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8672.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8673.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8674.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8675.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8676.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8677.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8678.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8679.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-868.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8680.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8681.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8682.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8683.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8684.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8685.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8686.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8687.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8688.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8689.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-869.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8690.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8691.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8692.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8693.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8694.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8695.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8696.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8697.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8698.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8699.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-87.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-870.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8700.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8701.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8702.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8703.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8704.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8705.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8706.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8707.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8708.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8709.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-871.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8710.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8711.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8712.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8713.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8714.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8715.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8716.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8717.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8718.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8719.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-872.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8720.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8721.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8722.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8723.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8724.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8725.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8726.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8727.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8728.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8729.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-873.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8730.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8731.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8732.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8733.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8734.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8735.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8736.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8737.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8738.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8739.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-874.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8740.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8741.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8742.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8743.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8744.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8745.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8746.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8747.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8748.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8749.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-875.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8750.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8751.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8752.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8753.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8754.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8755.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8756.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8757.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8758.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8759.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-876.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8760.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8761.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8762.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8763.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8764.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8765.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8766.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8767.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8768.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8769.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-877.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8770.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8771.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8772.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8773.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8774.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8775.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8776.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8777.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8778.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8779.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-878.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8780.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8781.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8782.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8783.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8784.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8785.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8786.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8787.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8788.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8789.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-879.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8790.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8791.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8792.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8793.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8794.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8795.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8796.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8797.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8798.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8799.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-88.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-880.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8800.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8801.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8802.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8803.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8804.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8805.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8806.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8807.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8808.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8809.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-881.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8810.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8811.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8812.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8813.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8814.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8815.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8816.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8817.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8818.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8819.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-882.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8820.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8821.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8822.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8823.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8824.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8825.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8826.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8827.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8828.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8829.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-883.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8830.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8831.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8832.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8833.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8834.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8835.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8836.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8837.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8838.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8839.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-884.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8840.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8841.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8842.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8843.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8844.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8845.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8846.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8847.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8848.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8849.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-885.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8850.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8851.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8852.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8853.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8854.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8855.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8856.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8857.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8858.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8859.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-886.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8860.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8861.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8862.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8863.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8864.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8865.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8866.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8867.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8868.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8869.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-887.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8870.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8871.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8872.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8873.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8874.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8875.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8876.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8877.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8878.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8879.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-888.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8880.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8881.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8882.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8883.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8884.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8885.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8886.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8887.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8888.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8889.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-889.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8890.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8891.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8892.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8893.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8894.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8895.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8896.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8897.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8898.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8899.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-89.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-890.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8900.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8901.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8902.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8903.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8904.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8905.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8906.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8907.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8908.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8909.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-891.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8910.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8911.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8912.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8913.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8914.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8915.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8916.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8917.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8918.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8919.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-892.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8920.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8921.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8922.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8923.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8924.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8925.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8926.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8927.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8928.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8929.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-893.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8930.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8931.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8932.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8933.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8934.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8935.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8936.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8937.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8938.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8939.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-894.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8940.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8941.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8942.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8943.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8944.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8945.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8946.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8947.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8948.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8949.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-895.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8950.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8951.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8952.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8953.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8954.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8955.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8956.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8957.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8958.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8959.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-896.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8960.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8961.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8962.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8963.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8964.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8965.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8966.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8967.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8968.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8969.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-897.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8970.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8971.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8972.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8973.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8974.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8975.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8976.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8977.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8978.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8979.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-898.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8980.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8981.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8982.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8983.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8984.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8985.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8986.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8987.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8988.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8989.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-899.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8990.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8991.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8992.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8993.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8994.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8995.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8996.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8997.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8998.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-8999.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-90.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-900.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9000.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9001.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9002.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9003.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9004.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9005.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9006.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9007.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9008.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9009.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-901.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9010.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9011.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9012.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9013.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9014.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9015.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9016.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9017.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9018.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9019.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-902.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9020.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9021.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9022.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9023.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9024.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9025.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9026.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9027.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9028.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9029.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-903.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9030.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9031.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9032.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9033.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9034.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9035.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9036.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9037.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9038.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9039.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-904.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9040.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9041.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9042.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9043.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9044.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9045.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9046.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9047.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9048.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9049.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-905.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9050.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9051.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9052.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9053.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9054.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9055.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9056.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9057.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9058.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9059.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-906.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9060.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9061.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9062.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9063.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9064.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9065.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9066.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9067.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9068.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9069.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-907.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9070.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9071.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9072.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9073.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9074.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9075.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9076.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9077.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9078.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9079.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-908.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9080.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9081.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9082.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9083.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9084.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9085.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9086.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9087.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9088.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9089.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-909.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9090.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9091.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9092.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9093.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9094.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9095.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9096.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9097.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9098.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9099.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-91.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-910.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9100.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9101.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9102.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9103.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9104.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9105.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9106.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9107.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9108.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9109.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-911.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9110.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9111.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9112.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9113.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9114.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9115.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9116.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9117.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9118.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9119.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-912.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9120.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9121.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9122.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9123.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9124.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9125.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9126.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9127.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9128.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9129.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-913.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9130.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9131.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9132.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9133.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9134.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9135.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9136.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9137.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9138.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9139.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-914.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9140.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9141.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9142.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9143.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9144.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9145.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9146.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9147.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9148.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9149.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-915.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9150.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9151.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9152.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9153.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9154.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9155.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9156.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9157.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9158.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9159.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-916.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9160.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9161.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9162.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9163.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9164.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9165.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9166.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9167.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9168.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9169.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-917.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9170.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9171.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9172.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9173.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9174.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9175.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9176.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9177.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9178.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9179.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-918.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9180.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9181.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9182.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9183.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9184.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9185.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9186.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9187.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9188.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9189.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-919.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9190.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9191.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9192.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9193.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9194.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9195.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9196.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9197.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9198.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9199.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-92.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-920.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9200.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9201.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9202.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9203.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9204.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9205.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9206.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9207.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9208.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9209.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-921.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9210.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9211.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9212.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9213.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9214.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9215.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9216.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9217.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9218.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9219.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-922.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9220.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9221.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9222.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9223.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9224.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9225.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9226.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9227.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9228.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9229.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-923.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9230.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9231.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9232.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9233.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9234.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9235.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9236.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9237.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9238.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9239.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-924.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9240.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9241.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9242.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9243.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9244.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9245.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9246.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9247.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9248.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9249.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-925.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9250.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9251.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9252.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9253.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9254.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9255.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9256.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9257.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9258.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9259.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-926.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9260.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9261.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9262.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9263.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9264.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9265.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9266.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9267.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9268.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9269.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-927.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9270.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9271.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9272.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9273.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9274.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9275.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9276.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9277.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9278.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9279.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-928.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9280.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9281.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9282.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9283.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9284.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9285.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9286.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9287.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9288.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9289.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-929.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9290.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9291.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9292.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9293.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9294.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9295.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9296.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9297.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9298.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9299.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-93.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-930.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9300.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9301.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9302.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9303.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9304.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9305.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9306.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9307.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9308.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9309.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-931.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9310.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9311.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9312.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9313.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9314.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9315.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9316.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9317.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9318.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9319.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-932.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9320.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9321.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9322.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9323.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9324.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9325.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9326.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9327.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9328.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9329.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-933.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9330.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9331.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9332.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9333.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9334.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9335.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9336.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9337.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9338.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9339.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-934.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9340.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9341.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9342.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9343.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9344.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9345.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9346.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9347.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9348.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9349.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-935.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9350.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9351.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9352.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9353.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9354.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9355.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9356.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9357.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9358.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9359.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-936.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9360.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9361.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9362.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9363.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9364.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9365.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9366.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9367.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9368.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9369.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-937.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9370.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9371.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9372.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9373.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9374.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9375.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9376.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9377.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9378.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9379.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-938.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9380.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9381.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9382.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9383.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9384.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9385.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9386.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9387.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9388.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9389.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-939.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9390.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9391.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9392.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9393.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9394.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9395.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9396.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9397.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9398.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9399.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-94.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-940.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9400.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9401.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9402.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9403.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9404.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9405.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9406.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9407.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9408.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9409.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-941.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9410.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9411.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9412.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9413.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9414.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9415.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9416.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9417.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9418.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9419.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-942.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9420.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9421.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9422.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9423.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9424.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9425.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9426.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9427.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9428.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9429.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-943.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9430.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9431.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9432.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9433.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9434.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9435.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9436.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9437.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9438.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9439.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-944.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9440.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9441.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9442.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9443.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9444.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9445.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9446.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9447.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9448.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9449.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-945.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9450.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9451.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9452.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9453.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9454.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9455.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9456.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9457.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9458.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9459.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-946.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9460.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9461.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9462.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9463.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9464.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9465.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9466.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9467.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9468.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9469.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-947.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9470.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9471.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9472.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9473.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9474.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9475.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9476.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9477.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9478.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9479.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-948.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9480.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9481.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9482.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9483.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9484.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9485.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9486.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9487.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9488.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9489.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-949.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9490.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9491.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9492.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9493.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9494.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9495.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9496.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9497.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9498.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9499.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-95.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-950.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9500.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9501.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9502.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9503.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9504.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9505.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9506.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9507.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9508.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9509.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-951.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9510.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9511.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9512.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9513.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9514.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9515.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9516.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9517.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9518.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9519.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-952.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9520.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9521.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9522.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9523.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9524.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9525.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9526.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9527.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9528.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9529.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-953.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9530.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9531.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9532.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9533.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9534.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9535.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9536.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9537.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9538.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9539.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-954.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9540.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9541.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9542.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9543.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9544.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9545.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9546.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9547.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9548.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9549.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-955.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9550.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9551.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9552.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9553.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9554.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9555.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9556.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9557.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9558.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9559.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-956.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9560.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9561.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9562.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9563.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9564.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9565.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9566.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9567.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9568.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9569.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-957.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9570.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9571.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9572.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9573.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9574.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9575.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9576.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9577.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9578.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9579.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-958.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9580.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9581.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9582.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9583.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9584.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9585.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9586.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9587.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9588.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9589.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-959.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9590.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9591.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9592.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9593.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9594.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9595.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9596.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9597.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9598.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9599.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-96.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-960.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9600.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9601.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9602.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9603.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9604.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9605.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9606.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9607.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9608.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9609.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-961.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9610.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9611.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9612.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9613.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9614.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9615.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9616.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9617.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9618.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9619.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-962.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9620.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9621.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9622.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9623.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9624.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9625.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9626.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9627.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9628.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9629.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-963.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9630.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9631.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9632.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9633.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9634.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9635.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9636.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9637.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9638.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9639.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-964.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9640.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9641.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9642.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9643.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9644.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9645.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9646.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9647.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9648.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9649.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-965.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9650.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9651.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9652.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9653.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9654.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9655.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9656.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9657.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9658.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9659.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-966.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9660.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9661.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9662.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9663.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9664.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9665.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9666.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9667.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9668.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9669.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-967.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9670.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9671.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9672.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9673.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9674.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9675.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9676.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9677.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9678.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9679.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-968.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9680.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9681.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9682.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9683.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9684.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9685.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9686.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9687.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9688.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9689.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-969.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9690.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9691.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9692.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9693.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9694.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9695.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9696.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9697.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9698.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9699.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-97.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-970.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9700.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9701.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9702.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9703.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9704.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9705.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9706.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9707.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9708.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9709.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-971.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9710.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9711.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9712.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9713.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9714.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9715.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9716.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9717.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9718.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9719.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-972.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9720.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9721.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9722.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9723.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9724.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9725.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9726.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9727.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9728.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9729.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-973.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9730.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9731.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9732.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9733.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9734.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9735.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9736.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9737.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9738.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9739.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-974.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9740.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9741.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9742.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9743.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9744.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9745.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9746.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9747.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9748.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9749.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-975.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9750.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9751.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9752.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9753.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9754.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9755.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9756.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9757.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9758.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9759.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-976.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9760.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9761.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9762.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9763.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9764.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9765.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9766.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9767.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9768.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9769.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-977.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9770.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9771.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9772.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9773.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9774.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9775.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9776.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9777.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9778.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9779.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-978.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9780.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9781.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9782.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9783.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9784.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9785.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9786.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9787.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9788.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9789.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-979.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9790.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9791.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9792.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9793.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9794.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9795.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9796.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9797.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9798.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9799.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-98.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-980.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9800.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9801.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9802.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9803.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9804.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9805.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9806.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9807.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9808.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9809.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-981.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9810.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9811.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9812.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9813.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9814.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9815.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9816.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9817.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9818.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9819.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-982.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9820.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9821.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9822.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9823.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9824.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9825.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9826.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9827.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9828.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9829.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-983.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9830.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9831.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9832.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9833.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9834.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9835.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9836.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9837.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9838.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9839.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-984.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9840.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9841.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9842.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9843.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9844.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9845.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9846.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9847.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9848.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9849.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-985.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9850.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9851.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9852.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9853.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9854.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9855.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9856.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9857.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9858.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9859.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-986.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9860.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9861.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9862.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9863.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9864.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9865.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9866.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9867.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9868.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9869.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-987.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9870.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9871.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9872.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9873.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9874.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9875.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9876.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9877.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9878.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9879.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-988.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9880.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9881.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9882.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9883.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9884.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9885.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9886.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9887.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9888.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9889.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-989.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9890.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9891.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9892.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9893.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9894.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9895.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9896.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9897.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9898.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9899.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-99.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-990.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9900.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9901.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9902.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9903.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9904.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9905.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9906.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9907.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9908.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9909.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-991.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9910.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9911.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9912.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9913.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9914.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9915.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9916.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9917.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9918.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9919.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-992.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9920.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9921.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9922.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9923.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9924.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9925.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9926.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9927.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9928.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9929.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-993.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9930.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9931.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9932.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9933.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9934.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9935.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9936.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9937.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9938.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9939.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-994.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9940.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9941.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9942.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9943.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9944.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9945.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9946.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9947.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9948.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9949.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-995.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9950.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9951.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9952.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9953.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9954.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9955.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9956.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9957.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9958.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9959.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-996.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9960.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9961.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9962.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9963.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9964.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9965.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9966.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9967.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9968.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9969.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-997.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9970.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9971.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9972.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9973.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9974.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9975.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9976.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9977.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9978.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9979.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-998.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9980.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9981.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9982.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9983.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9984.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9985.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9986.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9987.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9988.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9989.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-999.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9990.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9991.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9992.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9993.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9994.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9995.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9996.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9997.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9998.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Normal/masks/Normal-9999.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/README.md.txt  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia.metadata.xlsx  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-10.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-100.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1000.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1001.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1002.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1003.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1004.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1005.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1006.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1007.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1008.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1009.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-101.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1010.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1011.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1012.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1013.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1014.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1015.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1016.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1017.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1018.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1019.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-102.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1020.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1021.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1022.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1023.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1024.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1025.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1026.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1027.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1028.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1029.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-103.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1030.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1031.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1032.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1033.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1034.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1035.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1036.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1037.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1038.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1039.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-104.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1040.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1041.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1042.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1043.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1044.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1045.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1046.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1047.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1048.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1049.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-105.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1050.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1051.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1052.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1053.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1054.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1055.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1056.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1057.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1058.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1059.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-106.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1060.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1061.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1062.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1063.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1064.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1065.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1066.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1067.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1068.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1069.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-107.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1070.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1071.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1072.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1073.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1074.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1075.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1076.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1077.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1078.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1079.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-108.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1080.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1081.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1082.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1083.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1084.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1085.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1086.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1087.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1088.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1089.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-109.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1090.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1091.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1092.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1093.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1094.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1095.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1096.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1097.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1098.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1099.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-11.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-110.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1100.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1101.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1102.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1103.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1104.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1105.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1106.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1107.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1108.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1109.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-111.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1110.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1111.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1112.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1113.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1114.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1115.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1116.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1117.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1118.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1119.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-112.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1120.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1121.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1122.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1123.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1124.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1125.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1126.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1127.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1128.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1129.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-113.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1130.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1131.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1132.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1133.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1134.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1135.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1136.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1137.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1138.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1139.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-114.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1140.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1141.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1142.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1143.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1144.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1145.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1146.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1147.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1148.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1149.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-115.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1150.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1151.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1152.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1153.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1154.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1155.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1156.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1157.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1158.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1159.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-116.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1160.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1161.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1162.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1163.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1164.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1165.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1166.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1167.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1168.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1169.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-117.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1170.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1171.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1172.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1173.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1174.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1175.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1176.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1177.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1178.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1179.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-118.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1180.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1181.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1182.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1183.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1184.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1185.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1186.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1187.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1188.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1189.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-119.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1190.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1191.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1192.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1193.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1194.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1195.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1196.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1197.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1198.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1199.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-12.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-120.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1200.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1201.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1202.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1203.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1204.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1205.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1206.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1207.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1208.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1209.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-121.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1210.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1211.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1212.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1213.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1214.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1215.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1216.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1217.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1218.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1219.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-122.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1220.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1221.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1222.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1223.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1224.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1225.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1226.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1227.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1228.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1229.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-123.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1230.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1231.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1232.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1233.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1234.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1235.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1236.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1237.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1238.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1239.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-124.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1240.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1241.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1242.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1243.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1244.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1245.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1246.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1247.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1248.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1249.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-125.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1250.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1251.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1252.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1253.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1254.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1255.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1256.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1257.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1258.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1259.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-126.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1260.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1261.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1262.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1263.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1264.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1265.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1266.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1267.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1268.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1269.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-127.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1270.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1271.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1272.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1273.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1274.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1275.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1276.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1277.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1278.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1279.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-128.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1280.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1281.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1282.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1283.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1284.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1285.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1286.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1287.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1288.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1289.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-129.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1290.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1291.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1292.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1293.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1294.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1295.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1296.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1297.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1298.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1299.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-13.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-130.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1300.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1301.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1302.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1303.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1304.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1305.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1306.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1307.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1308.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1309.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-131.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1310.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1311.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1312.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1313.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1314.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1315.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1316.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1317.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1318.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1319.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-132.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1320.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1321.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1322.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1323.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1324.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1325.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1326.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1327.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1328.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1329.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-133.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1330.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1331.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1332.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1333.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1334.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1335.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1336.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1337.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1338.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1339.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-134.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1340.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1341.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1342.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1343.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1344.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-1345.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-135.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-136.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-137.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-138.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-139.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-14.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-140.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-141.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-142.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-143.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-144.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-145.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-146.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-147.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-148.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-149.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-15.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-150.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-151.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-152.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-153.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-154.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-155.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-156.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-157.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-158.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-159.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-16.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-160.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-161.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-162.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-163.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-164.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-165.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-166.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-167.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-168.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-169.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-17.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-170.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-171.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-172.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-173.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-174.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-175.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-176.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-177.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-178.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-179.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-18.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-180.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-181.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-182.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-183.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-184.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-185.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-186.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-187.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-188.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-189.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-19.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-190.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-191.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-192.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-193.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-194.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-195.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-196.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-197.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-198.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-199.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-2.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-20.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-200.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-201.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-202.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-203.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-204.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-205.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-206.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-207.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-208.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-209.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-21.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-210.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-211.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-212.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-213.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-214.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-215.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-216.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-217.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-218.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-219.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-22.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-220.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-221.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-222.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-223.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-224.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-225.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-226.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-227.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-228.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-229.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-23.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-230.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-231.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-232.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-233.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-234.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-235.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-236.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-237.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-238.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-239.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-24.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-240.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-241.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-242.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-243.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-244.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-245.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-246.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-247.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-248.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-249.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-25.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-250.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-251.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-252.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-253.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-254.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-255.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-256.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-257.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-258.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-259.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-26.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-260.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-261.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-262.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-263.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-264.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-265.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-266.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-267.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-268.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-269.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-27.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-270.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-271.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-272.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-273.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-274.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-275.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-276.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-277.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-278.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-279.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-28.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-280.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-281.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-282.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-283.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-284.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-285.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-286.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-287.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-288.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-289.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-29.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-290.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-291.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-292.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-293.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-294.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-295.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-296.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-297.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-298.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-299.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-3.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-30.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-300.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-301.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-302.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-303.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-304.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-305.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-306.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-307.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-308.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-309.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-31.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-310.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-311.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-312.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-313.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-314.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-315.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-316.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-317.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-318.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-319.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-32.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-320.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-321.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-322.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-323.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-324.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-325.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-326.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-327.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-328.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-329.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-33.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-330.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-331.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-332.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-333.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-334.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-335.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-336.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-337.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-338.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-339.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-34.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-340.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-341.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-342.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-343.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-344.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-345.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-346.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-347.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-348.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-349.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-35.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-350.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-351.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-352.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-353.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-354.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-355.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-356.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-357.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-358.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-359.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-36.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-360.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-361.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-362.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-363.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-364.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-365.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-366.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-367.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-368.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-369.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-37.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-370.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-371.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-372.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-373.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-374.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-375.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-376.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-377.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-378.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-379.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-38.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-380.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-381.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-382.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-383.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-384.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-385.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-386.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-387.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-388.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-389.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-39.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-390.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-391.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-392.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-393.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-394.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-395.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-396.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-397.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-398.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-399.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-4.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-40.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-400.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-401.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-402.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-403.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-404.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-405.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-406.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-407.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-408.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-409.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-41.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-410.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-411.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-412.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-413.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-414.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-415.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-416.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-417.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-418.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-419.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-42.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-420.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-421.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-422.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-423.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-424.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-425.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-426.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-427.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-428.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-429.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-43.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-430.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-431.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-432.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-433.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-434.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-435.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-436.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-437.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-438.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-439.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-44.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-440.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-441.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-442.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-443.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-444.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-445.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-446.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-447.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-448.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-449.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-45.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-450.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-451.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-452.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-453.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-454.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-455.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-456.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-457.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-458.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-459.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-46.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-460.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-461.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-462.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-463.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-464.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-465.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-466.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-467.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-468.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-469.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-47.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-470.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-471.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-472.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-473.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-474.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-475.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-476.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-477.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-478.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-479.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-48.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-480.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-481.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-482.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-483.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-484.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-485.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-486.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-487.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-488.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-489.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-49.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-490.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-491.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-492.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-493.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-494.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-495.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-496.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-497.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-498.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-499.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-5.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-50.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-500.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-501.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-502.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-503.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-504.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-505.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-506.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-507.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-508.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-509.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-51.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-510.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-511.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-512.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-513.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-514.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-515.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-516.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-517.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-518.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-519.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-52.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-520.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-521.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-522.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-523.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-524.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-525.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-526.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-527.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-528.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-529.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-53.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-530.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-531.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-532.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-533.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-534.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-535.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-536.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-537.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-538.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-539.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-54.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-540.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-541.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-542.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-543.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-544.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-545.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-546.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-547.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-548.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-549.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-55.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-550.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-551.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-552.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-553.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-554.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-555.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-556.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-557.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-558.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-559.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-56.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-560.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-561.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-562.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-563.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-564.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-565.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-566.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-567.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-568.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-569.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-57.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-570.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-571.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-572.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-573.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-574.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-575.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-576.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-577.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-578.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-579.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-58.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-580.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-581.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-582.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-583.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-584.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-585.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-586.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-587.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-588.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-589.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-59.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-590.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-591.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-592.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-593.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-594.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-595.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-596.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-597.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-598.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-599.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-6.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-60.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-600.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-601.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-602.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-603.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-604.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-605.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-606.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-607.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-608.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-609.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-61.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-610.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-611.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-612.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-613.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-614.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-615.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-616.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-617.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-618.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-619.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-62.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-620.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-621.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-622.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-623.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-624.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-625.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-626.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-627.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-628.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-629.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-63.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-630.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-631.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-632.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-633.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-634.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-635.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-636.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-637.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-638.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-639.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-64.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-640.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-641.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-642.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-643.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-644.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-645.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-646.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-647.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-648.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-649.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-65.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-650.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-651.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-652.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-653.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-654.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-655.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-656.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-657.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-658.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-659.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-66.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-660.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-661.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-662.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-663.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-664.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-665.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-666.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-667.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-668.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-669.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-67.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-670.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-671.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-672.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-673.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-674.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-675.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-676.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-677.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-678.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-679.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-68.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-680.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-681.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-682.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-683.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-684.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-685.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-686.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-687.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-688.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-689.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-69.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-690.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-691.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-692.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-693.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-694.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-695.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-696.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-697.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-698.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-699.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-7.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-70.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-700.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-701.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-702.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-703.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-704.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-705.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-706.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-707.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-708.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-709.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-71.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-710.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-711.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-712.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-713.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-714.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-715.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-716.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-717.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-718.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-719.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-72.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-720.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-721.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-722.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-723.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-724.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-725.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-726.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-727.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-728.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-729.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-73.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-730.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-731.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-732.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-733.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-734.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-735.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-736.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-737.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-738.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-739.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-74.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-740.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-741.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-742.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-743.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-744.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-745.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-746.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-747.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-748.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-749.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-75.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-750.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-751.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-752.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-753.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-754.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-755.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-756.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-757.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-758.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-759.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-76.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-760.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-761.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-762.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-763.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-764.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-765.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-766.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-767.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-768.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-769.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-77.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-770.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-771.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-772.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-773.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-774.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-775.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-776.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-777.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-778.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-779.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-78.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-780.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-781.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-782.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-783.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-784.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-785.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-786.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-787.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-788.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-789.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-79.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-790.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-791.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-792.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-793.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-794.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-795.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-796.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-797.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-798.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-799.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-8.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-80.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-800.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-801.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-802.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-803.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-804.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-805.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-806.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-807.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-808.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-809.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-81.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-810.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-811.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-812.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-813.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-814.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-815.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-816.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-817.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-818.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-819.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-82.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-820.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-821.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-822.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-823.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-824.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-825.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-826.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-827.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-828.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-829.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-83.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-830.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-831.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-832.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-833.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-834.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-835.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-836.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-837.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-838.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-839.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-84.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-840.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-841.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-842.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-843.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-844.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-845.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-846.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-847.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-848.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-849.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-85.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-850.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-851.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-852.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-853.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-854.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-855.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-856.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-857.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-858.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-859.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-86.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-860.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-861.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-862.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-863.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-864.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-865.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-866.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-867.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-868.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-869.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-87.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-870.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-871.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-872.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-873.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-874.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-875.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-876.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-877.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-878.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-879.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-88.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-880.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-881.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-882.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-883.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-884.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-885.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-886.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-887.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-888.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-889.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-89.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-890.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-891.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-892.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-893.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-894.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-895.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-896.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-897.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-898.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-899.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-9.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-90.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-900.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-901.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-902.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-903.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-904.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-905.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-906.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-907.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-908.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-909.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-91.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-910.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-911.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-912.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-913.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-914.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-915.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-916.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-917.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-918.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-919.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-92.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-920.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-921.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-922.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-923.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-924.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-925.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-926.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-927.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-928.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-929.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-93.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-930.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-931.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-932.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-933.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-934.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-935.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-936.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-937.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-938.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-939.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-94.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-940.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-941.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-942.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-943.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-944.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-945.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-946.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-947.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-948.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-949.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-95.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-950.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-951.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-952.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-953.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-954.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-955.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-956.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-957.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-958.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-959.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-96.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-960.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-961.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-962.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-963.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-964.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-965.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-966.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-967.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-968.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-969.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-97.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-970.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-971.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-972.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-973.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-974.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-975.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-976.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-977.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-978.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-979.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-98.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-980.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-981.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-982.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-983.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-984.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-985.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-986.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-987.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-988.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-989.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-99.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-990.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-991.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-992.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-993.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-994.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-995.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-996.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-997.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-998.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/images/Viral Pneumonia-999.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-10.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-100.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1000.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1001.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1002.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1003.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1004.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1005.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1006.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1007.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1008.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1009.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-101.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1010.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1011.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1012.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1013.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1014.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1015.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1016.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1017.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1018.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1019.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-102.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1020.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1021.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1022.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1023.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1024.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1025.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1026.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1027.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1028.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1029.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-103.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1030.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1031.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1032.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1033.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1034.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1035.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1036.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1037.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1038.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1039.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-104.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1040.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1041.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1042.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1043.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1044.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1045.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1046.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1047.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1048.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1049.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-105.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1050.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1051.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1052.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1053.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1054.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1055.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1056.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1057.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1058.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1059.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-106.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1060.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1061.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1062.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1063.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1064.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1065.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1066.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1067.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1068.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1069.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-107.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1070.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1071.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1072.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1073.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1074.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1075.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1076.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1077.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1078.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1079.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-108.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1080.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1081.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1082.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1083.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1084.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1085.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1086.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1087.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1088.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1089.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-109.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1090.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1091.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1092.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1093.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1094.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1095.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1096.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1097.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1098.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1099.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-11.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-110.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1100.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1101.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1102.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1103.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1104.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1105.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1106.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1107.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1108.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1109.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-111.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1110.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1111.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1112.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1113.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1114.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1115.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1116.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1117.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1118.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1119.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-112.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1120.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1121.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1122.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1123.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1124.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1125.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1126.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1127.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1128.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1129.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-113.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1130.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1131.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1132.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1133.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1134.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1135.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1136.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1137.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1138.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1139.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-114.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1140.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1141.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1142.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1143.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1144.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1145.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1146.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1147.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1148.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1149.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-115.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1150.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1151.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1152.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1153.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1154.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1155.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1156.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1157.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1158.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1159.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-116.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1160.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1161.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1162.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1163.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1164.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1165.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1166.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1167.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1168.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1169.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-117.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1170.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1171.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1172.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1173.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1174.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1175.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1176.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1177.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1178.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1179.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-118.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1180.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1181.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1182.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1183.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1184.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1185.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1186.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1187.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1188.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1189.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-119.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1190.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1191.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1192.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1193.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1194.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1195.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1196.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1197.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1198.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1199.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-12.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-120.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1200.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1201.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1202.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1203.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1204.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1205.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1206.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1207.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1208.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1209.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-121.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1210.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1211.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1212.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1213.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1214.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1215.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1216.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1217.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1218.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1219.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-122.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1220.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1221.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1222.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1223.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1224.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1225.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1226.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1227.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1228.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1229.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-123.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1230.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1231.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1232.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1233.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1234.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1235.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1236.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1237.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1238.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1239.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-124.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1240.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1241.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1242.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1243.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1244.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1245.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1246.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1247.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1248.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1249.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-125.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1250.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1251.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1252.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1253.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1254.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1255.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1256.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1257.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1258.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1259.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-126.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1260.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1261.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1262.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1263.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1264.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1265.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1266.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1267.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1268.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1269.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-127.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1270.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1271.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1272.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1273.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1274.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1275.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1276.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1277.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1278.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1279.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-128.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1280.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1281.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1282.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1283.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1284.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1285.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1286.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1287.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1288.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1289.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-129.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1290.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1291.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1292.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1293.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1294.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1295.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1296.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1297.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1298.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1299.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-13.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-130.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1300.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1301.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1302.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1303.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1304.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1305.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1306.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1307.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1308.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1309.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-131.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1310.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1311.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1312.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1313.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1314.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1315.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1316.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1317.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1318.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1319.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-132.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1320.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1321.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1322.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1323.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1324.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1325.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1326.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1327.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1328.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1329.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-133.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1330.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1331.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1332.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1333.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1334.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1335.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1336.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1337.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1338.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1339.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-134.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1340.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1341.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1342.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1343.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1344.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-1345.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-135.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-136.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-137.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-138.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-139.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-14.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-140.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-141.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-142.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-143.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-144.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-145.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-146.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-147.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-148.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-149.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-15.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-150.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-151.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-152.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-153.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-154.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-155.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-156.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-157.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-158.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-159.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-16.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-160.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-161.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-162.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-163.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-164.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-165.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-166.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-167.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-168.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-169.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-17.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-170.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-171.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-172.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-173.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-174.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-175.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-176.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-177.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-178.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-179.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-18.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-180.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-181.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-182.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-183.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-184.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-185.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-186.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-187.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-188.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-189.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-19.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-190.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-191.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-192.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-193.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-194.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-195.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-196.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-197.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-198.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-199.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-2.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-20.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-200.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-201.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-202.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-203.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-204.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-205.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-206.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-207.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-208.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-209.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-21.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-210.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-211.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-212.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-213.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-214.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-215.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-216.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-217.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-218.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-219.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-22.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-220.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-221.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-222.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-223.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-224.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-225.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-226.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-227.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-228.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-229.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-23.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-230.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-231.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-232.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-233.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-234.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-235.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-236.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-237.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-238.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-239.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-24.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-240.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-241.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-242.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-243.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-244.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-245.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-246.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-247.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-248.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-249.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-25.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-250.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-251.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-252.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-253.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-254.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-255.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-256.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-257.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-258.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-259.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-26.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-260.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-261.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-262.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-263.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-264.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-265.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-266.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-267.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-268.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-269.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-27.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-270.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-271.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-272.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-273.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-274.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-275.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-276.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-277.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-278.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-279.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-28.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-280.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-281.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-282.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-283.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-284.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-285.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-286.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-287.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-288.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-289.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-29.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-290.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-291.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-292.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-293.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-294.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-295.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-296.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-297.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-298.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-299.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-3.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-30.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-300.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-301.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-302.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-303.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-304.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-305.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-306.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-307.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-308.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-309.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-31.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-310.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-311.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-312.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-313.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-314.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-315.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-316.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-317.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-318.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-319.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-32.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-320.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-321.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-322.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-323.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-324.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-325.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-326.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-327.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-328.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-329.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-33.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-330.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-331.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-332.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-333.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-334.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-335.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-336.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-337.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-338.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-339.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-34.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-340.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-341.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-342.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-343.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-344.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-345.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-346.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-347.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-348.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-349.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-35.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-350.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-351.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-352.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-353.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-354.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-355.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-356.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-357.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-358.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-359.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-36.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-360.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-361.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-362.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-363.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-364.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-365.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-366.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-367.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-368.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-369.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-37.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-370.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-371.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-372.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-373.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-374.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-375.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-376.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-377.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-378.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-379.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-38.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-380.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-381.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-382.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-383.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-384.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-385.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-386.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-387.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-388.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-389.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-39.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-390.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-391.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-392.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-393.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-394.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-395.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-396.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-397.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-398.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-399.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-4.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-40.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-400.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-401.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-402.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-403.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-404.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-405.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-406.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-407.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-408.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-409.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-41.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-410.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-411.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-412.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-413.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-414.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-415.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-416.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-417.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-418.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-419.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-42.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-420.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-421.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-422.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-423.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-424.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-425.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-426.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-427.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-428.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-429.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-43.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-430.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-431.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-432.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-433.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-434.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-435.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-436.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-437.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-438.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-439.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-44.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-440.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-441.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-442.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-443.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-444.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-445.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-446.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-447.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-448.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-449.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-45.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-450.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-451.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-452.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-453.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-454.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-455.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-456.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-457.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-458.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-459.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-46.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-460.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-461.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-462.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-463.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-464.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-465.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-466.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-467.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-468.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-469.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-47.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-470.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-471.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-472.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-473.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-474.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-475.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-476.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-477.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-478.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-479.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-48.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-480.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-481.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-482.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-483.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-484.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-485.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-486.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-487.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-488.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-489.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-49.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-490.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-491.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-492.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-493.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-494.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-495.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-496.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-497.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-498.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-499.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-5.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-50.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-500.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-501.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-502.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-503.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-504.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-505.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-506.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-507.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-508.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-509.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-51.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-510.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-511.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-512.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-513.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-514.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-515.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-516.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-517.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-518.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-519.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-52.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-520.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-521.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-522.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-523.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-524.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-525.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-526.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-527.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-528.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-529.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-53.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-530.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-531.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-532.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-533.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-534.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-535.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-536.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-537.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-538.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-539.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-54.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-540.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-541.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-542.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-543.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-544.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-545.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-546.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-547.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-548.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-549.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-55.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-550.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-551.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-552.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-553.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-554.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-555.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-556.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-557.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-558.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-559.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-56.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-560.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-561.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-562.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-563.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-564.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-565.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-566.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-567.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-568.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-569.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-57.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-570.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-571.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-572.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-573.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-574.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-575.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-576.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-577.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-578.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-579.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-58.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-580.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-581.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-582.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-583.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-584.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-585.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-586.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-587.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-588.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-589.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-59.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-590.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-591.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-592.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-593.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-594.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-595.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-596.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-597.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-598.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-599.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-6.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-60.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-600.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-601.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-602.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-603.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-604.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-605.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-606.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-607.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-608.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-609.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-61.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-610.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-611.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-612.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-613.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-614.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-615.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-616.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-617.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-618.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-619.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-62.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-620.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-621.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-622.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-623.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-624.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-625.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-626.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-627.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-628.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-629.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-63.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-630.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-631.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-632.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-633.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-634.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-635.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-636.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-637.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-638.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-639.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-64.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-640.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-641.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-642.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-643.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-644.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-645.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-646.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-647.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-648.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-649.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-65.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-650.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-651.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-652.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-653.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-654.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-655.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-656.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-657.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-658.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-659.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-66.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-660.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-661.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-662.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-663.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-664.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-665.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-666.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-667.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-668.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-669.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-67.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-670.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-671.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-672.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-673.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-674.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-675.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-676.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-677.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-678.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-679.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-68.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-680.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-681.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-682.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-683.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-684.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-685.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-686.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-687.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-688.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-689.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-69.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-690.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-691.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-692.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-693.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-694.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-695.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-696.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-697.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-698.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-699.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-7.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-70.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-700.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-701.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-702.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-703.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-704.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-705.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-706.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-707.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-708.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-709.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-71.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-710.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-711.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-712.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-713.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-714.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-715.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-716.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-717.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-718.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-719.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-72.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-720.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-721.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-722.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-723.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-724.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-725.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-726.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-727.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-728.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-729.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-73.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-730.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-731.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-732.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-733.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-734.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-735.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-736.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-737.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-738.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-739.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-74.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-740.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-741.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-742.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-743.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-744.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-745.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-746.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-747.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-748.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-749.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-75.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-750.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-751.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-752.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-753.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-754.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-755.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-756.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-757.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-758.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-759.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-76.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-760.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-761.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-762.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-763.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-764.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-765.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-766.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-767.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-768.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-769.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-77.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-770.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-771.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-772.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-773.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-774.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-775.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-776.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-777.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-778.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-779.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-78.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-780.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-781.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-782.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-783.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-784.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-785.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-786.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-787.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-788.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-789.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-79.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-790.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-791.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-792.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-793.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-794.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-795.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-796.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-797.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-798.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-799.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-8.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-80.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-800.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-801.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-802.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-803.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-804.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-805.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-806.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-807.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-808.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-809.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-81.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-810.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-811.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-812.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-813.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-814.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-815.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-816.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-817.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-818.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-819.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-82.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-820.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-821.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-822.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-823.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-824.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-825.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-826.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-827.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-828.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-829.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-83.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-830.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-831.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-832.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-833.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-834.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-835.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-836.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-837.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-838.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-839.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-84.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-840.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-841.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-842.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-843.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-844.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-845.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-846.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-847.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-848.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-849.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-85.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-850.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-851.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-852.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-853.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-854.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-855.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-856.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-857.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-858.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-859.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-86.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-860.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-861.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-862.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-863.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-864.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-865.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-866.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-867.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-868.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-869.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-87.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-870.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-871.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-872.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-873.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-874.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-875.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-876.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-877.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-878.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-879.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-88.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-880.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-881.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-882.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-883.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-884.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-885.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-886.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-887.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-888.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-889.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-89.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-890.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-891.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-892.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-893.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-894.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-895.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-896.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-897.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-898.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-899.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-9.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-90.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-900.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-901.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-902.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-903.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-904.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-905.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-906.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-907.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-908.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-909.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-91.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-910.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-911.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-912.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-913.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-914.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-915.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-916.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-917.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-918.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-919.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-92.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-920.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-921.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-922.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-923.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-924.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-925.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-926.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-927.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-928.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-929.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-93.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-930.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-931.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-932.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-933.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-934.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-935.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-936.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-937.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-938.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-939.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-94.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-940.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-941.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-942.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-943.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-944.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-945.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-946.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-947.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-948.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-949.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-95.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-950.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-951.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-952.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-953.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-954.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-955.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-956.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-957.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-958.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-959.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-96.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-960.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-961.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-962.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-963.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-964.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-965.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-966.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-967.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-968.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-969.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-97.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-970.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-971.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-972.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-973.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-974.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-975.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-976.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-977.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-978.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-979.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-98.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-980.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-981.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-982.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-983.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-984.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-985.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-986.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-987.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-988.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-989.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-99.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-990.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-991.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-992.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-993.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-994.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-995.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-996.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-997.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-998.png  \n",
            "  inflating: COVID-19_Radiography_Dataset/Viral Pneumonia/masks/Viral Pneumonia-999.png  \n"
          ]
        }
      ],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download tawsifurrahman/covid19-radiography-database\n",
        "! unzip covid19-radiography-database.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "d31IhGToiBjh"
      },
      "outputs": [],
      "source": [
        "def read_covid_data():\n",
        "    levels = ['Normal', 'COVID']\n",
        "    path = \"./COVID-19_Radiography_Dataset/\"\n",
        "    data_dir = os.path.join(path)\n",
        "\n",
        "    data = []\n",
        "    for id, level in enumerate(levels):\n",
        "        for file in os.listdir(os.path.join(data_dir , level+ '/images/')):\n",
        "            data.append(['{}/images/{}'.format(level, file), level])\n",
        "\n",
        "    data = pd.DataFrame(data, columns = ['image_file', 'corona_result'])\n",
        "\n",
        "    data['path'] = path + '/' + data['image_file']\n",
        "    data['corona_result'] = data['corona_result'].map({'Normal': 'Negative', 'COVID': 'Positive'})\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    # Storing images and their labels into a list for further Train Test split\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        image = cv2.imread(data['path'][i])\n",
        "        image = cv2.resize(image, (70, 70)) / 255.0\n",
        "\n",
        "        label = 1 if data['corona_result'][i] == \"Positive\" else 0\n",
        "\n",
        "        x.append(image)\n",
        "        y.append(label)\n",
        "    \n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9jolZdvNko-V"
      },
      "outputs": [],
      "source": [
        "def get_covid_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (70, 70, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(units = 16, activation = 'relu'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "\n",
        "    model.add(layers.Dense(units = 2))\n",
        "    \n",
        "    model.compile(\n",
        "        optimizer = 'adam', \n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "L0HoprOPHUwh"
      },
      "outputs": [],
      "source": [
        "def deep_copy_covid_model(model):\n",
        "    model_copy= keras.models.clone_model(model)\n",
        "    model_copy.compile(\n",
        "        optimizer='adam', \n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        metrics = ['accuracy']\n",
        "    )\n",
        "    model_copy.set_weights(model.get_weights())\n",
        "    return model_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zYDJcoNrnxR",
        "outputId": "83b4e577-f7f9-4c68-f7dd-37a78fd35058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13808, 70, 70, 3)\n",
            "(13808,)\n"
          ]
        }
      ],
      "source": [
        "x_covid, y_covid = read_covid_data()\n",
        "print(x_covid.shape)\n",
        "print(y_covid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOzunrXkHIFn",
        "outputId": "acb91ce3-a375-46e9-e399-04a58c0bb76d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 68, 68, 128)       3584      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 34, 34, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 34, 34, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 64)        73792     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 64)        36928     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 16)                200720    \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 315,058\n",
            "Trainable params: 315,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "691/691 [==============================] - 7s 10ms/step - loss: 0.4744 - accuracy: 0.7650 - val_loss: 0.3637 - val_accuracy: 0.8338\n",
            "Epoch 2/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.3526 - accuracy: 0.8475 - val_loss: 0.2934 - val_accuracy: 0.8707\n",
            "Epoch 3/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.3031 - accuracy: 0.8727 - val_loss: 0.2526 - val_accuracy: 0.9019\n",
            "Epoch 4/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.2648 - accuracy: 0.8922 - val_loss: 0.2307 - val_accuracy: 0.9059\n",
            "Epoch 5/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.2436 - accuracy: 0.8982 - val_loss: 0.2603 - val_accuracy: 0.8722\n",
            "Epoch 6/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.2130 - accuracy: 0.9189 - val_loss: 0.1725 - val_accuracy: 0.9345\n",
            "Epoch 7/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.1972 - accuracy: 0.9223 - val_loss: 0.1540 - val_accuracy: 0.9399\n",
            "Epoch 8/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.1716 - accuracy: 0.9320 - val_loss: 0.1817 - val_accuracy: 0.9298\n",
            "Epoch 9/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.1574 - accuracy: 0.9404 - val_loss: 0.1672 - val_accuracy: 0.9381\n",
            "Epoch 10/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.1502 - accuracy: 0.9431 - val_loss: 0.1583 - val_accuracy: 0.9508\n",
            "Epoch 11/40\n",
            "691/691 [==============================] - 6s 9ms/step - loss: 0.1464 - accuracy: 0.9421 - val_loss: 0.1550 - val_accuracy: 0.9446\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Centralized\n",
        "covid_model = get_covid_model()\n",
        "covid_model = model_learn(x_covid, y_covid, covid_model, 40, deep_copy_covid_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42r0qoQgdBtz"
      },
      "outputs": [],
      "source": [
        "# Decentralized FL\n",
        "acc_dfl_covid = complete_xp(np.copy(x_covid), np.copy(y_covid), get_covid_model(), [2,4,8], [3,6,9], 50, 3, deep_copy_covid_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cITAD9beUx7a"
      },
      "outputs": [],
      "source": [
        "tmp = get_metrics(acc_dfl_covid, [0.85, 0.90])\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[0], \"Final Accuracy\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[1], \"Max Accuracy\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[2][0], \"Rounds to 85%\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[2][1], \"Rounds to 90%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97qswGLaRKHr",
        "outputId": "e25a5cfd-9ee5-4c30-8552-c0a5777c483c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.2793 - accuracy: 0.6364 - val_loss: 0.6395 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6494 - accuracy: 0.6364 - val_loss: 0.6929 - val_accuracy: 0.5161\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6610 - accuracy: 0.6667 - val_loss: 0.8286 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 1.4508 - accuracy: 0.6992 - val_loss: 0.5897 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6508 - accuracy: 0.6992 - val_loss: 0.6756 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6819 - accuracy: 0.6098 - val_loss: 0.9083 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 1.3301 - accuracy: 0.6423 - val_loss: 0.6642 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6470 - accuracy: 0.6423 - val_loss: 0.6847 - val_accuracy: 0.6129\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.6595 - accuracy: 0.6992 - val_loss: 1.3015 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 1.4395 - accuracy: 0.7398 - val_loss: 0.7041 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6190 - accuracy: 0.7398 - val_loss: 0.6846 - val_accuracy: 0.6129\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6358 - accuracy: 0.6860 - val_loss: 0.8720 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 1.4681 - accuracy: 0.7769 - val_loss: 0.5619 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5935 - accuracy: 0.7769 - val_loss: 0.6540 - val_accuracy: 0.7419\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6586 - accuracy: 0.7438 - val_loss: 0.7821 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 1.3536 - accuracy: 0.7603 - val_loss: 0.5570 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5918 - accuracy: 0.7603 - val_loss: 0.6585 - val_accuracy: 0.7742\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6480 - accuracy: 0.7438 - val_loss: 0.6783 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 1.3592 - accuracy: 0.7603 - val_loss: 0.5350 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6233 - accuracy: 0.7603 - val_loss: 0.6537 - val_accuracy: 0.8065\n",
            "Publisher: global iteration=1\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 0.6443 - accuracy: 0.7236 - val_loss: 0.7306 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.8314 - accuracy: 0.7236 - val_loss: 0.6577 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6153 - accuracy: 0.7236 - val_loss: 0.6805 - val_accuracy: 0.6452\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6340 - accuracy: 0.7561 - val_loss: 0.7787 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.7528 - accuracy: 0.7561 - val_loss: 0.6679 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5691 - accuracy: 0.7561 - val_loss: 0.6778 - val_accuracy: 0.6129\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 0.6272 - accuracy: 0.7851 - val_loss: 0.6850 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.7265 - accuracy: 0.7851 - val_loss: 0.6275 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5306 - accuracy: 0.7851 - val_loss: 0.6580 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6253 - accuracy: 0.7603 - val_loss: 0.5477 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.8214 - accuracy: 0.7603 - val_loss: 0.5866 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5789 - accuracy: 0.7603 - val_loss: 0.6489 - val_accuracy: 0.7742\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6253 - accuracy: 0.7967 - val_loss: 0.4893 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7380 - accuracy: 0.7967 - val_loss: 0.5730 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5354 - accuracy: 0.7967 - val_loss: 0.6426 - val_accuracy: 0.8065\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.6524 - accuracy: 0.7154 - val_loss: 0.6420 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7974 - accuracy: 0.7154 - val_loss: 0.6364 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6167 - accuracy: 0.7154 - val_loss: 0.6733 - val_accuracy: 0.7097\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6359 - accuracy: 0.7561 - val_loss: 0.5595 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.8064 - accuracy: 0.7561 - val_loss: 0.6038 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5866 - accuracy: 0.7561 - val_loss: 0.6567 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6376 - accuracy: 0.7317 - val_loss: 0.6694 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.8877 - accuracy: 0.7317 - val_loss: 0.6351 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5834 - accuracy: 0.7317 - val_loss: 0.6704 - val_accuracy: 0.7097\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.6539 - accuracy: 0.7154 - val_loss: 0.6250 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.8193 - accuracy: 0.7154 - val_loss: 0.6395 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6064 - accuracy: 0.7154 - val_loss: 0.6732 - val_accuracy: 0.7097\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.6397 - accuracy: 0.7107 - val_loss: 0.5026 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.9302 - accuracy: 0.7107 - val_loss: 0.5959 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6181 - accuracy: 0.7107 - val_loss: 0.6597 - val_accuracy: 0.8065\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6393 - accuracy: 0.7438 - val_loss: 0.4458 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.8425 - accuracy: 0.7438 - val_loss: 0.5859 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5902 - accuracy: 0.7438 - val_loss: 0.6514 - val_accuracy: 0.8387\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.6445 - accuracy: 0.7073 - val_loss: 0.5911 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.7775 - accuracy: 0.7073 - val_loss: 0.6278 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5997 - accuracy: 0.7073 - val_loss: 0.6652 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6441 - accuracy: 0.7107 - val_loss: 0.5909 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.8260 - accuracy: 0.7107 - val_loss: 0.6263 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.6188 - accuracy: 0.7107 - val_loss: 0.6708 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.6261 - accuracy: 0.7642 - val_loss: 0.4676 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.7737 - accuracy: 0.7642 - val_loss: 0.5626 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5703 - accuracy: 0.7642 - val_loss: 0.6410 - val_accuracy: 0.8387\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.6195 - accuracy: 0.7769 - val_loss: 0.5836 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.7648 - accuracy: 0.7769 - val_loss: 0.5985 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5605 - accuracy: 0.7769 - val_loss: 0.6501 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.6307 - accuracy: 0.7561 - val_loss: 0.5473 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.7562 - accuracy: 0.7561 - val_loss: 0.5953 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.5820 - accuracy: 0.7561 - val_loss: 0.6494 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.6468 - accuracy: 0.6829 - val_loss: 0.6772 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.8849 - accuracy: 0.6829 - val_loss: 0.6520 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6404 - accuracy: 0.6829 - val_loss: 0.6789 - val_accuracy: 0.6774\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6221 - accuracy: 0.8017 - val_loss: 0.5018 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6852 - accuracy: 0.8017 - val_loss: 0.5687 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5048 - accuracy: 0.8017 - val_loss: 0.6211 - val_accuracy: 0.8065\n",
            "Publisher: global iteration=2\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.6328 - accuracy: 0.7073 - val_loss: 0.6200 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7127 - accuracy: 0.7073 - val_loss: 0.6450 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6180 - accuracy: 0.7073 - val_loss: 0.6693 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5947 - accuracy: 0.8017 - val_loss: 0.5558 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6068 - accuracy: 0.8017 - val_loss: 0.5859 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4936 - accuracy: 0.8017 - val_loss: 0.6162 - val_accuracy: 0.7742\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.6140 - accuracy: 0.7521 - val_loss: 0.4713 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6812 - accuracy: 0.7521 - val_loss: 0.5757 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5682 - accuracy: 0.7521 - val_loss: 0.6306 - val_accuracy: 0.8387\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.6101 - accuracy: 0.7561 - val_loss: 0.4551 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.6665 - accuracy: 0.7561 - val_loss: 0.5688 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5677 - accuracy: 0.7561 - val_loss: 0.6267 - val_accuracy: 0.8387\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5952 - accuracy: 0.7934 - val_loss: 0.5590 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5459 - accuracy: 0.7934 - val_loss: 0.5729 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5274 - accuracy: 0.7934 - val_loss: 0.6188 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6279 - accuracy: 0.7073 - val_loss: 0.7089 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.7844 - accuracy: 0.7073 - val_loss: 0.6694 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6227 - accuracy: 0.7073 - val_loss: 0.6800 - val_accuracy: 0.6129\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6153 - accuracy: 0.7561 - val_loss: 0.5391 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6371 - accuracy: 0.7561 - val_loss: 0.5956 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5642 - accuracy: 0.7561 - val_loss: 0.6371 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6297 - accuracy: 0.7438 - val_loss: 0.5737 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6918 - accuracy: 0.7438 - val_loss: 0.6229 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5942 - accuracy: 0.7438 - val_loss: 0.6535 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6290 - accuracy: 0.7154 - val_loss: 0.5914 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.7713 - accuracy: 0.7154 - val_loss: 0.6368 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6174 - accuracy: 0.7154 - val_loss: 0.6684 - val_accuracy: 0.7097\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5946 - accuracy: 0.7967 - val_loss: 0.6012 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5729 - accuracy: 0.7967 - val_loss: 0.6070 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5507 - accuracy: 0.7967 - val_loss: 0.6364 - val_accuracy: 0.7097\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6095 - accuracy: 0.7398 - val_loss: 0.5837 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.7400 - accuracy: 0.7398 - val_loss: 0.6202 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5871 - accuracy: 0.7398 - val_loss: 0.6518 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6369 - accuracy: 0.6667 - val_loss: 0.6576 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.7733 - accuracy: 0.6667 - val_loss: 0.6639 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6379 - accuracy: 0.6667 - val_loss: 0.6805 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6367 - accuracy: 0.7025 - val_loss: 0.5364 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.7438 - accuracy: 0.7025 - val_loss: 0.6222 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6194 - accuracy: 0.7025 - val_loss: 0.6632 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.6082 - accuracy: 0.7642 - val_loss: 0.6170 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6128 - accuracy: 0.7642 - val_loss: 0.6220 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5650 - accuracy: 0.7642 - val_loss: 0.6491 - val_accuracy: 0.7097\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5949 - accuracy: 0.7851 - val_loss: 0.6090 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6350 - accuracy: 0.7851 - val_loss: 0.6171 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5250 - accuracy: 0.7851 - val_loss: 0.6399 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5997 - accuracy: 0.7769 - val_loss: 0.5728 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6012 - accuracy: 0.7769 - val_loss: 0.5936 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5495 - accuracy: 0.7769 - val_loss: 0.6304 - val_accuracy: 0.7419\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6281 - accuracy: 0.7355 - val_loss: 0.4401 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.6740 - accuracy: 0.7355 - val_loss: 0.5644 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.5860 - accuracy: 0.7355 - val_loss: 0.6217 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6044 - accuracy: 0.8099 - val_loss: 0.5186 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5584 - accuracy: 0.8099 - val_loss: 0.5612 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5317 - accuracy: 0.8099 - val_loss: 0.6135 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=3\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6257 - accuracy: 0.7073 - val_loss: 0.6063 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6663 - accuracy: 0.7073 - val_loss: 0.6390 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6119 - accuracy: 0.7073 - val_loss: 0.6619 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.6296 - accuracy: 0.6829 - val_loss: 0.5315 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6716 - accuracy: 0.6829 - val_loss: 0.6169 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6163 - accuracy: 0.6829 - val_loss: 0.6476 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5898 - accuracy: 0.7480 - val_loss: 0.5782 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6710 - accuracy: 0.7480 - val_loss: 0.6031 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5754 - accuracy: 0.7480 - val_loss: 0.6405 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.6110 - accuracy: 0.7073 - val_loss: 0.5857 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6538 - accuracy: 0.7073 - val_loss: 0.6265 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6051 - accuracy: 0.7073 - val_loss: 0.6581 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6233 - accuracy: 0.7236 - val_loss: 0.6144 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6531 - accuracy: 0.7236 - val_loss: 0.6435 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6067 - accuracy: 0.7236 - val_loss: 0.6614 - val_accuracy: 0.6774\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.6040 - accuracy: 0.7480 - val_loss: 0.7222 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6215 - accuracy: 0.7480 - val_loss: 0.6759 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5678 - accuracy: 0.7480 - val_loss: 0.6759 - val_accuracy: 0.5806\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5885 - accuracy: 0.7642 - val_loss: 0.5668 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6609 - accuracy: 0.7642 - val_loss: 0.6012 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5699 - accuracy: 0.7642 - val_loss: 0.6429 - val_accuracy: 0.7419\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6126 - accuracy: 0.7154 - val_loss: 0.5379 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6987 - accuracy: 0.7154 - val_loss: 0.6137 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5894 - accuracy: 0.7154 - val_loss: 0.6530 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6285 - accuracy: 0.6992 - val_loss: 0.4296 - val_accuracy: 0.9355\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6911 - accuracy: 0.6992 - val_loss: 0.5882 - val_accuracy: 0.9355\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6160 - accuracy: 0.6992 - val_loss: 0.6374 - val_accuracy: 0.9355\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6051 - accuracy: 0.7521 - val_loss: 0.6775 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6522 - accuracy: 0.7521 - val_loss: 0.6544 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5676 - accuracy: 0.7521 - val_loss: 0.6657 - val_accuracy: 0.6452\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5887 - accuracy: 0.7398 - val_loss: 0.5786 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7265 - accuracy: 0.7398 - val_loss: 0.6075 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5717 - accuracy: 0.7398 - val_loss: 0.6466 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6252 - accuracy: 0.6860 - val_loss: 0.7340 - val_accuracy: 0.5161\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6913 - accuracy: 0.6860 - val_loss: 0.6885 - val_accuracy: 0.5161\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6216 - accuracy: 0.6860 - val_loss: 0.6875 - val_accuracy: 0.5161\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6016 - accuracy: 0.7561 - val_loss: 0.5974 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6796 - accuracy: 0.7561 - val_loss: 0.6193 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5541 - accuracy: 0.7561 - val_loss: 0.6457 - val_accuracy: 0.7097\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5783 - accuracy: 0.7851 - val_loss: 0.4833 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5772 - accuracy: 0.7851 - val_loss: 0.5437 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5303 - accuracy: 0.7851 - val_loss: 0.5951 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5992 - accuracy: 0.7317 - val_loss: 0.7014 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.7272 - accuracy: 0.7317 - val_loss: 0.6628 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5879 - accuracy: 0.7317 - val_loss: 0.6733 - val_accuracy: 0.6452\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.5909 - accuracy: 0.7561 - val_loss: 0.4757 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.6979 - accuracy: 0.7561 - val_loss: 0.5701 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5802 - accuracy: 0.7561 - val_loss: 0.6299 - val_accuracy: 0.8387\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5966 - accuracy: 0.7724 - val_loss: 0.6272 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6861 - accuracy: 0.7724 - val_loss: 0.6285 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5655 - accuracy: 0.7724 - val_loss: 0.6543 - val_accuracy: 0.6774\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5792 - accuracy: 0.8017 - val_loss: 0.5091 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5451 - accuracy: 0.8017 - val_loss: 0.5493 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4887 - accuracy: 0.8017 - val_loss: 0.5868 - val_accuracy: 0.8065\n",
            "Publisher: global iteration=4\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6030 - accuracy: 0.7190 - val_loss: 0.5363 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6562 - accuracy: 0.7190 - val_loss: 0.5908 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5827 - accuracy: 0.7190 - val_loss: 0.6245 - val_accuracy: 0.7742\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5948 - accuracy: 0.7398 - val_loss: 0.6152 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6842 - accuracy: 0.7398 - val_loss: 0.6257 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5632 - accuracy: 0.7398 - val_loss: 0.6475 - val_accuracy: 0.6774\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5939 - accuracy: 0.7603 - val_loss: 0.4941 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6698 - accuracy: 0.7603 - val_loss: 0.5669 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5572 - accuracy: 0.7603 - val_loss: 0.6127 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5893 - accuracy: 0.7521 - val_loss: 0.5106 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6184 - accuracy: 0.7521 - val_loss: 0.5670 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5753 - accuracy: 0.7521 - val_loss: 0.6143 - val_accuracy: 0.8065\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5872 - accuracy: 0.7886 - val_loss: 0.4755 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5836 - accuracy: 0.7886 - val_loss: 0.5327 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5454 - accuracy: 0.7886 - val_loss: 0.5889 - val_accuracy: 0.8387\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6551 - accuracy: 0.6694 - val_loss: 0.6371 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6277 - accuracy: 0.6694 - val_loss: 0.5978 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6642 - accuracy: 0.6694 - val_loss: 0.6330 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6029 - accuracy: 0.7190 - val_loss: 0.4713 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6691 - accuracy: 0.7190 - val_loss: 0.5573 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5700 - accuracy: 0.7190 - val_loss: 0.6113 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.6152 - accuracy: 0.7154 - val_loss: 0.5510 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6675 - accuracy: 0.7154 - val_loss: 0.6077 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5852 - accuracy: 0.7154 - val_loss: 0.6404 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5856 - accuracy: 0.7805 - val_loss: 0.5181 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5955 - accuracy: 0.7805 - val_loss: 0.5630 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5311 - accuracy: 0.7805 - val_loss: 0.6013 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5945 - accuracy: 0.7480 - val_loss: 0.5694 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6691 - accuracy: 0.7480 - val_loss: 0.6046 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5749 - accuracy: 0.7480 - val_loss: 0.6357 - val_accuracy: 0.7419\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6122 - accuracy: 0.7236 - val_loss: 0.4949 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6453 - accuracy: 0.7236 - val_loss: 0.5818 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6037 - accuracy: 0.7236 - val_loss: 0.6375 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6579 - accuracy: 0.6198 - val_loss: 0.6381 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6615 - accuracy: 0.6198 - val_loss: 0.6401 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6522 - accuracy: 0.6198 - val_loss: 0.6207 - val_accuracy: 0.7742\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6076 - accuracy: 0.7398 - val_loss: 0.6028 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6385 - accuracy: 0.7398 - val_loss: 0.6188 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5740 - accuracy: 0.7398 - val_loss: 0.6407 - val_accuracy: 0.7097\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5904 - accuracy: 0.7724 - val_loss: 0.6239 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5706 - accuracy: 0.7724 - val_loss: 0.6229 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5334 - accuracy: 0.7724 - val_loss: 0.6353 - val_accuracy: 0.6774\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6080 - accuracy: 0.7317 - val_loss: 0.5968 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6488 - accuracy: 0.7317 - val_loss: 0.6195 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5960 - accuracy: 0.7317 - val_loss: 0.6458 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5851 - accuracy: 0.7724 - val_loss: 0.5307 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6425 - accuracy: 0.7724 - val_loss: 0.5765 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5491 - accuracy: 0.7724 - val_loss: 0.6127 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5984 - accuracy: 0.7642 - val_loss: 0.6158 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5686 - accuracy: 0.7642 - val_loss: 0.6162 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5915 - accuracy: 0.7642 - val_loss: 0.6411 - val_accuracy: 0.7097\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5824 - accuracy: 0.7769 - val_loss: 0.5792 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6103 - accuracy: 0.7769 - val_loss: 0.5971 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5543 - accuracy: 0.7769 - val_loss: 0.6260 - val_accuracy: 0.7419\n",
            "Publisher: global iteration=5\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5938 - accuracy: 0.7398 - val_loss: 0.7073 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6338 - accuracy: 0.7398 - val_loss: 0.6671 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5598 - accuracy: 0.7398 - val_loss: 0.6681 - val_accuracy: 0.5806\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5569 - accuracy: 0.7769 - val_loss: 0.4301 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6158 - accuracy: 0.7769 - val_loss: 0.5096 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5403 - accuracy: 0.7769 - val_loss: 0.5744 - val_accuracy: 0.8710\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5693 - accuracy: 0.7724 - val_loss: 0.6641 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6079 - accuracy: 0.7724 - val_loss: 0.6408 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5474 - accuracy: 0.7724 - val_loss: 0.6497 - val_accuracy: 0.6452\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6048 - accuracy: 0.7190 - val_loss: 0.4228 - val_accuracy: 0.9355\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6031 - accuracy: 0.7190 - val_loss: 0.5544 - val_accuracy: 0.9355\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5771 - accuracy: 0.7190 - val_loss: 0.5819 - val_accuracy: 0.9355\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5373 - accuracy: 0.8182 - val_loss: 0.6393 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5363 - accuracy: 0.8182 - val_loss: 0.6225 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4812 - accuracy: 0.8182 - val_loss: 0.6257 - val_accuracy: 0.6774\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6044 - accuracy: 0.7073 - val_loss: 0.5723 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6697 - accuracy: 0.7073 - val_loss: 0.6201 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5987 - accuracy: 0.7073 - val_loss: 0.6538 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5745 - accuracy: 0.7480 - val_loss: 0.5026 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6481 - accuracy: 0.7480 - val_loss: 0.5612 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5537 - accuracy: 0.7480 - val_loss: 0.6070 - val_accuracy: 0.8065\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6020 - accuracy: 0.7190 - val_loss: 0.4697 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6861 - accuracy: 0.7190 - val_loss: 0.5749 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5962 - accuracy: 0.7190 - val_loss: 0.6320 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6058 - accuracy: 0.7154 - val_loss: 0.5806 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.6369 - accuracy: 0.7154 - val_loss: 0.6204 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5771 - accuracy: 0.7154 - val_loss: 0.6395 - val_accuracy: 0.7097\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5442 - accuracy: 0.8211 - val_loss: 0.7134 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5031 - accuracy: 0.8211 - val_loss: 0.6817 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4910 - accuracy: 0.8211 - val_loss: 0.6607 - val_accuracy: 0.6129\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6321 - accuracy: 0.6829 - val_loss: 0.5876 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6248 - accuracy: 0.6829 - val_loss: 0.6247 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6138 - accuracy: 0.6829 - val_loss: 0.5999 - val_accuracy: 0.7742\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6561 - accuracy: 0.6281 - val_loss: 0.6534 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6499 - accuracy: 0.6281 - val_loss: 0.6254 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6496 - accuracy: 0.6281 - val_loss: 0.6226 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6026 - accuracy: 0.7154 - val_loss: 0.5042 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6837 - accuracy: 0.7154 - val_loss: 0.5813 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5801 - accuracy: 0.7154 - val_loss: 0.6286 - val_accuracy: 0.8065\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.6001 - accuracy: 0.7317 - val_loss: 0.4658 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.6593 - accuracy: 0.7317 - val_loss: 0.5601 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5886 - accuracy: 0.7317 - val_loss: 0.6161 - val_accuracy: 0.8387\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5951 - accuracy: 0.7317 - val_loss: 0.4992 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6683 - accuracy: 0.7317 - val_loss: 0.5781 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5811 - accuracy: 0.7317 - val_loss: 0.6200 - val_accuracy: 0.8065\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5945 - accuracy: 0.7398 - val_loss: 0.4716 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6465 - accuracy: 0.7398 - val_loss: 0.5574 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5731 - accuracy: 0.7398 - val_loss: 0.6120 - val_accuracy: 0.8387\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5549 - accuracy: 0.7769 - val_loss: 0.5974 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5799 - accuracy: 0.7769 - val_loss: 0.5948 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5574 - accuracy: 0.7769 - val_loss: 0.6216 - val_accuracy: 0.7097\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5438 - accuracy: 0.8099 - val_loss: 0.7053 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5452 - accuracy: 0.8099 - val_loss: 0.6640 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4934 - accuracy: 0.8099 - val_loss: 0.6557 - val_accuracy: 0.6129\n",
            "Publisher: global iteration=6\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5838 - accuracy: 0.7317 - val_loss: 0.7044 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6339 - accuracy: 0.7317 - val_loss: 0.6638 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5753 - accuracy: 0.7317 - val_loss: 0.6658 - val_accuracy: 0.6129\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5187 - accuracy: 0.8347 - val_loss: 0.6881 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4684 - accuracy: 0.8347 - val_loss: 0.6750 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4821 - accuracy: 0.8347 - val_loss: 0.6436 - val_accuracy: 0.6452\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5714 - accuracy: 0.7480 - val_loss: 0.5450 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6319 - accuracy: 0.7480 - val_loss: 0.5820 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5490 - accuracy: 0.7480 - val_loss: 0.6176 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5988 - accuracy: 0.7154 - val_loss: 0.5890 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6320 - accuracy: 0.7154 - val_loss: 0.6162 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5950 - accuracy: 0.7154 - val_loss: 0.6436 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.6205 - accuracy: 0.6748 - val_loss: 0.5108 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6237 - accuracy: 0.6748 - val_loss: 0.5858 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6153 - accuracy: 0.6748 - val_loss: 0.5775 - val_accuracy: 0.8710\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5937 - accuracy: 0.7073 - val_loss: 0.5616 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6738 - accuracy: 0.7073 - val_loss: 0.5992 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5952 - accuracy: 0.7073 - val_loss: 0.6347 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5959 - accuracy: 0.6992 - val_loss: 0.5431 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.7007 - accuracy: 0.6992 - val_loss: 0.5992 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6097 - accuracy: 0.6992 - val_loss: 0.6384 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5500 - accuracy: 0.8049 - val_loss: 0.6615 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5372 - accuracy: 0.8049 - val_loss: 0.6353 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5030 - accuracy: 0.8049 - val_loss: 0.6353 - val_accuracy: 0.6452\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5881 - accuracy: 0.7236 - val_loss: 0.4597 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6656 - accuracy: 0.7236 - val_loss: 0.5569 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5627 - accuracy: 0.7236 - val_loss: 0.6084 - val_accuracy: 0.8387\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6178 - accuracy: 0.6992 - val_loss: 0.6032 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6108 - accuracy: 0.6992 - val_loss: 0.6298 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5967 - accuracy: 0.6992 - val_loss: 0.6362 - val_accuracy: 0.6774\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6195 - accuracy: 0.6748 - val_loss: 0.5624 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6304 - accuracy: 0.6748 - val_loss: 0.6208 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6169 - accuracy: 0.6748 - val_loss: 0.6172 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5704 - accuracy: 0.7480 - val_loss: 0.7049 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6047 - accuracy: 0.7480 - val_loss: 0.6651 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5722 - accuracy: 0.7480 - val_loss: 0.6650 - val_accuracy: 0.5806\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5901 - accuracy: 0.7398 - val_loss: 0.5237 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6153 - accuracy: 0.7398 - val_loss: 0.5758 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5560 - accuracy: 0.7398 - val_loss: 0.6106 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5856 - accuracy: 0.7398 - val_loss: 0.5161 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6357 - accuracy: 0.7398 - val_loss: 0.5730 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5770 - accuracy: 0.7398 - val_loss: 0.6229 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5641 - accuracy: 0.7769 - val_loss: 0.5536 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5781 - accuracy: 0.7769 - val_loss: 0.5775 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5410 - accuracy: 0.7769 - val_loss: 0.6157 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5747 - accuracy: 0.7561 - val_loss: 0.5296 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.6456 - accuracy: 0.7561 - val_loss: 0.5722 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5783 - accuracy: 0.7561 - val_loss: 0.6178 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5694 - accuracy: 0.7561 - val_loss: 0.5616 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5954 - accuracy: 0.7561 - val_loss: 0.5825 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5509 - accuracy: 0.7561 - val_loss: 0.6138 - val_accuracy: 0.7419\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5333 - accuracy: 0.8182 - val_loss: 0.4288 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5616 - accuracy: 0.8182 - val_loss: 0.4776 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4785 - accuracy: 0.8182 - val_loss: 0.5312 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=7\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5669 - accuracy: 0.7603 - val_loss: 0.6954 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6035 - accuracy: 0.7603 - val_loss: 0.6483 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5177 - accuracy: 0.7603 - val_loss: 0.6444 - val_accuracy: 0.6129\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5820 - accuracy: 0.7236 - val_loss: 0.5515 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6685 - accuracy: 0.7236 - val_loss: 0.5957 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5894 - accuracy: 0.7236 - val_loss: 0.6361 - val_accuracy: 0.7419\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5252 - accuracy: 0.8293 - val_loss: 0.6707 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4782 - accuracy: 0.8293 - val_loss: 0.6534 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4538 - accuracy: 0.8293 - val_loss: 0.6409 - val_accuracy: 0.6452\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5943 - accuracy: 0.7154 - val_loss: 0.5857 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6316 - accuracy: 0.7154 - val_loss: 0.6133 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5802 - accuracy: 0.7154 - val_loss: 0.6380 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5416 - accuracy: 0.8049 - val_loss: 0.5182 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5418 - accuracy: 0.8049 - val_loss: 0.5399 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4982 - accuracy: 0.8049 - val_loss: 0.5784 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6004 - accuracy: 0.6992 - val_loss: 0.5470 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6329 - accuracy: 0.6992 - val_loss: 0.6036 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5805 - accuracy: 0.6992 - val_loss: 0.6210 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5642 - accuracy: 0.7642 - val_loss: 0.5059 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5626 - accuracy: 0.7642 - val_loss: 0.5405 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5452 - accuracy: 0.7642 - val_loss: 0.5883 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6009 - accuracy: 0.7154 - val_loss: 0.5234 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6234 - accuracy: 0.7154 - val_loss: 0.5832 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5808 - accuracy: 0.7154 - val_loss: 0.6167 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6142 - accuracy: 0.6829 - val_loss: 0.4822 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6269 - accuracy: 0.6829 - val_loss: 0.5710 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6137 - accuracy: 0.6829 - val_loss: 0.6085 - val_accuracy: 0.8387\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5737 - accuracy: 0.7561 - val_loss: 0.4175 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6170 - accuracy: 0.7561 - val_loss: 0.5081 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5279 - accuracy: 0.7561 - val_loss: 0.5640 - val_accuracy: 0.8710\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5524 - accuracy: 0.7934 - val_loss: 0.6537 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5579 - accuracy: 0.7934 - val_loss: 0.6233 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5005 - accuracy: 0.7934 - val_loss: 0.6299 - val_accuracy: 0.6452\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5902 - accuracy: 0.7073 - val_loss: 0.5413 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6581 - accuracy: 0.7073 - val_loss: 0.5895 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5913 - accuracy: 0.7073 - val_loss: 0.6303 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5740 - accuracy: 0.7398 - val_loss: 0.5922 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6400 - accuracy: 0.7398 - val_loss: 0.6021 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5457 - accuracy: 0.7398 - val_loss: 0.6298 - val_accuracy: 0.7097\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5315 - accuracy: 0.8099 - val_loss: 0.5504 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4741 - accuracy: 0.8099 - val_loss: 0.5487 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5009 - accuracy: 0.8099 - val_loss: 0.5662 - val_accuracy: 0.7097\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5745 - accuracy: 0.7480 - val_loss: 0.5377 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6099 - accuracy: 0.7480 - val_loss: 0.5715 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5660 - accuracy: 0.7480 - val_loss: 0.6097 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5642 - accuracy: 0.7724 - val_loss: 0.5116 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6115 - accuracy: 0.7724 - val_loss: 0.5447 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5363 - accuracy: 0.7724 - val_loss: 0.5875 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5623 - accuracy: 0.7805 - val_loss: 0.4877 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6248 - accuracy: 0.7805 - val_loss: 0.5378 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5363 - accuracy: 0.7805 - val_loss: 0.5869 - val_accuracy: 0.8065\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5900 - accuracy: 0.7107 - val_loss: 0.7618 - val_accuracy: 0.5161\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6820 - accuracy: 0.7107 - val_loss: 0.6914 - val_accuracy: 0.5161\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5783 - accuracy: 0.7107 - val_loss: 0.6827 - val_accuracy: 0.5161\n",
            "Publisher: global iteration=8\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6026 - accuracy: 0.6992 - val_loss: 0.5380 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6038 - accuracy: 0.6992 - val_loss: 0.5851 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5799 - accuracy: 0.6992 - val_loss: 0.5898 - val_accuracy: 0.7419\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5405 - accuracy: 0.7805 - val_loss: 0.5718 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5525 - accuracy: 0.7805 - val_loss: 0.5702 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4920 - accuracy: 0.7805 - val_loss: 0.5908 - val_accuracy: 0.7097\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5644 - accuracy: 0.7317 - val_loss: 0.4913 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6239 - accuracy: 0.7317 - val_loss: 0.5542 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5548 - accuracy: 0.7317 - val_loss: 0.6001 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5294 - accuracy: 0.7769 - val_loss: 0.5569 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6122 - accuracy: 0.7769 - val_loss: 0.5681 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5110 - accuracy: 0.7769 - val_loss: 0.5938 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5610 - accuracy: 0.7686 - val_loss: 0.4124 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5951 - accuracy: 0.7686 - val_loss: 0.4910 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5262 - accuracy: 0.7686 - val_loss: 0.5485 - val_accuracy: 0.8710\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5647 - accuracy: 0.7236 - val_loss: 0.6027 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6258 - accuracy: 0.7236 - val_loss: 0.6109 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5676 - accuracy: 0.7236 - val_loss: 0.6290 - val_accuracy: 0.7097\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.6131 - accuracy: 0.6829 - val_loss: 0.5429 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6080 - accuracy: 0.6829 - val_loss: 0.5593 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6011 - accuracy: 0.6829 - val_loss: 0.5043 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.5717 - accuracy: 0.7398 - val_loss: 0.6227 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6253 - accuracy: 0.7398 - val_loss: 0.6196 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5562 - accuracy: 0.7398 - val_loss: 0.6344 - val_accuracy: 0.6774\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5369 - accuracy: 0.8049 - val_loss: 0.5938 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5253 - accuracy: 0.8049 - val_loss: 0.5847 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4931 - accuracy: 0.8049 - val_loss: 0.5958 - val_accuracy: 0.7097\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5709 - accuracy: 0.7317 - val_loss: 0.4906 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6280 - accuracy: 0.7317 - val_loss: 0.5600 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5527 - accuracy: 0.7317 - val_loss: 0.6030 - val_accuracy: 0.8065\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5613 - accuracy: 0.7603 - val_loss: 0.5334 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6326 - accuracy: 0.7603 - val_loss: 0.5711 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5281 - accuracy: 0.7603 - val_loss: 0.6027 - val_accuracy: 0.7742\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6307 - accuracy: 0.6585 - val_loss: 0.6348 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6176 - accuracy: 0.6585 - val_loss: 0.6052 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6166 - accuracy: 0.6585 - val_loss: 0.5997 - val_accuracy: 0.6774\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5639 - accuracy: 0.7073 - val_loss: 0.5778 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6128 - accuracy: 0.7073 - val_loss: 0.5878 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5418 - accuracy: 0.7073 - val_loss: 0.6007 - val_accuracy: 0.7097\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5623 - accuracy: 0.7480 - val_loss: 0.3659 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6261 - accuracy: 0.7480 - val_loss: 0.4798 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5318 - accuracy: 0.7480 - val_loss: 0.5413 - val_accuracy: 0.9032\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5629 - accuracy: 0.7236 - val_loss: 0.5388 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6240 - accuracy: 0.7236 - val_loss: 0.5784 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5490 - accuracy: 0.7236 - val_loss: 0.6077 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5508 - accuracy: 0.7724 - val_loss: 0.5979 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5579 - accuracy: 0.7724 - val_loss: 0.5900 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5271 - accuracy: 0.7724 - val_loss: 0.6097 - val_accuracy: 0.7097\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5584 - accuracy: 0.7355 - val_loss: 0.4162 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5975 - accuracy: 0.7355 - val_loss: 0.5122 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5478 - accuracy: 0.7355 - val_loss: 0.5774 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5305 - accuracy: 0.7934 - val_loss: 0.5974 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5581 - accuracy: 0.7934 - val_loss: 0.5848 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4967 - accuracy: 0.7934 - val_loss: 0.5962 - val_accuracy: 0.6774\n",
            "Publisher: global iteration=9\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5713 - accuracy: 0.7154 - val_loss: 0.6002 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6741 - accuracy: 0.7154 - val_loss: 0.6171 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5732 - accuracy: 0.7154 - val_loss: 0.6528 - val_accuracy: 0.6774\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5359 - accuracy: 0.7805 - val_loss: 0.5850 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5422 - accuracy: 0.7805 - val_loss: 0.5692 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4838 - accuracy: 0.7805 - val_loss: 0.5864 - val_accuracy: 0.7097\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5316 - accuracy: 0.7805 - val_loss: 0.4252 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5705 - accuracy: 0.7805 - val_loss: 0.4736 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4985 - accuracy: 0.7805 - val_loss: 0.5328 - val_accuracy: 0.8387\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5637 - accuracy: 0.7154 - val_loss: 0.6065 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6278 - accuracy: 0.7154 - val_loss: 0.5879 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5358 - accuracy: 0.7154 - val_loss: 0.6231 - val_accuracy: 0.6774\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5710 - accuracy: 0.6911 - val_loss: 0.5510 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5913 - accuracy: 0.6911 - val_loss: 0.5887 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5580 - accuracy: 0.6911 - val_loss: 0.6018 - val_accuracy: 0.7419\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5775 - accuracy: 0.6911 - val_loss: 0.4600 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6536 - accuracy: 0.6911 - val_loss: 0.5434 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5713 - accuracy: 0.6911 - val_loss: 0.6148 - val_accuracy: 0.8065\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5320 - accuracy: 0.7603 - val_loss: 0.6144 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5510 - accuracy: 0.7603 - val_loss: 0.5834 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5011 - accuracy: 0.7603 - val_loss: 0.5968 - val_accuracy: 0.6774\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5298 - accuracy: 0.7724 - val_loss: 0.5301 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5986 - accuracy: 0.7724 - val_loss: 0.5420 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4951 - accuracy: 0.7724 - val_loss: 0.5729 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5484 - accuracy: 0.7724 - val_loss: 0.4345 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6260 - accuracy: 0.7724 - val_loss: 0.4897 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5278 - accuracy: 0.7724 - val_loss: 0.5456 - val_accuracy: 0.8387\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5596 - accuracy: 0.7317 - val_loss: 0.7245 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6255 - accuracy: 0.7317 - val_loss: 0.6449 - val_accuracy: 0.5484\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5506 - accuracy: 0.7317 - val_loss: 0.6415 - val_accuracy: 0.5484\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5650 - accuracy: 0.7073 - val_loss: 0.3795 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6127 - accuracy: 0.7073 - val_loss: 0.4917 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5493 - accuracy: 0.7073 - val_loss: 0.5659 - val_accuracy: 0.8710\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6155 - accuracy: 0.6529 - val_loss: 0.6031 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6166 - accuracy: 0.6529 - val_loss: 0.6338 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6168 - accuracy: 0.6529 - val_loss: 0.6052 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5724 - accuracy: 0.6777 - val_loss: 0.4708 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5722 - accuracy: 0.6777 - val_loss: 0.6156 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5745 - accuracy: 0.6777 - val_loss: 0.5455 - val_accuracy: 0.8710\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5832 - accuracy: 0.7236 - val_loss: 0.4234 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6018 - accuracy: 0.7236 - val_loss: 0.5173 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5610 - accuracy: 0.7236 - val_loss: 0.5627 - val_accuracy: 0.8710\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5478 - accuracy: 0.7686 - val_loss: 0.5123 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5945 - accuracy: 0.7686 - val_loss: 0.5340 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5230 - accuracy: 0.7686 - val_loss: 0.5733 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5506 - accuracy: 0.7480 - val_loss: 0.4955 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5961 - accuracy: 0.7480 - val_loss: 0.5312 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5229 - accuracy: 0.7480 - val_loss: 0.5821 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5369 - accuracy: 0.7521 - val_loss: 0.4609 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6281 - accuracy: 0.7521 - val_loss: 0.4969 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5067 - accuracy: 0.7521 - val_loss: 0.5477 - val_accuracy: 0.8065\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4963 - accuracy: 0.8182 - val_loss: 0.3990 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5126 - accuracy: 0.8182 - val_loss: 0.4265 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4614 - accuracy: 0.8182 - val_loss: 0.4850 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=10\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5715 - accuracy: 0.6829 - val_loss: 0.5079 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5783 - accuracy: 0.6829 - val_loss: 0.5941 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5901 - accuracy: 0.6829 - val_loss: 0.5738 - val_accuracy: 0.8065\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5051 - accuracy: 0.8099 - val_loss: 0.4916 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.5379 - accuracy: 0.8099 - val_loss: 0.4932 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4580 - accuracy: 0.8099 - val_loss: 0.5192 - val_accuracy: 0.7419\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5085 - accuracy: 0.7967 - val_loss: 0.4762 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5496 - accuracy: 0.7967 - val_loss: 0.4925 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4893 - accuracy: 0.7967 - val_loss: 0.5398 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.5319 - accuracy: 0.7355 - val_loss: 0.3403 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5736 - accuracy: 0.7355 - val_loss: 0.4366 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5015 - accuracy: 0.7355 - val_loss: 0.5322 - val_accuracy: 0.8710\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5540 - accuracy: 0.7236 - val_loss: 0.6186 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5918 - accuracy: 0.7236 - val_loss: 0.5889 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5432 - accuracy: 0.7236 - val_loss: 0.5980 - val_accuracy: 0.6129\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5432 - accuracy: 0.7317 - val_loss: 0.6130 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5875 - accuracy: 0.7317 - val_loss: 0.5856 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5321 - accuracy: 0.7317 - val_loss: 0.6006 - val_accuracy: 0.6774\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5657 - accuracy: 0.7398 - val_loss: 0.6253 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5943 - accuracy: 0.7398 - val_loss: 0.6009 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5712 - accuracy: 0.7398 - val_loss: 0.6159 - val_accuracy: 0.6129\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5134 - accuracy: 0.7724 - val_loss: 0.5321 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5976 - accuracy: 0.7724 - val_loss: 0.5308 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4972 - accuracy: 0.7724 - val_loss: 0.5622 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5103 - accuracy: 0.7805 - val_loss: 0.6850 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5507 - accuracy: 0.7805 - val_loss: 0.6291 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4890 - accuracy: 0.7805 - val_loss: 0.6230 - val_accuracy: 0.6129\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5725 - accuracy: 0.7154 - val_loss: 0.3882 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5996 - accuracy: 0.7154 - val_loss: 0.5045 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5538 - accuracy: 0.7154 - val_loss: 0.5232 - val_accuracy: 0.8710\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5912 - accuracy: 0.6911 - val_loss: 0.5240 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6220 - accuracy: 0.6911 - val_loss: 0.5567 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5766 - accuracy: 0.6911 - val_loss: 0.5845 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6166 - accuracy: 0.6423 - val_loss: 0.6375 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6248 - accuracy: 0.6423 - val_loss: 0.5314 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6182 - accuracy: 0.6423 - val_loss: 0.5493 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5162 - accuracy: 0.7398 - val_loss: 0.4603 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5533 - accuracy: 0.7398 - val_loss: 0.4788 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4895 - accuracy: 0.7398 - val_loss: 0.5431 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6060 - accuracy: 0.6260 - val_loss: 0.6077 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5948 - accuracy: 0.6260 - val_loss: 0.5651 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6168 - accuracy: 0.6260 - val_loss: 0.6126 - val_accuracy: 0.6774\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5299 - accuracy: 0.7480 - val_loss: 0.5555 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6069 - accuracy: 0.7480 - val_loss: 0.5595 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5175 - accuracy: 0.7480 - val_loss: 0.5916 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5424 - accuracy: 0.7561 - val_loss: 0.5177 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6061 - accuracy: 0.7561 - val_loss: 0.5306 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5236 - accuracy: 0.7561 - val_loss: 0.5705 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5850 - accuracy: 0.6667 - val_loss: 0.5402 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5637 - accuracy: 0.6667 - val_loss: 0.5350 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5510 - accuracy: 0.6667 - val_loss: 0.4887 - val_accuracy: 0.7419\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4685 - accuracy: 0.8347 - val_loss: 0.4892 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4790 - accuracy: 0.8347 - val_loss: 0.4835 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4346 - accuracy: 0.8347 - val_loss: 0.5068 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=11\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5127 - accuracy: 0.7398 - val_loss: 0.7646 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6364 - accuracy: 0.7398 - val_loss: 0.6315 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5267 - accuracy: 0.7398 - val_loss: 0.6060 - val_accuracy: 0.5806\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5015 - accuracy: 0.7769 - val_loss: 0.3213 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5457 - accuracy: 0.7769 - val_loss: 0.3854 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4643 - accuracy: 0.7769 - val_loss: 0.4504 - val_accuracy: 0.8710\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4908 - accuracy: 0.7724 - val_loss: 0.5055 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5902 - accuracy: 0.7724 - val_loss: 0.5142 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4745 - accuracy: 0.7724 - val_loss: 0.5573 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4831 - accuracy: 0.7603 - val_loss: 0.4428 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5202 - accuracy: 0.7603 - val_loss: 0.4917 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4247 - accuracy: 0.7603 - val_loss: 0.5463 - val_accuracy: 0.7742\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5268 - accuracy: 0.7154 - val_loss: 0.5387 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4994 - accuracy: 0.7154 - val_loss: 0.5116 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4890 - accuracy: 0.7154 - val_loss: 0.5751 - val_accuracy: 0.7097\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5348 - accuracy: 0.7236 - val_loss: 0.7279 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5374 - accuracy: 0.7236 - val_loss: 0.6718 - val_accuracy: 0.5484\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5439 - accuracy: 0.7236 - val_loss: 0.6730 - val_accuracy: 0.5484\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4863 - accuracy: 0.7886 - val_loss: 0.5845 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6050 - accuracy: 0.7886 - val_loss: 0.5500 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4708 - accuracy: 0.7886 - val_loss: 0.5692 - val_accuracy: 0.6774\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4965 - accuracy: 0.7805 - val_loss: 0.5019 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5617 - accuracy: 0.7805 - val_loss: 0.4950 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4762 - accuracy: 0.7805 - val_loss: 0.5373 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5447 - accuracy: 0.7236 - val_loss: 0.3969 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5608 - accuracy: 0.7236 - val_loss: 0.5541 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5734 - accuracy: 0.7236 - val_loss: 0.5135 - val_accuracy: 0.8387\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5310 - accuracy: 0.7273 - val_loss: 0.5446 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5529 - accuracy: 0.7273 - val_loss: 0.5453 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4963 - accuracy: 0.7273 - val_loss: 0.5504 - val_accuracy: 0.7419\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4780 - accuracy: 0.7561 - val_loss: 0.5083 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5606 - accuracy: 0.7561 - val_loss: 0.5003 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4446 - accuracy: 0.7561 - val_loss: 0.5380 - val_accuracy: 0.7742\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6050 - accuracy: 0.6364 - val_loss: 0.6599 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6439 - accuracy: 0.6364 - val_loss: 0.6009 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6068 - accuracy: 0.6364 - val_loss: 0.5548 - val_accuracy: 0.7097\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5234 - accuracy: 0.7355 - val_loss: 0.5726 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5574 - accuracy: 0.7355 - val_loss: 0.5598 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5062 - accuracy: 0.7355 - val_loss: 0.5621 - val_accuracy: 0.6452\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.4488 - accuracy: 0.7934 - val_loss: 0.4779 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5095 - accuracy: 0.7934 - val_loss: 0.4655 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4162 - accuracy: 0.7934 - val_loss: 0.4909 - val_accuracy: 0.7742\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5348 - accuracy: 0.7317 - val_loss: 0.4851 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5998 - accuracy: 0.7317 - val_loss: 0.5025 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5164 - accuracy: 0.7317 - val_loss: 0.5598 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5192 - accuracy: 0.7805 - val_loss: 0.6674 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5204 - accuracy: 0.7805 - val_loss: 0.6185 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4758 - accuracy: 0.7805 - val_loss: 0.6311 - val_accuracy: 0.6774\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5904 - accuracy: 0.6585 - val_loss: 0.6047 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6066 - accuracy: 0.6585 - val_loss: 0.5044 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5777 - accuracy: 0.6585 - val_loss: 0.4750 - val_accuracy: 0.7742\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4510 - accuracy: 0.8430 - val_loss: 0.5659 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4460 - accuracy: 0.8430 - val_loss: 0.5349 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3951 - accuracy: 0.8430 - val_loss: 0.5334 - val_accuracy: 0.7419\n",
            "Publisher: global iteration=12\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5385 - accuracy: 0.6992 - val_loss: 0.5226 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5277 - accuracy: 0.6992 - val_loss: 0.5126 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5020 - accuracy: 0.6992 - val_loss: 0.5041 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5404 - accuracy: 0.7073 - val_loss: 0.4274 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6415 - accuracy: 0.7073 - val_loss: 0.4889 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5504 - accuracy: 0.7073 - val_loss: 0.5546 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4812 - accuracy: 0.7724 - val_loss: 0.5054 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6117 - accuracy: 0.7724 - val_loss: 0.4856 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4903 - accuracy: 0.7724 - val_loss: 0.5244 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5440 - accuracy: 0.6992 - val_loss: 0.4789 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6153 - accuracy: 0.6992 - val_loss: 0.5371 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5584 - accuracy: 0.6992 - val_loss: 0.5837 - val_accuracy: 0.7742\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4595 - accuracy: 0.7967 - val_loss: 0.4801 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5323 - accuracy: 0.7967 - val_loss: 0.4706 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4589 - accuracy: 0.7967 - val_loss: 0.5119 - val_accuracy: 0.8065\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5671 - accuracy: 0.6748 - val_loss: 0.5956 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5754 - accuracy: 0.6748 - val_loss: 0.4686 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6098 - accuracy: 0.6748 - val_loss: 0.5049 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.4640 - accuracy: 0.7642 - val_loss: 0.5387 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5342 - accuracy: 0.7642 - val_loss: 0.4939 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4476 - accuracy: 0.7642 - val_loss: 0.5254 - val_accuracy: 0.7419\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5405 - accuracy: 0.7273 - val_loss: 0.4771 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5380 - accuracy: 0.7273 - val_loss: 0.6050 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5653 - accuracy: 0.7273 - val_loss: 0.5425 - val_accuracy: 0.8065\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.5122 - accuracy: 0.7273 - val_loss: 0.4206 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4854 - accuracy: 0.7273 - val_loss: 0.4904 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5034 - accuracy: 0.7273 - val_loss: 0.4026 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5161 - accuracy: 0.7273 - val_loss: 0.5529 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6470 - accuracy: 0.7273 - val_loss: 0.5555 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5018 - accuracy: 0.7273 - val_loss: 0.5997 - val_accuracy: 0.7419\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4928 - accuracy: 0.7561 - val_loss: 0.5616 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5231 - accuracy: 0.7561 - val_loss: 0.5373 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4573 - accuracy: 0.7561 - val_loss: 0.5651 - val_accuracy: 0.6774\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5420 - accuracy: 0.6694 - val_loss: 0.6490 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5732 - accuracy: 0.6694 - val_loss: 0.6617 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5980 - accuracy: 0.6694 - val_loss: 0.6474 - val_accuracy: 0.5806\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 0.5382 - accuracy: 0.7025 - val_loss: 0.3877 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5687 - accuracy: 0.7025 - val_loss: 0.4560 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5195 - accuracy: 0.7025 - val_loss: 0.4665 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4651 - accuracy: 0.7805 - val_loss: 0.4002 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5613 - accuracy: 0.7805 - val_loss: 0.4214 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4897 - accuracy: 0.7805 - val_loss: 0.4919 - val_accuracy: 0.7742\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5142 - accuracy: 0.7317 - val_loss: 0.5750 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6168 - accuracy: 0.7317 - val_loss: 0.5342 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5068 - accuracy: 0.7317 - val_loss: 0.5842 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4901 - accuracy: 0.7561 - val_loss: 0.3783 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5323 - accuracy: 0.7561 - val_loss: 0.4346 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4611 - accuracy: 0.7561 - val_loss: 0.5453 - val_accuracy: 0.8387\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5588 - accuracy: 0.6992 - val_loss: 0.5444 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5224 - accuracy: 0.6992 - val_loss: 0.5387 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.5353 - accuracy: 0.6992 - val_loss: 0.5584 - val_accuracy: 0.6129\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5783 - accuracy: 0.6612 - val_loss: 0.5848 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5672 - accuracy: 0.6612 - val_loss: 0.5580 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6328 - accuracy: 0.6612 - val_loss: 0.5604 - val_accuracy: 0.7097\n",
            "Publisher: global iteration=13\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5030 - accuracy: 0.7317 - val_loss: 0.7855 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6784 - accuracy: 0.7317 - val_loss: 0.6322 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5036 - accuracy: 0.7317 - val_loss: 0.6080 - val_accuracy: 0.6129\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5291 - accuracy: 0.7398 - val_loss: 0.6473 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6459 - accuracy: 0.7398 - val_loss: 0.5656 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5526 - accuracy: 0.7398 - val_loss: 0.5770 - val_accuracy: 0.6774\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.5009 - accuracy: 0.7480 - val_loss: 0.5088 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6197 - accuracy: 0.7480 - val_loss: 0.4954 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.4741 - accuracy: 0.7480 - val_loss: 0.5550 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4947 - accuracy: 0.7642 - val_loss: 0.4340 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6281 - accuracy: 0.7642 - val_loss: 0.4574 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5033 - accuracy: 0.7642 - val_loss: 0.5280 - val_accuracy: 0.8065\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4959 - accuracy: 0.7769 - val_loss: 0.3728 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5894 - accuracy: 0.7769 - val_loss: 0.4010 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4859 - accuracy: 0.7769 - val_loss: 0.4623 - val_accuracy: 0.8387\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5230 - accuracy: 0.7236 - val_loss: 0.5608 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5948 - accuracy: 0.7236 - val_loss: 0.5346 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5196 - accuracy: 0.7236 - val_loss: 0.5673 - val_accuracy: 0.7097\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5320 - accuracy: 0.7154 - val_loss: 0.5234 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5911 - accuracy: 0.7154 - val_loss: 0.5960 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5663 - accuracy: 0.7154 - val_loss: 0.5887 - val_accuracy: 0.7097\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5129 - accuracy: 0.7851 - val_loss: 0.7983 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5782 - accuracy: 0.7851 - val_loss: 0.6780 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4780 - accuracy: 0.7851 - val_loss: 0.6282 - val_accuracy: 0.5806\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4853 - accuracy: 0.7355 - val_loss: 0.4355 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6149 - accuracy: 0.7355 - val_loss: 0.5092 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4782 - accuracy: 0.7355 - val_loss: 0.5692 - val_accuracy: 0.7742\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4959 - accuracy: 0.7438 - val_loss: 0.6429 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6535 - accuracy: 0.7438 - val_loss: 0.5691 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5309 - accuracy: 0.7438 - val_loss: 0.5777 - val_accuracy: 0.6774\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4887 - accuracy: 0.7686 - val_loss: 0.5728 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5814 - accuracy: 0.7686 - val_loss: 0.5412 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4712 - accuracy: 0.7686 - val_loss: 0.5617 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5749 - accuracy: 0.6585 - val_loss: 0.5460 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5826 - accuracy: 0.6585 - val_loss: 0.5136 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5733 - accuracy: 0.6585 - val_loss: 0.5242 - val_accuracy: 0.6774\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5255 - accuracy: 0.7317 - val_loss: 0.5153 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6675 - accuracy: 0.7317 - val_loss: 0.4925 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5397 - accuracy: 0.7317 - val_loss: 0.5406 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5168 - accuracy: 0.7561 - val_loss: 0.5638 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6218 - accuracy: 0.7561 - val_loss: 0.5283 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5384 - accuracy: 0.7561 - val_loss: 0.5582 - val_accuracy: 0.7419\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5497 - accuracy: 0.6992 - val_loss: 0.5124 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6133 - accuracy: 0.6992 - val_loss: 0.4974 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5320 - accuracy: 0.6992 - val_loss: 0.5244 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4655 - accuracy: 0.7480 - val_loss: 0.3827 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6620 - accuracy: 0.7480 - val_loss: 0.3819 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4831 - accuracy: 0.7480 - val_loss: 0.4425 - val_accuracy: 0.8710\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5051 - accuracy: 0.7642 - val_loss: 0.5526 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5909 - accuracy: 0.7642 - val_loss: 0.5266 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4687 - accuracy: 0.7642 - val_loss: 0.5525 - val_accuracy: 0.7097\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4802 - accuracy: 0.7603 - val_loss: 0.3602 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5959 - accuracy: 0.7603 - val_loss: 0.3803 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4765 - accuracy: 0.7603 - val_loss: 0.4543 - val_accuracy: 0.8065\n",
            "Publisher: global iteration=14\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.5683 - accuracy: 0.7073 - val_loss: 0.5276 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5565 - accuracy: 0.7073 - val_loss: 0.5354 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5483 - accuracy: 0.7073 - val_loss: 0.5238 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4744 - accuracy: 0.7642 - val_loss: 0.4563 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5611 - accuracy: 0.7642 - val_loss: 0.4531 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4523 - accuracy: 0.7642 - val_loss: 0.4922 - val_accuracy: 0.7742\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4753 - accuracy: 0.7561 - val_loss: 0.4035 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5442 - accuracy: 0.7561 - val_loss: 0.4202 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4674 - accuracy: 0.7561 - val_loss: 0.4771 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.4913 - accuracy: 0.7561 - val_loss: 0.4379 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5172 - accuracy: 0.7561 - val_loss: 0.4995 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4902 - accuracy: 0.7561 - val_loss: 0.4871 - val_accuracy: 0.8387\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5130 - accuracy: 0.6992 - val_loss: 0.4683 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4859 - accuracy: 0.6992 - val_loss: 0.4330 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5857 - accuracy: 0.6992 - val_loss: 0.4411 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5544 - accuracy: 0.6911 - val_loss: 0.5631 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5432 - accuracy: 0.6911 - val_loss: 0.5609 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5326 - accuracy: 0.6911 - val_loss: 0.5837 - val_accuracy: 0.6774\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4922 - accuracy: 0.7355 - val_loss: 0.4977 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5355 - accuracy: 0.7355 - val_loss: 0.4926 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4867 - accuracy: 0.7355 - val_loss: 0.5234 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4715 - accuracy: 0.7480 - val_loss: 0.6719 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4912 - accuracy: 0.7480 - val_loss: 0.5453 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4250 - accuracy: 0.7480 - val_loss: 0.5384 - val_accuracy: 0.6452\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5076 - accuracy: 0.7642 - val_loss: 0.3214 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5532 - accuracy: 0.7642 - val_loss: 0.3970 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4939 - accuracy: 0.7642 - val_loss: 0.4422 - val_accuracy: 0.8710\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5097 - accuracy: 0.7642 - val_loss: 0.3185 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5480 - accuracy: 0.7642 - val_loss: 0.3987 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - accuracy: 0.7642 - val_loss: 0.4316 - val_accuracy: 0.8387\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5084 - accuracy: 0.7686 - val_loss: 0.5727 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5016 - accuracy: 0.7686 - val_loss: 0.5309 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4630 - accuracy: 0.7686 - val_loss: 0.5361 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5175 - accuracy: 0.7317 - val_loss: 0.5986 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5186 - accuracy: 0.7317 - val_loss: 0.5587 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5014 - accuracy: 0.7317 - val_loss: 0.5612 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4916 - accuracy: 0.7236 - val_loss: 0.3397 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4909 - accuracy: 0.7236 - val_loss: 0.4604 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4695 - accuracy: 0.7236 - val_loss: 0.3810 - val_accuracy: 0.8387\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4535 - accuracy: 0.7769 - val_loss: 0.3420 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4748 - accuracy: 0.7769 - val_loss: 0.3573 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4095 - accuracy: 0.7769 - val_loss: 0.4104 - val_accuracy: 0.8387\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5109 - accuracy: 0.7398 - val_loss: 0.4654 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5338 - accuracy: 0.7398 - val_loss: 0.4833 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5039 - accuracy: 0.7398 - val_loss: 0.5067 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5240 - accuracy: 0.7561 - val_loss: 0.4656 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5062 - accuracy: 0.7561 - val_loss: 0.5381 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5049 - accuracy: 0.7561 - val_loss: 0.4808 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5392 - accuracy: 0.6667 - val_loss: 0.5243 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5254 - accuracy: 0.6667 - val_loss: 0.4854 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5419 - accuracy: 0.6667 - val_loss: 0.5300 - val_accuracy: 0.7419\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.4871 - accuracy: 0.7438 - val_loss: 0.3131 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4618 - accuracy: 0.7438 - val_loss: 0.4611 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4558 - accuracy: 0.7438 - val_loss: 0.3782 - val_accuracy: 0.8710\n",
            "Publisher: global iteration=15\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5040 - accuracy: 0.7073 - val_loss: 0.7122 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6155 - accuracy: 0.7073 - val_loss: 0.5844 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4916 - accuracy: 0.7073 - val_loss: 0.5807 - val_accuracy: 0.6774\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4546 - accuracy: 0.7851 - val_loss: 0.3936 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5516 - accuracy: 0.7851 - val_loss: 0.3924 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4219 - accuracy: 0.7851 - val_loss: 0.4487 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4741 - accuracy: 0.7886 - val_loss: 0.4395 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5311 - accuracy: 0.7886 - val_loss: 0.4396 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4474 - accuracy: 0.7886 - val_loss: 0.4891 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4254 - accuracy: 0.7686 - val_loss: 0.5290 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6008 - accuracy: 0.7686 - val_loss: 0.4801 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4283 - accuracy: 0.7686 - val_loss: 0.5357 - val_accuracy: 0.7419\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4701 - accuracy: 0.6911 - val_loss: 0.5670 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5303 - accuracy: 0.6911 - val_loss: 0.4316 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6262 - accuracy: 0.6911 - val_loss: 0.4538 - val_accuracy: 0.8065\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5239 - accuracy: 0.7154 - val_loss: 0.4836 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5719 - accuracy: 0.7154 - val_loss: 0.4864 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5080 - accuracy: 0.7154 - val_loss: 0.5218 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4991 - accuracy: 0.7355 - val_loss: 0.4551 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5639 - accuracy: 0.7355 - val_loss: 0.4234 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4803 - accuracy: 0.7355 - val_loss: 0.4693 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4977 - accuracy: 0.7236 - val_loss: 0.5459 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5463 - accuracy: 0.7236 - val_loss: 0.5278 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4855 - accuracy: 0.7236 - val_loss: 0.5405 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5206 - accuracy: 0.6992 - val_loss: 0.4572 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5874 - accuracy: 0.6992 - val_loss: 0.5479 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5474 - accuracy: 0.6992 - val_loss: 0.5584 - val_accuracy: 0.7742\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4828 - accuracy: 0.7355 - val_loss: 0.5805 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5515 - accuracy: 0.7355 - val_loss: 0.5769 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4771 - accuracy: 0.7355 - val_loss: 0.5922 - val_accuracy: 0.7097\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4684 - accuracy: 0.7398 - val_loss: 0.4260 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5148 - accuracy: 0.7398 - val_loss: 0.4659 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4827 - accuracy: 0.7398 - val_loss: 0.5030 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5742 - accuracy: 0.6179 - val_loss: 0.5953 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6445 - accuracy: 0.6179 - val_loss: 0.5272 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5947 - accuracy: 0.6179 - val_loss: 0.5239 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5032 - accuracy: 0.7154 - val_loss: 0.3783 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6845 - accuracy: 0.7154 - val_loss: 0.4202 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5103 - accuracy: 0.7154 - val_loss: 0.5126 - val_accuracy: 0.8065\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.4868 - accuracy: 0.7561 - val_loss: 0.6502 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6417 - accuracy: 0.7561 - val_loss: 0.5742 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4846 - accuracy: 0.7561 - val_loss: 0.5864 - val_accuracy: 0.7419\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4972 - accuracy: 0.7154 - val_loss: 0.5391 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5804 - accuracy: 0.7154 - val_loss: 0.5401 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5155 - accuracy: 0.7154 - val_loss: 0.5760 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.4265 - accuracy: 0.7851 - val_loss: 0.5007 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5218 - accuracy: 0.7851 - val_loss: 0.4529 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4444 - accuracy: 0.7851 - val_loss: 0.4680 - val_accuracy: 0.7097\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4958 - accuracy: 0.7805 - val_loss: 0.5572 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6183 - accuracy: 0.7805 - val_loss: 0.5276 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4800 - accuracy: 0.7805 - val_loss: 0.5563 - val_accuracy: 0.8065\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.4439 - accuracy: 0.7521 - val_loss: 0.3296 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6452 - accuracy: 0.7521 - val_loss: 0.3422 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4601 - accuracy: 0.7521 - val_loss: 0.4342 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=16\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5267 - accuracy: 0.7073 - val_loss: 0.5409 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4890 - accuracy: 0.7073 - val_loss: 0.5453 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5277 - accuracy: 0.7073 - val_loss: 0.5343 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4675 - accuracy: 0.7724 - val_loss: 0.4987 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4583 - accuracy: 0.7724 - val_loss: 0.4626 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4418 - accuracy: 0.7724 - val_loss: 0.5036 - val_accuracy: 0.7419\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5054 - accuracy: 0.7561 - val_loss: 0.4778 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5090 - accuracy: 0.7561 - val_loss: 0.5042 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4903 - accuracy: 0.7561 - val_loss: 0.4975 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5391 - accuracy: 0.6829 - val_loss: 0.4480 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5348 - accuracy: 0.6829 - val_loss: 0.4068 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5417 - accuracy: 0.6829 - val_loss: 0.5201 - val_accuracy: 0.8387\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5358 - accuracy: 0.6911 - val_loss: 0.4379 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5099 - accuracy: 0.6911 - val_loss: 0.5086 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5351 - accuracy: 0.6911 - val_loss: 0.4576 - val_accuracy: 0.7419\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5664 - accuracy: 0.6529 - val_loss: 0.4854 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5500 - accuracy: 0.6529 - val_loss: 0.4073 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6077 - accuracy: 0.6529 - val_loss: 0.4974 - val_accuracy: 0.8065\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4577 - accuracy: 0.7724 - val_loss: 0.5123 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5830 - accuracy: 0.7724 - val_loss: 0.4756 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4472 - accuracy: 0.7724 - val_loss: 0.5120 - val_accuracy: 0.7419\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5074 - accuracy: 0.7236 - val_loss: 0.4891 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5812 - accuracy: 0.7236 - val_loss: 0.4831 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4914 - accuracy: 0.7236 - val_loss: 0.5170 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.4787 - accuracy: 0.7603 - val_loss: 0.5078 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4813 - accuracy: 0.7603 - val_loss: 0.5019 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4745 - accuracy: 0.7603 - val_loss: 0.4747 - val_accuracy: 0.6774\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5312 - accuracy: 0.7107 - val_loss: 0.3959 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5256 - accuracy: 0.7107 - val_loss: 0.4570 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5193 - accuracy: 0.7107 - val_loss: 0.4205 - val_accuracy: 0.8065\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5388 - accuracy: 0.6911 - val_loss: 0.5988 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5957 - accuracy: 0.6911 - val_loss: 0.5658 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5386 - accuracy: 0.6911 - val_loss: 0.5945 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4907 - accuracy: 0.6992 - val_loss: 0.5494 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6021 - accuracy: 0.6992 - val_loss: 0.5132 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5025 - accuracy: 0.6992 - val_loss: 0.5567 - val_accuracy: 0.7742\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4412 - accuracy: 0.7561 - val_loss: 0.4869 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4893 - accuracy: 0.7561 - val_loss: 0.4414 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4075 - accuracy: 0.7561 - val_loss: 0.5095 - val_accuracy: 0.7097\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4978 - accuracy: 0.7805 - val_loss: 0.6687 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5633 - accuracy: 0.7805 - val_loss: 0.5738 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4803 - accuracy: 0.7805 - val_loss: 0.5666 - val_accuracy: 0.6452\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5170 - accuracy: 0.7236 - val_loss: 0.4431 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5195 - accuracy: 0.7236 - val_loss: 0.5426 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5257 - accuracy: 0.7236 - val_loss: 0.4675 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4706 - accuracy: 0.7805 - val_loss: 0.7143 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5088 - accuracy: 0.7805 - val_loss: 0.5980 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4297 - accuracy: 0.7805 - val_loss: 0.5782 - val_accuracy: 0.6774\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5211 - accuracy: 0.6911 - val_loss: 0.5618 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5086 - accuracy: 0.6911 - val_loss: 0.5778 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4836 - accuracy: 0.6911 - val_loss: 0.5501 - val_accuracy: 0.6452\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4406 - accuracy: 0.7934 - val_loss: 0.1946 - val_accuracy: 0.9355\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5093 - accuracy: 0.7934 - val_loss: 0.2532 - val_accuracy: 0.9355\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4205 - accuracy: 0.7934 - val_loss: 0.3470 - val_accuracy: 0.9355\n",
            "Publisher: global iteration=17\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5428 - accuracy: 0.7073 - val_loss: 0.5685 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5495 - accuracy: 0.7073 - val_loss: 0.5181 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5460 - accuracy: 0.7073 - val_loss: 0.5316 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4902 - accuracy: 0.6829 - val_loss: 0.4049 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5215 - accuracy: 0.6829 - val_loss: 0.4487 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4750 - accuracy: 0.6829 - val_loss: 0.4483 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4456 - accuracy: 0.8049 - val_loss: 0.6559 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5082 - accuracy: 0.8049 - val_loss: 0.5635 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4173 - accuracy: 0.8049 - val_loss: 0.5492 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4654 - accuracy: 0.7724 - val_loss: 0.4106 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5022 - accuracy: 0.7724 - val_loss: 0.4355 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4655 - accuracy: 0.7724 - val_loss: 0.4925 - val_accuracy: 0.7742\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4348 - accuracy: 0.8049 - val_loss: 0.5325 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4887 - accuracy: 0.8049 - val_loss: 0.4937 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4186 - accuracy: 0.8049 - val_loss: 0.5091 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5625 - accuracy: 0.6667 - val_loss: 0.5174 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5645 - accuracy: 0.6667 - val_loss: 0.4848 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5508 - accuracy: 0.6667 - val_loss: 0.5086 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4714 - accuracy: 0.7154 - val_loss: 0.7382 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6138 - accuracy: 0.7154 - val_loss: 0.6000 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4628 - accuracy: 0.7154 - val_loss: 0.6225 - val_accuracy: 0.7097\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5023 - accuracy: 0.6911 - val_loss: 0.4027 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5228 - accuracy: 0.6911 - val_loss: 0.5502 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5404 - accuracy: 0.6911 - val_loss: 0.4354 - val_accuracy: 0.8710\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4488 - accuracy: 0.7724 - val_loss: 0.7246 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5788 - accuracy: 0.7724 - val_loss: 0.5823 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4429 - accuracy: 0.7724 - val_loss: 0.5564 - val_accuracy: 0.6452\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4757 - accuracy: 0.7686 - val_loss: 0.7383 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5173 - accuracy: 0.7686 - val_loss: 0.6023 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4608 - accuracy: 0.7686 - val_loss: 0.5734 - val_accuracy: 0.5806\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4767 - accuracy: 0.7521 - val_loss: 0.4704 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5929 - accuracy: 0.7521 - val_loss: 0.4543 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4760 - accuracy: 0.7521 - val_loss: 0.5108 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4934 - accuracy: 0.7317 - val_loss: 0.5364 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5686 - accuracy: 0.7317 - val_loss: 0.5370 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5022 - accuracy: 0.7317 - val_loss: 0.5802 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.4931 - accuracy: 0.7154 - val_loss: 0.5114 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5535 - accuracy: 0.7154 - val_loss: 0.5645 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5007 - accuracy: 0.7154 - val_loss: 0.5663 - val_accuracy: 0.8065\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4512 - accuracy: 0.7561 - val_loss: 0.2982 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5667 - accuracy: 0.7561 - val_loss: 0.3133 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4421 - accuracy: 0.7561 - val_loss: 0.4350 - val_accuracy: 0.8710\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4811 - accuracy: 0.7398 - val_loss: 0.4640 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5137 - accuracy: 0.7398 - val_loss: 0.4860 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4975 - accuracy: 0.7398 - val_loss: 0.4969 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4923 - accuracy: 0.7561 - val_loss: 0.4096 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5972 - accuracy: 0.7561 - val_loss: 0.4243 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4909 - accuracy: 0.7561 - val_loss: 0.4780 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5179 - accuracy: 0.7642 - val_loss: 0.4074 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4995 - accuracy: 0.7642 - val_loss: 0.5078 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5170 - accuracy: 0.7642 - val_loss: 0.4421 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4317 - accuracy: 0.7934 - val_loss: 0.3539 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5503 - accuracy: 0.7934 - val_loss: 0.3666 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4525 - accuracy: 0.7934 - val_loss: 0.4469 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=18\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5314 - accuracy: 0.6748 - val_loss: 0.4393 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5334 - accuracy: 0.6748 - val_loss: 0.3524 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5721 - accuracy: 0.6748 - val_loss: 0.4009 - val_accuracy: 0.8387\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4403 - accuracy: 0.7398 - val_loss: 0.3644 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5215 - accuracy: 0.7398 - val_loss: 0.4201 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4615 - accuracy: 0.7398 - val_loss: 0.5243 - val_accuracy: 0.8710\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4714 - accuracy: 0.7398 - val_loss: 0.4298 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4988 - accuracy: 0.7398 - val_loss: 0.5360 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5105 - accuracy: 0.7398 - val_loss: 0.4912 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4349 - accuracy: 0.7521 - val_loss: 0.3543 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5018 - accuracy: 0.7521 - val_loss: 0.4415 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4137 - accuracy: 0.7521 - val_loss: 0.5051 - val_accuracy: 0.8065\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4911 - accuracy: 0.7521 - val_loss: 0.2598 - val_accuracy: 0.9355\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4743 - accuracy: 0.7521 - val_loss: 0.4585 - val_accuracy: 0.9355\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4861 - accuracy: 0.7521 - val_loss: 0.2791 - val_accuracy: 0.9355\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5544 - accuracy: 0.6612 - val_loss: 0.5622 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5821 - accuracy: 0.6612 - val_loss: 0.4791 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5194 - accuracy: 0.6612 - val_loss: 0.4664 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4854 - accuracy: 0.7398 - val_loss: 0.3879 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4820 - accuracy: 0.7398 - val_loss: 0.5041 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4820 - accuracy: 0.7398 - val_loss: 0.4240 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5214 - accuracy: 0.7355 - val_loss: 0.4631 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4711 - accuracy: 0.7355 - val_loss: 0.5346 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4831 - accuracy: 0.7355 - val_loss: 0.4570 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4514 - accuracy: 0.7642 - val_loss: 0.6348 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5007 - accuracy: 0.7642 - val_loss: 0.5343 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4505 - accuracy: 0.7642 - val_loss: 0.5317 - val_accuracy: 0.6774\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5023 - accuracy: 0.7107 - val_loss: 0.5572 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5147 - accuracy: 0.7107 - val_loss: 0.4623 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4896 - accuracy: 0.7107 - val_loss: 0.5076 - val_accuracy: 0.8065\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4622 - accuracy: 0.7480 - val_loss: 0.3485 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5201 - accuracy: 0.7480 - val_loss: 0.3540 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4657 - accuracy: 0.7480 - val_loss: 0.4250 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5457 - accuracy: 0.6504 - val_loss: 0.6184 - val_accuracy: 0.5161\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5475 - accuracy: 0.6504 - val_loss: 0.6122 - val_accuracy: 0.5161\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5463 - accuracy: 0.6504 - val_loss: 0.6026 - val_accuracy: 0.5161\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4462 - accuracy: 0.7438 - val_loss: 0.6925 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5213 - accuracy: 0.7438 - val_loss: 0.5598 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4279 - accuracy: 0.7438 - val_loss: 0.5657 - val_accuracy: 0.6129\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4179 - accuracy: 0.7686 - val_loss: 0.2706 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4772 - accuracy: 0.7686 - val_loss: 0.3475 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3821 - accuracy: 0.7686 - val_loss: 0.4243 - val_accuracy: 0.8710\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4592 - accuracy: 0.7642 - val_loss: 0.6349 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4623 - accuracy: 0.7642 - val_loss: 0.5795 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4603 - accuracy: 0.7642 - val_loss: 0.5730 - val_accuracy: 0.6774\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4213 - accuracy: 0.7686 - val_loss: 0.4275 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4974 - accuracy: 0.7686 - val_loss: 0.4308 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3948 - accuracy: 0.7686 - val_loss: 0.4870 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5158 - accuracy: 0.7886 - val_loss: 0.4408 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4852 - accuracy: 0.7886 - val_loss: 0.4536 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4460 - accuracy: 0.7886 - val_loss: 0.4434 - val_accuracy: 0.7742\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4452 - accuracy: 0.7521 - val_loss: 0.3122 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4960 - accuracy: 0.7521 - val_loss: 0.3395 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4222 - accuracy: 0.7521 - val_loss: 0.3888 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=19\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4888 - accuracy: 0.6992 - val_loss: 0.5242 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4983 - accuracy: 0.6992 - val_loss: 0.4985 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4909 - accuracy: 0.6992 - val_loss: 0.5697 - val_accuracy: 0.7419\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4477 - accuracy: 0.7686 - val_loss: 0.2271 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5580 - accuracy: 0.7686 - val_loss: 0.2899 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4064 - accuracy: 0.7686 - val_loss: 0.3921 - val_accuracy: 0.9032\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4132 - accuracy: 0.7851 - val_loss: 0.5720 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5529 - accuracy: 0.7851 - val_loss: 0.4968 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4159 - accuracy: 0.7851 - val_loss: 0.5430 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5355 - accuracy: 0.6667 - val_loss: 0.3263 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5737 - accuracy: 0.6667 - val_loss: 0.4853 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5284 - accuracy: 0.6667 - val_loss: 0.4961 - val_accuracy: 0.8710\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4100 - accuracy: 0.8211 - val_loss: 0.6375 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5870 - accuracy: 0.8211 - val_loss: 0.5076 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3704 - accuracy: 0.8211 - val_loss: 0.5066 - val_accuracy: 0.7097\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 0.5061 - accuracy: 0.7073 - val_loss: 0.5849 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4944 - accuracy: 0.7073 - val_loss: 0.5852 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5478 - accuracy: 0.7073 - val_loss: 0.5884 - val_accuracy: 0.6129\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4744 - accuracy: 0.7273 - val_loss: 0.5328 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4933 - accuracy: 0.7273 - val_loss: 0.4276 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5115 - accuracy: 0.7273 - val_loss: 0.4470 - val_accuracy: 0.8065\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4731 - accuracy: 0.7317 - val_loss: 0.5786 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5603 - accuracy: 0.7317 - val_loss: 0.4843 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4968 - accuracy: 0.7317 - val_loss: 0.4967 - val_accuracy: 0.7097\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4408 - accuracy: 0.7805 - val_loss: 0.4581 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.6298 - accuracy: 0.7805 - val_loss: 0.4175 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4481 - accuracy: 0.7805 - val_loss: 0.4811 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4325 - accuracy: 0.7967 - val_loss: 0.6180 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5371 - accuracy: 0.7967 - val_loss: 0.5019 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4067 - accuracy: 0.7967 - val_loss: 0.5092 - val_accuracy: 0.7097\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4475 - accuracy: 0.7317 - val_loss: 0.4712 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4611 - accuracy: 0.7317 - val_loss: 0.4955 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4720 - accuracy: 0.7317 - val_loss: 0.4755 - val_accuracy: 0.7742\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4841 - accuracy: 0.6911 - val_loss: 0.6682 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4924 - accuracy: 0.6911 - val_loss: 0.7996 - val_accuracy: 0.5484\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4885 - accuracy: 0.6911 - val_loss: 0.6501 - val_accuracy: 0.5484\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4997 - accuracy: 0.7073 - val_loss: 0.3938 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5897 - accuracy: 0.7073 - val_loss: 0.4941 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5198 - accuracy: 0.7073 - val_loss: 0.5553 - val_accuracy: 0.8387\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4038 - accuracy: 0.7851 - val_loss: 0.3446 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4995 - accuracy: 0.7851 - val_loss: 0.3516 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3628 - accuracy: 0.7851 - val_loss: 0.4037 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4774 - accuracy: 0.7686 - val_loss: 0.3824 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5287 - accuracy: 0.7686 - val_loss: 0.4760 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4921 - accuracy: 0.7686 - val_loss: 0.4966 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5110 - accuracy: 0.7398 - val_loss: 0.5329 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5374 - accuracy: 0.7398 - val_loss: 0.4232 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5101 - accuracy: 0.7398 - val_loss: 0.4223 - val_accuracy: 0.8387\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5215 - accuracy: 0.7642 - val_loss: 0.4647 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5052 - accuracy: 0.7642 - val_loss: 0.3820 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5438 - accuracy: 0.7642 - val_loss: 0.4190 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5928 - accuracy: 0.6529 - val_loss: 0.6353 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.6512 - accuracy: 0.6529 - val_loss: 0.5858 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6210 - accuracy: 0.6529 - val_loss: 0.4886 - val_accuracy: 0.7419\n",
            "Publisher: global iteration=20\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4491 - accuracy: 0.7355 - val_loss: 0.5269 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5664 - accuracy: 0.7355 - val_loss: 0.4700 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4275 - accuracy: 0.7355 - val_loss: 0.4796 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5246 - accuracy: 0.6992 - val_loss: 0.5006 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5102 - accuracy: 0.6992 - val_loss: 0.3824 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5672 - accuracy: 0.6992 - val_loss: 0.4652 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4637 - accuracy: 0.7967 - val_loss: 0.4526 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5034 - accuracy: 0.7967 - val_loss: 0.4328 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4337 - accuracy: 0.7967 - val_loss: 0.4654 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4366 - accuracy: 0.7521 - val_loss: 0.3344 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5939 - accuracy: 0.7521 - val_loss: 0.3392 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4504 - accuracy: 0.7521 - val_loss: 0.4142 - val_accuracy: 0.8065\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4513 - accuracy: 0.7398 - val_loss: 0.4879 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4710 - accuracy: 0.7398 - val_loss: 0.5090 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5073 - accuracy: 0.7398 - val_loss: 0.4701 - val_accuracy: 0.6129\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.4936 - accuracy: 0.7317 - val_loss: 0.5638 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5336 - accuracy: 0.7317 - val_loss: 0.5121 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4970 - accuracy: 0.7317 - val_loss: 0.5153 - val_accuracy: 0.6774\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5334 - accuracy: 0.6992 - val_loss: 0.4423 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5764 - accuracy: 0.6992 - val_loss: 0.5163 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5405 - accuracy: 0.6992 - val_loss: 0.5155 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4590 - accuracy: 0.7805 - val_loss: 0.4546 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5413 - accuracy: 0.7805 - val_loss: 0.4421 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4512 - accuracy: 0.7805 - val_loss: 0.5163 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5027 - accuracy: 0.7073 - val_loss: 0.5117 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5398 - accuracy: 0.7073 - val_loss: 0.5185 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5286 - accuracy: 0.7073 - val_loss: 0.4896 - val_accuracy: 0.7419\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4654 - accuracy: 0.7438 - val_loss: 0.5420 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6111 - accuracy: 0.7438 - val_loss: 0.4876 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4502 - accuracy: 0.7438 - val_loss: 0.5307 - val_accuracy: 0.6774\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.5542 - accuracy: 0.6667 - val_loss: 0.3481 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5783 - accuracy: 0.6667 - val_loss: 0.4965 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5814 - accuracy: 0.6667 - val_loss: 0.4437 - val_accuracy: 0.8387\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5475 - accuracy: 0.6777 - val_loss: 0.6557 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6154 - accuracy: 0.6777 - val_loss: 0.5787 - val_accuracy: 0.5484\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5269 - accuracy: 0.6777 - val_loss: 0.6401 - val_accuracy: 0.5484\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4205 - accuracy: 0.7317 - val_loss: 0.4282 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5516 - accuracy: 0.7317 - val_loss: 0.4069 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4073 - accuracy: 0.7317 - val_loss: 0.5222 - val_accuracy: 0.8065\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4316 - accuracy: 0.7851 - val_loss: 0.2999 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4593 - accuracy: 0.7851 - val_loss: 0.2991 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3842 - accuracy: 0.7851 - val_loss: 0.3667 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4591 - accuracy: 0.7851 - val_loss: 0.6224 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5369 - accuracy: 0.7851 - val_loss: 0.5095 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4464 - accuracy: 0.7851 - val_loss: 0.5228 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4822 - accuracy: 0.7642 - val_loss: 0.5000 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5304 - accuracy: 0.7642 - val_loss: 0.4779 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4360 - accuracy: 0.7642 - val_loss: 0.4923 - val_accuracy: 0.7419\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4926 - accuracy: 0.7724 - val_loss: 0.4083 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5731 - accuracy: 0.7724 - val_loss: 0.4456 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5036 - accuracy: 0.7724 - val_loss: 0.4794 - val_accuracy: 0.8387\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5777 - accuracy: 0.6446 - val_loss: 0.4694 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5694 - accuracy: 0.6446 - val_loss: 0.4480 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6146 - accuracy: 0.6446 - val_loss: 0.4648 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=21\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5145 - accuracy: 0.6992 - val_loss: 0.5144 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5033 - accuracy: 0.6992 - val_loss: 0.5049 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5204 - accuracy: 0.6992 - val_loss: 0.5069 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4521 - accuracy: 0.7561 - val_loss: 0.3645 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4960 - accuracy: 0.7561 - val_loss: 0.3724 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4336 - accuracy: 0.7561 - val_loss: 0.4271 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.4668 - accuracy: 0.7438 - val_loss: 0.3002 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4694 - accuracy: 0.7438 - val_loss: 0.4040 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4646 - accuracy: 0.7438 - val_loss: 0.3726 - val_accuracy: 0.8710\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.3907 - accuracy: 0.7851 - val_loss: 0.5645 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4669 - accuracy: 0.7851 - val_loss: 0.4947 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3618 - accuracy: 0.7851 - val_loss: 0.5036 - val_accuracy: 0.6774\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4973 - accuracy: 0.6829 - val_loss: 0.4218 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5362 - accuracy: 0.6829 - val_loss: 0.3332 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4636 - accuracy: 0.6829 - val_loss: 0.3277 - val_accuracy: 0.8387\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.4625 - accuracy: 0.7480 - val_loss: 0.5734 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4532 - accuracy: 0.7480 - val_loss: 0.5839 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4902 - accuracy: 0.7480 - val_loss: 0.5542 - val_accuracy: 0.5806\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4419 - accuracy: 0.7480 - val_loss: 0.3543 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4917 - accuracy: 0.7480 - val_loss: 0.4248 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4576 - accuracy: 0.7480 - val_loss: 0.4358 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4793 - accuracy: 0.7561 - val_loss: 0.3177 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4981 - accuracy: 0.7561 - val_loss: 0.3871 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4722 - accuracy: 0.7561 - val_loss: 0.3960 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4560 - accuracy: 0.7273 - val_loss: 0.4110 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4374 - accuracy: 0.7273 - val_loss: 0.4729 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4531 - accuracy: 0.7273 - val_loss: 0.3971 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4835 - accuracy: 0.7073 - val_loss: 0.6010 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4641 - accuracy: 0.7073 - val_loss: 0.5557 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4783 - accuracy: 0.7073 - val_loss: 0.5551 - val_accuracy: 0.6452\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4493 - accuracy: 0.7154 - val_loss: 0.3349 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4411 - accuracy: 0.7154 - val_loss: 0.4269 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4942 - accuracy: 0.7154 - val_loss: 0.3444 - val_accuracy: 0.8387\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.4748 - accuracy: 0.7317 - val_loss: 0.5724 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5096 - accuracy: 0.7317 - val_loss: 0.5068 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4792 - accuracy: 0.7317 - val_loss: 0.5063 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5261 - accuracy: 0.7236 - val_loss: 0.4303 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4941 - accuracy: 0.7236 - val_loss: 0.3898 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5584 - accuracy: 0.7236 - val_loss: 0.4636 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5475 - accuracy: 0.6423 - val_loss: 0.5996 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6216 - accuracy: 0.6423 - val_loss: 0.5490 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5203 - accuracy: 0.6423 - val_loss: 0.6234 - val_accuracy: 0.6129\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4977 - accuracy: 0.7073 - val_loss: 0.4692 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4684 - accuracy: 0.7073 - val_loss: 0.4675 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4434 - accuracy: 0.7073 - val_loss: 0.4870 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4254 - accuracy: 0.7686 - val_loss: 0.3500 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4528 - accuracy: 0.7686 - val_loss: 0.3336 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4058 - accuracy: 0.7686 - val_loss: 0.3668 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4665 - accuracy: 0.7438 - val_loss: 0.3548 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4952 - accuracy: 0.7438 - val_loss: 0.3760 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4652 - accuracy: 0.7438 - val_loss: 0.3813 - val_accuracy: 0.8387\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3868 - accuracy: 0.8182 - val_loss: 0.3204 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4304 - accuracy: 0.8182 - val_loss: 0.3479 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3850 - accuracy: 0.8182 - val_loss: 0.3916 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=22\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.3960 - accuracy: 0.7438 - val_loss: 0.6063 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6271 - accuracy: 0.7438 - val_loss: 0.4447 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3920 - accuracy: 0.7438 - val_loss: 0.4633 - val_accuracy: 0.6774\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4558 - accuracy: 0.7398 - val_loss: 0.1636 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.7031 - accuracy: 0.7398 - val_loss: 0.2444 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4346 - accuracy: 0.7398 - val_loss: 0.3526 - val_accuracy: 0.8710\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4756 - accuracy: 0.7480 - val_loss: 0.4047 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5917 - accuracy: 0.7480 - val_loss: 0.3764 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4699 - accuracy: 0.7480 - val_loss: 0.4091 - val_accuracy: 0.8387\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4132 - accuracy: 0.7603 - val_loss: 0.4810 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.7185 - accuracy: 0.7603 - val_loss: 0.3715 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4078 - accuracy: 0.7603 - val_loss: 0.3956 - val_accuracy: 0.7742\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.4366 - accuracy: 0.7236 - val_loss: 0.4474 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4274 - accuracy: 0.7236 - val_loss: 0.5334 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5968 - accuracy: 0.7236 - val_loss: 0.4269 - val_accuracy: 0.6774\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4773 - accuracy: 0.7154 - val_loss: 0.5035 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5689 - accuracy: 0.7154 - val_loss: 0.4355 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4847 - accuracy: 0.7154 - val_loss: 0.4700 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.4204 - accuracy: 0.7642 - val_loss: 0.5569 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.6039 - accuracy: 0.7642 - val_loss: 0.4595 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4161 - accuracy: 0.7642 - val_loss: 0.4824 - val_accuracy: 0.7419\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4579 - accuracy: 0.7686 - val_loss: 0.6807 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5315 - accuracy: 0.7686 - val_loss: 0.5305 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4375 - accuracy: 0.7686 - val_loss: 0.5666 - val_accuracy: 0.6452\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4438 - accuracy: 0.7805 - val_loss: 0.3425 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.7142 - accuracy: 0.7805 - val_loss: 0.3277 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4429 - accuracy: 0.7805 - val_loss: 0.4047 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.4386 - accuracy: 0.7561 - val_loss: 0.3098 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6422 - accuracy: 0.7561 - val_loss: 0.3394 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4416 - accuracy: 0.7561 - val_loss: 0.4169 - val_accuracy: 0.8710\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4812 - accuracy: 0.7154 - val_loss: 0.5837 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5577 - accuracy: 0.7154 - val_loss: 0.4533 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4338 - accuracy: 0.7154 - val_loss: 0.4026 - val_accuracy: 0.8387\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5107 - accuracy: 0.6341 - val_loss: 0.5991 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5229 - accuracy: 0.6341 - val_loss: 0.7155 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5711 - accuracy: 0.6341 - val_loss: 0.5970 - val_accuracy: 0.5806\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5051 - accuracy: 0.7317 - val_loss: 0.4566 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5034 - accuracy: 0.7317 - val_loss: 0.4303 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4984 - accuracy: 0.7317 - val_loss: 0.4899 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5137 - accuracy: 0.7236 - val_loss: 0.3290 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4938 - accuracy: 0.7236 - val_loss: 0.3894 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5164 - accuracy: 0.7236 - val_loss: 0.2979 - val_accuracy: 0.8710\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4420 - accuracy: 0.7317 - val_loss: 0.5952 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5766 - accuracy: 0.7317 - val_loss: 0.5207 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4470 - accuracy: 0.7317 - val_loss: 0.5884 - val_accuracy: 0.7097\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4052 - accuracy: 0.7805 - val_loss: 0.3912 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4851 - accuracy: 0.7805 - val_loss: 0.4342 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4299 - accuracy: 0.7805 - val_loss: 0.4281 - val_accuracy: 0.7419\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4333 - accuracy: 0.7438 - val_loss: 0.4270 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5057 - accuracy: 0.7438 - val_loss: 0.5223 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4370 - accuracy: 0.7438 - val_loss: 0.5286 - val_accuracy: 0.8387\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.3921 - accuracy: 0.7934 - val_loss: 0.4517 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6478 - accuracy: 0.7934 - val_loss: 0.3723 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.3912 - accuracy: 0.7934 - val_loss: 0.4177 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=23\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5223 - accuracy: 0.7073 - val_loss: 0.4312 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5435 - accuracy: 0.7073 - val_loss: 0.5058 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5486 - accuracy: 0.7073 - val_loss: 0.4725 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4444 - accuracy: 0.7480 - val_loss: 0.3454 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4944 - accuracy: 0.7480 - val_loss: 0.3514 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4137 - accuracy: 0.7480 - val_loss: 0.4208 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4179 - accuracy: 0.7851 - val_loss: 0.6051 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5011 - accuracy: 0.7851 - val_loss: 0.4873 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3730 - accuracy: 0.7851 - val_loss: 0.4760 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4465 - accuracy: 0.7561 - val_loss: 0.4512 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5424 - accuracy: 0.7561 - val_loss: 0.4512 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4031 - accuracy: 0.7561 - val_loss: 0.5049 - val_accuracy: 0.8387\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4321 - accuracy: 0.7317 - val_loss: 0.6594 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5731 - accuracy: 0.7317 - val_loss: 0.4833 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4143 - accuracy: 0.7317 - val_loss: 0.4914 - val_accuracy: 0.6452\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4661 - accuracy: 0.7398 - val_loss: 0.6282 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5743 - accuracy: 0.7398 - val_loss: 0.5065 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4883 - accuracy: 0.7398 - val_loss: 0.5084 - val_accuracy: 0.6129\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.4634 - accuracy: 0.7603 - val_loss: 0.5323 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5508 - accuracy: 0.7603 - val_loss: 0.4566 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4278 - accuracy: 0.7603 - val_loss: 0.4725 - val_accuracy: 0.6774\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.4869 - accuracy: 0.7561 - val_loss: 0.3049 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.5363 - accuracy: 0.7561 - val_loss: 0.3684 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4778 - accuracy: 0.7561 - val_loss: 0.4047 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4592 - accuracy: 0.7886 - val_loss: 0.4913 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4747 - accuracy: 0.7886 - val_loss: 0.4728 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4272 - accuracy: 0.7886 - val_loss: 0.5246 - val_accuracy: 0.7742\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5127 - accuracy: 0.7073 - val_loss: 0.2982 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5610 - accuracy: 0.7073 - val_loss: 0.3958 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5177 - accuracy: 0.7073 - val_loss: 0.4486 - val_accuracy: 0.9032\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4471 - accuracy: 0.7317 - val_loss: 0.4193 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4966 - accuracy: 0.7317 - val_loss: 0.4052 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4381 - accuracy: 0.7317 - val_loss: 0.4019 - val_accuracy: 0.7742\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4918 - accuracy: 0.6504 - val_loss: 0.7384 - val_accuracy: 0.5161\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5313 - accuracy: 0.6504 - val_loss: 0.6089 - val_accuracy: 0.5161\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5702 - accuracy: 0.6504 - val_loss: 0.6206 - val_accuracy: 0.5161\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4762 - accuracy: 0.7025 - val_loss: 0.4289 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5520 - accuracy: 0.7025 - val_loss: 0.3955 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4515 - accuracy: 0.7025 - val_loss: 0.4407 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4737 - accuracy: 0.7561 - val_loss: 0.5911 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5234 - accuracy: 0.7561 - val_loss: 0.5024 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4434 - accuracy: 0.7561 - val_loss: 0.5281 - val_accuracy: 0.7419\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4769 - accuracy: 0.7686 - val_loss: 0.4385 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5915 - accuracy: 0.7686 - val_loss: 0.4065 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4687 - accuracy: 0.7686 - val_loss: 0.4638 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4041 - accuracy: 0.7724 - val_loss: 0.4684 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5296 - accuracy: 0.7724 - val_loss: 0.4183 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4098 - accuracy: 0.7724 - val_loss: 0.4436 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4797 - accuracy: 0.7317 - val_loss: 0.3119 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.4993 - accuracy: 0.7317 - val_loss: 0.4465 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4495 - accuracy: 0.7317 - val_loss: 0.4941 - val_accuracy: 0.8387\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5585 - accuracy: 0.6364 - val_loss: 0.4522 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5526 - accuracy: 0.6364 - val_loss: 0.4811 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5516 - accuracy: 0.6364 - val_loss: 0.4393 - val_accuracy: 0.8065\n",
            "Publisher: global iteration=24\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4934 - accuracy: 0.6911 - val_loss: 0.4911 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4672 - accuracy: 0.6911 - val_loss: 0.5114 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4846 - accuracy: 0.6911 - val_loss: 0.5290 - val_accuracy: 0.7742\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4283 - accuracy: 0.7851 - val_loss: 0.2727 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5079 - accuracy: 0.7851 - val_loss: 0.2982 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3901 - accuracy: 0.7851 - val_loss: 0.3510 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4355 - accuracy: 0.7561 - val_loss: 0.4106 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4548 - accuracy: 0.7561 - val_loss: 0.5060 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4731 - accuracy: 0.7561 - val_loss: 0.4374 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4226 - accuracy: 0.7886 - val_loss: 0.5289 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4511 - accuracy: 0.7886 - val_loss: 0.4524 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3994 - accuracy: 0.7886 - val_loss: 0.4550 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4071 - accuracy: 0.8049 - val_loss: 0.4563 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4987 - accuracy: 0.8049 - val_loss: 0.4725 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3751 - accuracy: 0.8049 - val_loss: 0.5259 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4647 - accuracy: 0.7154 - val_loss: 0.5082 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5329 - accuracy: 0.7154 - val_loss: 0.5025 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4638 - accuracy: 0.7154 - val_loss: 0.5175 - val_accuracy: 0.7097\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4840 - accuracy: 0.7642 - val_loss: 0.4334 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4257 - accuracy: 0.7642 - val_loss: 0.3918 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4777 - accuracy: 0.7642 - val_loss: 0.4081 - val_accuracy: 0.7419\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5205 - accuracy: 0.6992 - val_loss: 0.3366 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5031 - accuracy: 0.6992 - val_loss: 0.3651 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5098 - accuracy: 0.6992 - val_loss: 0.2939 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.4961 - accuracy: 0.7236 - val_loss: 0.5052 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5383 - accuracy: 0.7236 - val_loss: 0.4802 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4646 - accuracy: 0.7236 - val_loss: 0.4811 - val_accuracy: 0.6774\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4732 - accuracy: 0.7561 - val_loss: 0.4093 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4954 - accuracy: 0.7561 - val_loss: 0.5073 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4966 - accuracy: 0.7561 - val_loss: 0.4387 - val_accuracy: 0.7097\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4397 - accuracy: 0.7769 - val_loss: 0.6425 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4805 - accuracy: 0.7769 - val_loss: 0.5318 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4391 - accuracy: 0.7769 - val_loss: 0.5318 - val_accuracy: 0.7097\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5531 - accuracy: 0.6098 - val_loss: 0.5876 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.6183 - accuracy: 0.6098 - val_loss: 0.4919 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5352 - accuracy: 0.6098 - val_loss: 0.4891 - val_accuracy: 0.6774\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5093 - accuracy: 0.7236 - val_loss: 0.3825 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5136 - accuracy: 0.7236 - val_loss: 0.4587 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5286 - accuracy: 0.7236 - val_loss: 0.4288 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.3863 - accuracy: 0.7686 - val_loss: 0.3287 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4318 - accuracy: 0.7686 - val_loss: 0.3430 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3690 - accuracy: 0.7686 - val_loss: 0.3205 - val_accuracy: 0.8710\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4336 - accuracy: 0.7561 - val_loss: 0.6296 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4931 - accuracy: 0.7561 - val_loss: 0.5401 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4178 - accuracy: 0.7561 - val_loss: 0.5462 - val_accuracy: 0.6129\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4644 - accuracy: 0.7317 - val_loss: 0.3468 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4718 - accuracy: 0.7317 - val_loss: 0.4817 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4979 - accuracy: 0.7317 - val_loss: 0.3996 - val_accuracy: 0.8710\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4287 - accuracy: 0.7438 - val_loss: 0.4214 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5214 - accuracy: 0.7438 - val_loss: 0.4054 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4145 - accuracy: 0.7438 - val_loss: 0.4377 - val_accuracy: 0.8387\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3769 - accuracy: 0.8182 - val_loss: 0.6183 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4600 - accuracy: 0.8182 - val_loss: 0.5128 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3509 - accuracy: 0.8182 - val_loss: 0.5086 - val_accuracy: 0.7419\n",
            "Publisher: global iteration=25\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 744ms/step - loss: 0.3756 - accuracy: 0.7355 - val_loss: 0.5424 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5185 - accuracy: 0.7355 - val_loss: 0.4772 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3574 - accuracy: 0.7355 - val_loss: 0.5107 - val_accuracy: 0.7419\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.3824 - accuracy: 0.8017 - val_loss: 0.4503 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4702 - accuracy: 0.8017 - val_loss: 0.4079 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3762 - accuracy: 0.8017 - val_loss: 0.4622 - val_accuracy: 0.7742\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 0.3682 - accuracy: 0.7769 - val_loss: 0.6073 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.5054 - accuracy: 0.7769 - val_loss: 0.4776 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3856 - accuracy: 0.7769 - val_loss: 0.5012 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4529 - accuracy: 0.7236 - val_loss: 0.5104 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4476 - accuracy: 0.7236 - val_loss: 0.4689 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4653 - accuracy: 0.7236 - val_loss: 0.4711 - val_accuracy: 0.7419\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3767 - accuracy: 0.8017 - val_loss: 0.4679 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5056 - accuracy: 0.8017 - val_loss: 0.4197 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.3817 - accuracy: 0.8017 - val_loss: 0.4648 - val_accuracy: 0.7419\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4882 - accuracy: 0.6911 - val_loss: 0.5587 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5734 - accuracy: 0.6911 - val_loss: 0.4929 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4814 - accuracy: 0.6911 - val_loss: 0.4881 - val_accuracy: 0.6774\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3698 - accuracy: 0.8130 - val_loss: 0.7670 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4295 - accuracy: 0.8130 - val_loss: 0.5990 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3816 - accuracy: 0.8130 - val_loss: 0.6048 - val_accuracy: 0.5806\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4209 - accuracy: 0.7805 - val_loss: 0.5007 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4533 - accuracy: 0.7805 - val_loss: 0.4977 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4609 - accuracy: 0.7805 - val_loss: 0.4699 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5044 - accuracy: 0.6992 - val_loss: 0.5715 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.5926 - accuracy: 0.6992 - val_loss: 0.4834 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5031 - accuracy: 0.6992 - val_loss: 0.4201 - val_accuracy: 0.7742\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5010 - accuracy: 0.6748 - val_loss: 0.3807 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4881 - accuracy: 0.6748 - val_loss: 0.3818 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.6530 - accuracy: 0.6748 - val_loss: 0.3637 - val_accuracy: 0.8710\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.4317 - accuracy: 0.7236 - val_loss: 0.3810 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4234 - accuracy: 0.7236 - val_loss: 0.3905 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4394 - accuracy: 0.7236 - val_loss: 0.3578 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5365 - accuracy: 0.6529 - val_loss: 0.6065 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6061 - accuracy: 0.6529 - val_loss: 0.5892 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5340 - accuracy: 0.6529 - val_loss: 0.6018 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.4748 - accuracy: 0.7107 - val_loss: 0.4660 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5083 - accuracy: 0.7107 - val_loss: 0.3311 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4891 - accuracy: 0.7107 - val_loss: 0.3504 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3849 - accuracy: 0.7724 - val_loss: 0.4179 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5465 - accuracy: 0.7724 - val_loss: 0.3417 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.3724 - accuracy: 0.7724 - val_loss: 0.3852 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.4324 - accuracy: 0.7154 - val_loss: 0.6796 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4446 - accuracy: 0.7154 - val_loss: 0.5750 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4770 - accuracy: 0.7154 - val_loss: 0.5586 - val_accuracy: 0.6774\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4523 - accuracy: 0.7480 - val_loss: 0.3851 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4378 - accuracy: 0.7480 - val_loss: 0.5094 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4905 - accuracy: 0.7480 - val_loss: 0.4628 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4762 - accuracy: 0.6911 - val_loss: 0.5343 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5550 - accuracy: 0.6911 - val_loss: 0.4819 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4715 - accuracy: 0.6911 - val_loss: 0.4746 - val_accuracy: 0.6452\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3712 - accuracy: 0.7769 - val_loss: 0.4131 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5111 - accuracy: 0.7769 - val_loss: 0.3726 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3601 - accuracy: 0.7769 - val_loss: 0.4426 - val_accuracy: 0.7419\n",
            "Publisher: global iteration=26\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.4807 - accuracy: 0.6911 - val_loss: 0.4351 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4994 - accuracy: 0.7073 - val_loss: 0.5106 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5240 - accuracy: 0.7805 - val_loss: 0.5146 - val_accuracy: 0.7742\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4211 - accuracy: 0.7561 - val_loss: 0.5091 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5263 - accuracy: 0.7561 - val_loss: 0.3990 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3841 - accuracy: 0.7561 - val_loss: 0.4237 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.4160 - accuracy: 0.7561 - val_loss: 0.6577 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6469 - accuracy: 0.7561 - val_loss: 0.5114 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4119 - accuracy: 0.7561 - val_loss: 0.5239 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4391 - accuracy: 0.7561 - val_loss: 0.3364 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6512 - accuracy: 0.7561 - val_loss: 0.3341 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4446 - accuracy: 0.7561 - val_loss: 0.4180 - val_accuracy: 0.8387\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.3907 - accuracy: 0.8017 - val_loss: 0.6239 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5570 - accuracy: 0.8017 - val_loss: 0.4518 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3642 - accuracy: 0.8017 - val_loss: 0.4310 - val_accuracy: 0.7419\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4379 - accuracy: 0.7073 - val_loss: 0.6809 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.5909 - accuracy: 0.7073 - val_loss: 0.4974 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4283 - accuracy: 0.7805 - val_loss: 0.5045 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4479 - accuracy: 0.7480 - val_loss: 0.3847 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4798 - accuracy: 0.7561 - val_loss: 0.4494 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4864 - accuracy: 0.7724 - val_loss: 0.4017 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.4000 - accuracy: 0.7398 - val_loss: 0.5701 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6498 - accuracy: 0.7480 - val_loss: 0.4257 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3874 - accuracy: 0.8130 - val_loss: 0.4504 - val_accuracy: 0.8065\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4556 - accuracy: 0.7480 - val_loss: 0.4709 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4887 - accuracy: 0.7480 - val_loss: 0.4171 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4701 - accuracy: 0.7480 - val_loss: 0.4245 - val_accuracy: 0.7419\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4203 - accuracy: 0.7603 - val_loss: 0.6687 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.5608 - accuracy: 0.7603 - val_loss: 0.5195 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.3984 - accuracy: 0.7603 - val_loss: 0.5514 - val_accuracy: 0.6129\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4432 - accuracy: 0.7236 - val_loss: 0.3216 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.4807 - accuracy: 0.7073 - val_loss: 0.4184 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5299 - accuracy: 0.7561 - val_loss: 0.3606 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5057 - accuracy: 0.6748 - val_loss: 0.4928 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4991 - accuracy: 0.7398 - val_loss: 0.5069 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4959 - accuracy: 0.6829 - val_loss: 0.4866 - val_accuracy: 0.6774\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4638 - accuracy: 0.7273 - val_loss: 0.6127 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4837 - accuracy: 0.7273 - val_loss: 0.5162 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4307 - accuracy: 0.7273 - val_loss: 0.5579 - val_accuracy: 0.6774\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3522 - accuracy: 0.7934 - val_loss: 0.4382 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5158 - accuracy: 0.7934 - val_loss: 0.3378 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3338 - accuracy: 0.7934 - val_loss: 0.3647 - val_accuracy: 0.7742\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4802 - accuracy: 0.7154 - val_loss: 0.3087 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5455 - accuracy: 0.7154 - val_loss: 0.4638 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5516 - accuracy: 0.7154 - val_loss: 0.4049 - val_accuracy: 0.8710\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3924 - accuracy: 0.7603 - val_loss: 0.4532 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5232 - accuracy: 0.7603 - val_loss: 0.3516 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3610 - accuracy: 0.7603 - val_loss: 0.3909 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4694 - accuracy: 0.8049 - val_loss: 0.5697 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4693 - accuracy: 0.8049 - val_loss: 0.5093 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4977 - accuracy: 0.8049 - val_loss: 0.4842 - val_accuracy: 0.7097\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5213 - accuracy: 0.6860 - val_loss: 0.5751 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4906 - accuracy: 0.7190 - val_loss: 0.6016 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4948 - accuracy: 0.7190 - val_loss: 0.5958 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=27\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.4475 - accuracy: 0.7154 - val_loss: 0.6816 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5987 - accuracy: 0.7236 - val_loss: 0.5374 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4750 - accuracy: 0.7480 - val_loss: 0.5412 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3832 - accuracy: 0.8099 - val_loss: 0.5241 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4717 - accuracy: 0.8099 - val_loss: 0.4762 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3556 - accuracy: 0.8099 - val_loss: 0.4846 - val_accuracy: 0.7419\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4270 - accuracy: 0.8130 - val_loss: 0.4811 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4596 - accuracy: 0.8130 - val_loss: 0.4842 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4620 - accuracy: 0.8130 - val_loss: 0.4548 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4445 - accuracy: 0.7561 - val_loss: 0.2920 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4589 - accuracy: 0.7561 - val_loss: 0.4790 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5032 - accuracy: 0.7561 - val_loss: 0.3637 - val_accuracy: 0.8387\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4336 - accuracy: 0.7236 - val_loss: 0.4478 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4169 - accuracy: 0.7154 - val_loss: 0.4924 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4542 - accuracy: 0.8293 - val_loss: 0.4405 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4275 - accuracy: 0.7398 - val_loss: 0.6004 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5172 - accuracy: 0.7398 - val_loss: 0.5024 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4484 - accuracy: 0.7398 - val_loss: 0.4897 - val_accuracy: 0.6452\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4942 - accuracy: 0.7154 - val_loss: 0.4536 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5390 - accuracy: 0.7642 - val_loss: 0.3996 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4920 - accuracy: 0.7236 - val_loss: 0.4065 - val_accuracy: 0.7419\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4258 - accuracy: 0.7886 - val_loss: 0.6615 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5126 - accuracy: 0.7886 - val_loss: 0.6028 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4125 - accuracy: 0.7886 - val_loss: 0.5904 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4757 - accuracy: 0.7154 - val_loss: 0.4719 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4704 - accuracy: 0.7317 - val_loss: 0.4655 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4644 - accuracy: 0.7154 - val_loss: 0.5334 - val_accuracy: 0.7097\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4587 - accuracy: 0.7561 - val_loss: 0.4758 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5133 - accuracy: 0.7561 - val_loss: 0.4622 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4692 - accuracy: 0.7561 - val_loss: 0.4754 - val_accuracy: 0.7097\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4303 - accuracy: 0.7724 - val_loss: 0.4996 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4745 - accuracy: 0.7724 - val_loss: 0.4304 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3981 - accuracy: 0.7724 - val_loss: 0.4443 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5313 - accuracy: 0.6341 - val_loss: 0.6830 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6855 - accuracy: 0.4390 - val_loss: 0.6614 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6671 - accuracy: 0.5528 - val_loss: 0.5541 - val_accuracy: 0.8065\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4669 - accuracy: 0.6911 - val_loss: 0.3473 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4904 - accuracy: 0.7480 - val_loss: 0.6188 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.6029 - accuracy: 0.7480 - val_loss: 0.3965 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3920 - accuracy: 0.7724 - val_loss: 0.3306 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4874 - accuracy: 0.7724 - val_loss: 0.3454 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3646 - accuracy: 0.7724 - val_loss: 0.3915 - val_accuracy: 0.8387\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4472 - accuracy: 0.7236 - val_loss: 0.6001 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5183 - accuracy: 0.7561 - val_loss: 0.5287 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4726 - accuracy: 0.8537 - val_loss: 0.5176 - val_accuracy: 0.6452\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4733 - accuracy: 0.7480 - val_loss: 0.3373 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4685 - accuracy: 0.7480 - val_loss: 0.4346 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5253 - accuracy: 0.7480 - val_loss: 0.3524 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4720 - accuracy: 0.6829 - val_loss: 0.5613 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5743 - accuracy: 0.7480 - val_loss: 0.5342 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4609 - accuracy: 0.7480 - val_loss: 0.5303 - val_accuracy: 0.6774\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3486 - accuracy: 0.8595 - val_loss: 0.5963 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3651 - accuracy: 0.8595 - val_loss: 0.4875 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3014 - accuracy: 0.8595 - val_loss: 0.4817 - val_accuracy: 0.6774\n",
            "Publisher: global iteration=28\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.3851 - accuracy: 0.8264 - val_loss: 0.7271 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4948 - accuracy: 0.7521 - val_loss: 0.4800 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3597 - accuracy: 0.8678 - val_loss: 0.5101 - val_accuracy: 0.6774\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3897 - accuracy: 0.8455 - val_loss: 0.4619 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5417 - accuracy: 0.7561 - val_loss: 0.3748 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3627 - accuracy: 0.7967 - val_loss: 0.4159 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4224 - accuracy: 0.7967 - val_loss: 0.4660 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4889 - accuracy: 0.7724 - val_loss: 0.4403 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4120 - accuracy: 0.8293 - val_loss: 0.4484 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4663 - accuracy: 0.7480 - val_loss: 0.4680 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5211 - accuracy: 0.7398 - val_loss: 0.4124 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4555 - accuracy: 0.7154 - val_loss: 0.4263 - val_accuracy: 0.7742\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4833 - accuracy: 0.7317 - val_loss: 0.5087 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5506 - accuracy: 0.7480 - val_loss: 0.4078 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4563 - accuracy: 0.7073 - val_loss: 0.4305 - val_accuracy: 0.7419\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4299 - accuracy: 0.7724 - val_loss: 0.5471 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4278 - accuracy: 0.8130 - val_loss: 0.7729 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5951 - accuracy: 0.7236 - val_loss: 0.5631 - val_accuracy: 0.7097\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4211 - accuracy: 0.7886 - val_loss: 0.3754 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3953 - accuracy: 0.7642 - val_loss: 0.3598 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.3869 - accuracy: 0.7805 - val_loss: 0.3685 - val_accuracy: 0.8065\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4651 - accuracy: 0.7438 - val_loss: 0.3872 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4500 - accuracy: 0.7851 - val_loss: 0.4161 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6180 - accuracy: 0.7355 - val_loss: 0.4121 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.4365 - accuracy: 0.7724 - val_loss: 0.4842 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4111 - accuracy: 0.7561 - val_loss: 0.5584 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4949 - accuracy: 0.7724 - val_loss: 0.4888 - val_accuracy: 0.7419\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4514 - accuracy: 0.7355 - val_loss: 0.3997 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4666 - accuracy: 0.7686 - val_loss: 0.2719 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4627 - accuracy: 0.7025 - val_loss: 0.3222 - val_accuracy: 0.8710\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.4019 - accuracy: 0.7805 - val_loss: 0.6338 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5654 - accuracy: 0.7642 - val_loss: 0.3966 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4276 - accuracy: 0.7805 - val_loss: 0.4102 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5348 - accuracy: 0.7107 - val_loss: 0.6111 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5973 - accuracy: 0.7686 - val_loss: 0.6011 - val_accuracy: 0.5161\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5045 - accuracy: 0.7025 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4192 - accuracy: 0.7886 - val_loss: 0.4260 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4305 - accuracy: 0.8455 - val_loss: 0.4863 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4165 - accuracy: 0.7724 - val_loss: 0.4256 - val_accuracy: 0.8065\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.3534 - accuracy: 0.8293 - val_loss: 0.4890 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5948 - accuracy: 0.7886 - val_loss: 0.3693 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.3494 - accuracy: 0.8293 - val_loss: 0.4065 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4671 - accuracy: 0.7561 - val_loss: 0.3212 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4585 - accuracy: 0.7073 - val_loss: 0.3194 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4277 - accuracy: 0.7642 - val_loss: 0.3273 - val_accuracy: 0.8710\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3661 - accuracy: 0.8374 - val_loss: 0.6120 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6572 - accuracy: 0.7642 - val_loss: 0.3947 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3433 - accuracy: 0.8455 - val_loss: 0.4331 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4275 - accuracy: 0.7686 - val_loss: 0.2682 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4264 - accuracy: 0.7603 - val_loss: 0.4170 - val_accuracy: 0.9355\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5098 - accuracy: 0.8017 - val_loss: 0.3080 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.3666 - accuracy: 0.8017 - val_loss: 0.5141 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6303 - accuracy: 0.7769 - val_loss: 0.3765 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3657 - accuracy: 0.7934 - val_loss: 0.3907 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=29\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5204 - accuracy: 0.7561 - val_loss: 0.4180 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5250 - accuracy: 0.7073 - val_loss: 0.3694 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5038 - accuracy: 0.6992 - val_loss: 0.3668 - val_accuracy: 0.8387\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3687 - accuracy: 0.8678 - val_loss: 0.5474 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5328 - accuracy: 0.8017 - val_loss: 0.4301 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3742 - accuracy: 0.8264 - val_loss: 0.4169 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4253 - accuracy: 0.8293 - val_loss: 0.4814 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4112 - accuracy: 0.8293 - val_loss: 0.5468 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4754 - accuracy: 0.8049 - val_loss: 0.4865 - val_accuracy: 0.7097\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4522 - accuracy: 0.7724 - val_loss: 0.5823 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4406 - accuracy: 0.7317 - val_loss: 0.5508 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4210 - accuracy: 0.7805 - val_loss: 0.5502 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4534 - accuracy: 0.7967 - val_loss: 0.5470 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.4124 - accuracy: 0.7561 - val_loss: 0.5575 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4409 - accuracy: 0.7398 - val_loss: 0.5417 - val_accuracy: 0.6452\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4699 - accuracy: 0.7521 - val_loss: 0.5087 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4857 - accuracy: 0.6942 - val_loss: 0.5145 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5137 - accuracy: 0.7107 - val_loss: 0.4690 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4247 - accuracy: 0.7886 - val_loss: 0.7267 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5130 - accuracy: 0.7480 - val_loss: 0.5226 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4957 - accuracy: 0.7967 - val_loss: 0.5179 - val_accuracy: 0.6452\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.4149 - accuracy: 0.8455 - val_loss: 0.4944 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4853 - accuracy: 0.7154 - val_loss: 0.4356 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4518 - accuracy: 0.8780 - val_loss: 0.4071 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4655 - accuracy: 0.7805 - val_loss: 0.5059 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5737 - accuracy: 0.7886 - val_loss: 0.4524 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4601 - accuracy: 0.7642 - val_loss: 0.4504 - val_accuracy: 0.7419\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4314 - accuracy: 0.8374 - val_loss: 0.5235 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4919 - accuracy: 0.7398 - val_loss: 0.4820 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4486 - accuracy: 0.8455 - val_loss: 0.5224 - val_accuracy: 0.6774\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3854 - accuracy: 0.7886 - val_loss: 0.5106 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3938 - accuracy: 0.8049 - val_loss: 0.7489 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5305 - accuracy: 0.7561 - val_loss: 0.5377 - val_accuracy: 0.6129\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4357 - accuracy: 0.7967 - val_loss: 0.4121 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4492 - accuracy: 0.7236 - val_loss: 0.4247 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4458 - accuracy: 0.7967 - val_loss: 0.4168 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4147 - accuracy: 0.8099 - val_loss: 0.7772 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5602 - accuracy: 0.7438 - val_loss: 0.5219 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4045 - accuracy: 0.8182 - val_loss: 0.5146 - val_accuracy: 0.6129\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4955 - accuracy: 0.7561 - val_loss: 0.5731 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5614 - accuracy: 0.7805 - val_loss: 0.5233 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.5044 - accuracy: 0.7154 - val_loss: 0.5118 - val_accuracy: 0.7419\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4483 - accuracy: 0.7769 - val_loss: 0.3524 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4480 - accuracy: 0.7603 - val_loss: 0.3712 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4331 - accuracy: 0.8099 - val_loss: 0.3404 - val_accuracy: 0.8387\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3708 - accuracy: 0.9008 - val_loss: 0.4899 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.5135 - accuracy: 0.7686 - val_loss: 0.3813 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3469 - accuracy: 0.8264 - val_loss: 0.3777 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4575 - accuracy: 0.7724 - val_loss: 0.3607 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4542 - accuracy: 0.7724 - val_loss: 0.4308 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4666 - accuracy: 0.8293 - val_loss: 0.3719 - val_accuracy: 0.8387\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3669 - accuracy: 0.8347 - val_loss: 0.6060 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4997 - accuracy: 0.8099 - val_loss: 0.4592 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3545 - accuracy: 0.8182 - val_loss: 0.4321 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=30\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.3840 - accuracy: 0.7769 - val_loss: 0.3827 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3812 - accuracy: 0.7438 - val_loss: 0.3690 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3752 - accuracy: 0.8430 - val_loss: 0.3449 - val_accuracy: 0.9355\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4326 - accuracy: 0.8130 - val_loss: 0.2984 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4126 - accuracy: 0.8130 - val_loss: 0.2692 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4381 - accuracy: 0.7317 - val_loss: 0.3424 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4031 - accuracy: 0.8211 - val_loss: 0.5175 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3700 - accuracy: 0.7967 - val_loss: 0.5745 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3775 - accuracy: 0.7967 - val_loss: 0.5631 - val_accuracy: 0.7419\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3824 - accuracy: 0.7967 - val_loss: 0.4680 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3665 - accuracy: 0.8049 - val_loss: 0.4889 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3761 - accuracy: 0.8049 - val_loss: 0.4477 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3566 - accuracy: 0.8264 - val_loss: 0.5043 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3637 - accuracy: 0.8182 - val_loss: 0.5414 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4657 - accuracy: 0.7934 - val_loss: 0.4864 - val_accuracy: 0.7419\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4399 - accuracy: 0.7561 - val_loss: 0.5410 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5526 - accuracy: 0.7642 - val_loss: 0.4199 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4292 - accuracy: 0.7561 - val_loss: 0.4195 - val_accuracy: 0.6774\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4193 - accuracy: 0.7686 - val_loss: 0.3996 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4108 - accuracy: 0.7934 - val_loss: 0.4313 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5007 - accuracy: 0.7438 - val_loss: 0.4089 - val_accuracy: 0.7742\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4400 - accuracy: 0.7521 - val_loss: 0.3919 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4144 - accuracy: 0.7438 - val_loss: 0.3749 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4813 - accuracy: 0.7355 - val_loss: 0.4491 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.4188 - accuracy: 0.7561 - val_loss: 0.4168 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4196 - accuracy: 0.7642 - val_loss: 0.4157 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3995 - accuracy: 0.8130 - val_loss: 0.4936 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5116 - accuracy: 0.7724 - val_loss: 0.5231 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.5071 - accuracy: 0.7967 - val_loss: 0.4294 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4576 - accuracy: 0.7642 - val_loss: 0.4315 - val_accuracy: 0.7742\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4429 - accuracy: 0.8099 - val_loss: 0.3644 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4269 - accuracy: 0.8347 - val_loss: 0.3951 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4632 - accuracy: 0.7603 - val_loss: 0.3553 - val_accuracy: 0.7742\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5982 - accuracy: 0.6777 - val_loss: 0.4505 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6209 - accuracy: 0.7190 - val_loss: 0.4205 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6227 - accuracy: 0.5702 - val_loss: 0.3709 - val_accuracy: 0.8710\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4518 - accuracy: 0.7886 - val_loss: 0.4863 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5056 - accuracy: 0.8374 - val_loss: 0.4209 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4431 - accuracy: 0.7073 - val_loss: 0.4155 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4343 - accuracy: 0.7805 - val_loss: 0.4166 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4825 - accuracy: 0.7805 - val_loss: 0.4218 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4571 - accuracy: 0.7642 - val_loss: 0.4270 - val_accuracy: 0.7419\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4433 - accuracy: 0.7724 - val_loss: 0.4518 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4346 - accuracy: 0.8049 - val_loss: 0.6856 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.5917 - accuracy: 0.7236 - val_loss: 0.4780 - val_accuracy: 0.7419\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3539 - accuracy: 0.8293 - val_loss: 0.4838 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.3448 - accuracy: 0.7886 - val_loss: 0.3875 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3984 - accuracy: 0.8293 - val_loss: 0.3957 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3856 - accuracy: 0.8049 - val_loss: 0.6394 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.3900 - accuracy: 0.8049 - val_loss: 0.4956 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4355 - accuracy: 0.8618 - val_loss: 0.4907 - val_accuracy: 0.7097\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.3786 - accuracy: 0.8264 - val_loss: 0.2807 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3704 - accuracy: 0.7934 - val_loss: 0.3608 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4145 - accuracy: 0.8678 - val_loss: 0.3604 - val_accuracy: 0.8710\n",
            "Publisher: global iteration=31\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.4069 - accuracy: 0.8595 - val_loss: 0.2683 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.8008 - accuracy: 0.7025 - val_loss: 0.2341 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4010 - accuracy: 0.7769 - val_loss: 0.3113 - val_accuracy: 0.9355\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4461 - accuracy: 0.7805 - val_loss: 0.4958 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4437 - accuracy: 0.7967 - val_loss: 0.6924 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5757 - accuracy: 0.7398 - val_loss: 0.4820 - val_accuracy: 0.7742\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.3739 - accuracy: 0.8347 - val_loss: 0.5146 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.6783 - accuracy: 0.7603 - val_loss: 0.3519 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3756 - accuracy: 0.7686 - val_loss: 0.4315 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.4460 - accuracy: 0.8537 - val_loss: 0.9637 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.6816 - accuracy: 0.7480 - val_loss: 0.5865 - val_accuracy: 0.5484\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4077 - accuracy: 0.7398 - val_loss: 0.5444 - val_accuracy: 0.6452\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3843 - accuracy: 0.8699 - val_loss: 0.5403 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.6996 - accuracy: 0.7967 - val_loss: 0.3890 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3502 - accuracy: 0.8049 - val_loss: 0.4081 - val_accuracy: 0.8387\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3944 - accuracy: 0.8537 - val_loss: 0.8429 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.6298 - accuracy: 0.7398 - val_loss: 0.5421 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3549 - accuracy: 0.8049 - val_loss: 0.5462 - val_accuracy: 0.6452\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4113 - accuracy: 0.8455 - val_loss: 0.4647 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3572 - accuracy: 0.7805 - val_loss: 0.4190 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4113 - accuracy: 0.8699 - val_loss: 0.4419 - val_accuracy: 0.7097\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.3919 - accuracy: 0.8374 - val_loss: 0.5621 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4752 - accuracy: 0.7805 - val_loss: 0.5625 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4878 - accuracy: 0.8618 - val_loss: 0.4913 - val_accuracy: 0.7419\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.3779 - accuracy: 0.8455 - val_loss: 0.5491 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.6568 - accuracy: 0.7805 - val_loss: 0.3746 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4111 - accuracy: 0.7967 - val_loss: 0.3858 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.4568 - accuracy: 0.8049 - val_loss: 0.2757 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5318 - accuracy: 0.7642 - val_loss: 0.4492 - val_accuracy: 0.9677\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5625 - accuracy: 0.6992 - val_loss: 0.3791 - val_accuracy: 0.8387\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4203 - accuracy: 0.7642 - val_loss: 0.3401 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4340 - accuracy: 0.8049 - val_loss: 0.2736 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5369 - accuracy: 0.7073 - val_loss: 0.2913 - val_accuracy: 0.8710\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4693 - accuracy: 0.7398 - val_loss: 0.5180 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5247 - accuracy: 0.7724 - val_loss: 0.4766 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.4447 - accuracy: 0.7236 - val_loss: 0.5062 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4130 - accuracy: 0.8130 - val_loss: 0.4748 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4071 - accuracy: 0.7398 - val_loss: 0.4206 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4303 - accuracy: 0.8293 - val_loss: 0.4503 - val_accuracy: 0.7097\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3422 - accuracy: 0.8780 - val_loss: 0.7423 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.7052 - accuracy: 0.7886 - val_loss: 0.4718 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3348 - accuracy: 0.7967 - val_loss: 0.4572 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4208 - accuracy: 0.7805 - val_loss: 0.4069 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5019 - accuracy: 0.7317 - val_loss: 0.3985 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4325 - accuracy: 0.8455 - val_loss: 0.3798 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3682 - accuracy: 0.8293 - val_loss: 0.4150 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.8232 - accuracy: 0.7561 - val_loss: 0.2621 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3792 - accuracy: 0.7886 - val_loss: 0.3300 - val_accuracy: 0.8710\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4595 - accuracy: 0.7805 - val_loss: 0.5573 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5501 - accuracy: 0.7480 - val_loss: 0.5108 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4490 - accuracy: 0.7236 - val_loss: 0.5722 - val_accuracy: 0.6774\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3172 - accuracy: 0.8512 - val_loss: 0.3169 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5485 - accuracy: 0.8099 - val_loss: 0.3007 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3237 - accuracy: 0.8760 - val_loss: 0.3439 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=32\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4357 - accuracy: 0.7886 - val_loss: 0.5805 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4204 - accuracy: 0.7561 - val_loss: 0.5938 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4693 - accuracy: 0.7805 - val_loss: 0.6461 - val_accuracy: 0.6452\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4585 - accuracy: 0.8130 - val_loss: 0.3315 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5200 - accuracy: 0.7154 - val_loss: 0.3792 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.4870 - accuracy: 0.7886 - val_loss: 0.3615 - val_accuracy: 0.7742\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.4049 - accuracy: 0.8537 - val_loss: 0.6713 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4362 - accuracy: 0.8211 - val_loss: 0.4368 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4171 - accuracy: 0.8293 - val_loss: 0.5515 - val_accuracy: 0.6774\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3560 - accuracy: 0.8760 - val_loss: 0.6196 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5381 - accuracy: 0.7769 - val_loss: 0.4414 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3418 - accuracy: 0.8099 - val_loss: 0.4691 - val_accuracy: 0.7419\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4193 - accuracy: 0.8049 - val_loss: 0.4687 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3836 - accuracy: 0.8049 - val_loss: 0.4773 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5230 - accuracy: 0.7724 - val_loss: 0.3803 - val_accuracy: 0.6774\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.4423 - accuracy: 0.7642 - val_loss: 0.3643 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.5083 - accuracy: 0.6911 - val_loss: 0.4146 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4571 - accuracy: 0.8049 - val_loss: 0.4036 - val_accuracy: 0.8387\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4193 - accuracy: 0.8017 - val_loss: 0.6752 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5457 - accuracy: 0.7603 - val_loss: 0.4987 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4055 - accuracy: 0.8182 - val_loss: 0.5037 - val_accuracy: 0.7097\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4280 - accuracy: 0.7851 - val_loss: 0.5462 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5178 - accuracy: 0.7521 - val_loss: 0.5010 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5362 - accuracy: 0.7438 - val_loss: 0.4669 - val_accuracy: 0.7742\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3996 - accuracy: 0.7686 - val_loss: 0.4784 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5051 - accuracy: 0.7273 - val_loss: 0.4748 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5121 - accuracy: 0.8099 - val_loss: 0.4005 - val_accuracy: 0.8387\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4358 - accuracy: 0.8211 - val_loss: 0.5225 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5215 - accuracy: 0.6911 - val_loss: 0.5402 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5744 - accuracy: 0.7317 - val_loss: 0.4835 - val_accuracy: 0.8065\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4356 - accuracy: 0.7934 - val_loss: 0.2665 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4669 - accuracy: 0.7273 - val_loss: 0.5192 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5513 - accuracy: 0.7769 - val_loss: 0.3625 - val_accuracy: 0.9032\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4886 - accuracy: 0.7317 - val_loss: 0.4910 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5269 - accuracy: 0.7642 - val_loss: 0.5905 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5409 - accuracy: 0.6748 - val_loss: 0.5028 - val_accuracy: 0.8065\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4138 - accuracy: 0.8595 - val_loss: 0.9555 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.6260 - accuracy: 0.7438 - val_loss: 0.5786 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3665 - accuracy: 0.8017 - val_loss: 0.4917 - val_accuracy: 0.5806\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5158 - accuracy: 0.7642 - val_loss: 0.4371 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5103 - accuracy: 0.7561 - val_loss: 0.4093 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5373 - accuracy: 0.6748 - val_loss: 0.4032 - val_accuracy: 0.8387\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.4486 - accuracy: 0.7886 - val_loss: 0.4135 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4375 - accuracy: 0.7967 - val_loss: 0.3869 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4580 - accuracy: 0.7317 - val_loss: 0.4221 - val_accuracy: 0.8710\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3813 - accuracy: 0.8211 - val_loss: 0.4615 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.4893 - accuracy: 0.7642 - val_loss: 0.3773 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3820 - accuracy: 0.8049 - val_loss: 0.3637 - val_accuracy: 0.8065\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4133 - accuracy: 0.8211 - val_loss: 0.3688 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5120 - accuracy: 0.7480 - val_loss: 0.3473 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3767 - accuracy: 0.7967 - val_loss: 0.3914 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3819 - accuracy: 0.8347 - val_loss: 0.3217 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5693 - accuracy: 0.7521 - val_loss: 0.3138 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3867 - accuracy: 0.8264 - val_loss: 0.4002 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=33\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4505 - accuracy: 0.8049 - val_loss: 0.4783 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5500 - accuracy: 0.7236 - val_loss: 0.4301 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4828 - accuracy: 0.7805 - val_loss: 0.4421 - val_accuracy: 0.8387\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3835 - accuracy: 0.8943 - val_loss: 0.4452 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4603 - accuracy: 0.7642 - val_loss: 0.3647 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3580 - accuracy: 0.8374 - val_loss: 0.3935 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.3794 - accuracy: 0.8347 - val_loss: 0.5071 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4588 - accuracy: 0.7851 - val_loss: 0.4056 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3715 - accuracy: 0.8512 - val_loss: 0.4384 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3980 - accuracy: 0.8211 - val_loss: 0.2590 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4780 - accuracy: 0.7480 - val_loss: 0.3071 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3890 - accuracy: 0.7724 - val_loss: 0.3724 - val_accuracy: 0.8710\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.4557 - accuracy: 0.7724 - val_loss: 0.4948 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5332 - accuracy: 0.6992 - val_loss: 0.5529 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4819 - accuracy: 0.7642 - val_loss: 0.5620 - val_accuracy: 0.8710\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4537 - accuracy: 0.7851 - val_loss: 0.5381 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5385 - accuracy: 0.6777 - val_loss: 0.4319 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4983 - accuracy: 0.8099 - val_loss: 0.4370 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4575 - accuracy: 0.8374 - val_loss: 0.3687 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.5126 - accuracy: 0.6992 - val_loss: 0.4152 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4757 - accuracy: 0.8130 - val_loss: 0.4257 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4498 - accuracy: 0.7967 - val_loss: 0.2641 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4578 - accuracy: 0.7317 - val_loss: 0.3498 - val_accuracy: 0.9677\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.4671 - accuracy: 0.8211 - val_loss: 0.3154 - val_accuracy: 0.8710\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4008 - accuracy: 0.8618 - val_loss: 0.7268 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4627 - accuracy: 0.7724 - val_loss: 0.5342 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3869 - accuracy: 0.7805 - val_loss: 0.5326 - val_accuracy: 0.6774\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4207 - accuracy: 0.8182 - val_loss: 0.3309 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.4965 - accuracy: 0.7025 - val_loss: 0.4321 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4723 - accuracy: 0.7851 - val_loss: 0.4139 - val_accuracy: 0.8710\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4820 - accuracy: 0.7724 - val_loss: 0.4105 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5601 - accuracy: 0.6992 - val_loss: 0.4374 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5072 - accuracy: 0.7642 - val_loss: 0.4545 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4422 - accuracy: 0.7642 - val_loss: 0.5722 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4256 - accuracy: 0.6829 - val_loss: 0.6596 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4817 - accuracy: 0.6829 - val_loss: 0.6106 - val_accuracy: 0.6452\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3827 - accuracy: 0.8618 - val_loss: 0.3966 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5288 - accuracy: 0.7398 - val_loss: 0.3634 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3662 - accuracy: 0.7805 - val_loss: 0.4185 - val_accuracy: 0.9032\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4889 - accuracy: 0.7398 - val_loss: 0.3864 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.5430 - accuracy: 0.6423 - val_loss: 0.4658 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5486 - accuracy: 0.8130 - val_loss: 0.4340 - val_accuracy: 0.8710\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4596 - accuracy: 0.8211 - val_loss: 0.3611 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4366 - accuracy: 0.7154 - val_loss: 0.4087 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4692 - accuracy: 0.7642 - val_loss: 0.3828 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3946 - accuracy: 0.8130 - val_loss: 0.2197 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4658 - accuracy: 0.7398 - val_loss: 0.3427 - val_accuracy: 0.9677\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3994 - accuracy: 0.8211 - val_loss: 0.3595 - val_accuracy: 0.9032\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.4297 - accuracy: 0.7886 - val_loss: 0.5436 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3990 - accuracy: 0.8049 - val_loss: 0.4863 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4102 - accuracy: 0.8211 - val_loss: 0.4839 - val_accuracy: 0.7097\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.3380 - accuracy: 0.8595 - val_loss: 0.2363 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4184 - accuracy: 0.8099 - val_loss: 0.3343 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.3456 - accuracy: 0.8347 - val_loss: 0.4146 - val_accuracy: 0.9032\n",
            "Publisher: global iteration=34\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4846 - accuracy: 0.7886 - val_loss: 0.5000 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5982 - accuracy: 0.6911 - val_loss: 0.4168 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4322 - accuracy: 0.7724 - val_loss: 0.4497 - val_accuracy: 0.7097\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4546 - accuracy: 0.8374 - val_loss: 0.4669 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6039 - accuracy: 0.6992 - val_loss: 0.3385 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4156 - accuracy: 0.7561 - val_loss: 0.3646 - val_accuracy: 0.8387\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4479 - accuracy: 0.8699 - val_loss: 0.7395 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5594 - accuracy: 0.7967 - val_loss: 0.5921 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4022 - accuracy: 0.7967 - val_loss: 0.5718 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4258 - accuracy: 0.8512 - val_loss: 0.4139 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5811 - accuracy: 0.7686 - val_loss: 0.3468 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4006 - accuracy: 0.7769 - val_loss: 0.3564 - val_accuracy: 0.7419\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4377 - accuracy: 0.8374 - val_loss: 0.4833 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5573 - accuracy: 0.7073 - val_loss: 0.4008 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3836 - accuracy: 0.7886 - val_loss: 0.4291 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4659 - accuracy: 0.8293 - val_loss: 0.5219 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5821 - accuracy: 0.7236 - val_loss: 0.4225 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4045 - accuracy: 0.7886 - val_loss: 0.4551 - val_accuracy: 0.8065\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4181 - accuracy: 0.8374 - val_loss: 0.6392 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5751 - accuracy: 0.7886 - val_loss: 0.4606 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.3829 - accuracy: 0.7886 - val_loss: 0.4841 - val_accuracy: 0.7097\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4721 - accuracy: 0.7967 - val_loss: 0.3338 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6276 - accuracy: 0.7154 - val_loss: 0.3469 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4326 - accuracy: 0.7805 - val_loss: 0.4298 - val_accuracy: 0.9032\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4574 - accuracy: 0.8293 - val_loss: 0.4086 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5840 - accuracy: 0.7805 - val_loss: 0.3654 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4002 - accuracy: 0.7967 - val_loss: 0.4024 - val_accuracy: 0.8387\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4379 - accuracy: 0.8099 - val_loss: 0.5485 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.6185 - accuracy: 0.7603 - val_loss: 0.4074 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4115 - accuracy: 0.7603 - val_loss: 0.4238 - val_accuracy: 0.7419\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.4342 - accuracy: 0.8293 - val_loss: 0.5262 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.5398 - accuracy: 0.8049 - val_loss: 0.4365 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3956 - accuracy: 0.7967 - val_loss: 0.4685 - val_accuracy: 0.6774\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5243 - accuracy: 0.7073 - val_loss: 0.4006 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5007 - accuracy: 0.6992 - val_loss: 0.5094 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.5194 - accuracy: 0.8293 - val_loss: 0.4771 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4278 - accuracy: 0.8293 - val_loss: 0.4747 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6460 - accuracy: 0.7073 - val_loss: 0.4441 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3959 - accuracy: 0.8130 - val_loss: 0.4993 - val_accuracy: 0.8387\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4921 - accuracy: 0.8211 - val_loss: 0.7363 - val_accuracy: 0.5484\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.7195 - accuracy: 0.6748 - val_loss: 0.5279 - val_accuracy: 0.5806\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4914 - accuracy: 0.7398 - val_loss: 0.5355 - val_accuracy: 0.6774\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4357 - accuracy: 0.8017 - val_loss: 0.6119 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6430 - accuracy: 0.7769 - val_loss: 0.4502 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4123 - accuracy: 0.7769 - val_loss: 0.4656 - val_accuracy: 0.7742\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4320 - accuracy: 0.8130 - val_loss: 0.4836 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6224 - accuracy: 0.7642 - val_loss: 0.4047 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4101 - accuracy: 0.7886 - val_loss: 0.4324 - val_accuracy: 0.7419\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4914 - accuracy: 0.7886 - val_loss: 0.3610 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6917 - accuracy: 0.6829 - val_loss: 0.3756 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4716 - accuracy: 0.7724 - val_loss: 0.4570 - val_accuracy: 0.8065\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3655 - accuracy: 0.8843 - val_loss: 0.2976 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5507 - accuracy: 0.8182 - val_loss: 0.2720 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3523 - accuracy: 0.8182 - val_loss: 0.3370 - val_accuracy: 0.8710\n",
            "Publisher: global iteration=35\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4310 - accuracy: 0.8595 - val_loss: 0.2521 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4912 - accuracy: 0.7190 - val_loss: 0.3004 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3886 - accuracy: 0.8430 - val_loss: 0.3756 - val_accuracy: 0.9355\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4206 - accuracy: 0.8182 - val_loss: 0.3645 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4569 - accuracy: 0.7934 - val_loss: 0.3322 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3966 - accuracy: 0.8182 - val_loss: 0.3764 - val_accuracy: 0.8710\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4277 - accuracy: 0.8455 - val_loss: 0.5302 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4670 - accuracy: 0.7805 - val_loss: 0.4944 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3429 - accuracy: 0.8374 - val_loss: 0.5274 - val_accuracy: 0.7742\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4683 - accuracy: 0.7886 - val_loss: 0.5610 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5177 - accuracy: 0.7154 - val_loss: 0.5474 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4245 - accuracy: 0.8455 - val_loss: 0.5558 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4326 - accuracy: 0.8293 - val_loss: 0.3295 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4635 - accuracy: 0.7886 - val_loss: 0.3162 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3879 - accuracy: 0.8211 - val_loss: 0.3639 - val_accuracy: 0.9032\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4524 - accuracy: 0.7686 - val_loss: 0.5200 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4059 - accuracy: 0.7603 - val_loss: 0.5443 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4423 - accuracy: 0.8430 - val_loss: 0.5117 - val_accuracy: 0.6774\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4300 - accuracy: 0.8537 - val_loss: 0.4331 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4829 - accuracy: 0.7886 - val_loss: 0.3785 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3502 - accuracy: 0.8537 - val_loss: 0.4128 - val_accuracy: 0.9032\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4565 - accuracy: 0.8017 - val_loss: 0.3658 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.5208 - accuracy: 0.7355 - val_loss: 0.3412 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4186 - accuracy: 0.7934 - val_loss: 0.3952 - val_accuracy: 0.8710\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.4283 - accuracy: 0.7603 - val_loss: 0.3078 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4611 - accuracy: 0.7355 - val_loss: 0.3132 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3967 - accuracy: 0.7851 - val_loss: 0.3339 - val_accuracy: 0.9032\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4129 - accuracy: 0.8347 - val_loss: 0.5461 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4330 - accuracy: 0.7521 - val_loss: 0.4611 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3694 - accuracy: 0.8512 - val_loss: 0.4656 - val_accuracy: 0.8387\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.3975 - accuracy: 0.8537 - val_loss: 0.6177 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4024 - accuracy: 0.7642 - val_loss: 0.5327 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3474 - accuracy: 0.8049 - val_loss: 0.4860 - val_accuracy: 0.8065\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4801 - accuracy: 0.6992 - val_loss: 0.4678 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4416 - accuracy: 0.7886 - val_loss: 0.6164 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5975 - accuracy: 0.6585 - val_loss: 0.4734 - val_accuracy: 0.7419\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.5873 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4805 - accuracy: 0.7805 - val_loss: 0.5109 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4082 - accuracy: 0.8130 - val_loss: 0.5032 - val_accuracy: 0.6452\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4631 - accuracy: 0.7967 - val_loss: 0.7621 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5074 - accuracy: 0.6992 - val_loss: 0.5603 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4768 - accuracy: 0.8130 - val_loss: 0.5611 - val_accuracy: 0.6774\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.4204 - accuracy: 0.8211 - val_loss: 0.4312 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4573 - accuracy: 0.7642 - val_loss: 0.3950 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3728 - accuracy: 0.8130 - val_loss: 0.4282 - val_accuracy: 0.8710\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4002 - accuracy: 0.8374 - val_loss: 0.4006 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4144 - accuracy: 0.7724 - val_loss: 0.3706 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3368 - accuracy: 0.8049 - val_loss: 0.3810 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4300 - accuracy: 0.8374 - val_loss: 0.4298 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4713 - accuracy: 0.7886 - val_loss: 0.3746 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3839 - accuracy: 0.7886 - val_loss: 0.4030 - val_accuracy: 0.8065\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3643 - accuracy: 0.8595 - val_loss: 0.3582 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4230 - accuracy: 0.8182 - val_loss: 0.3153 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3036 - accuracy: 0.8347 - val_loss: 0.3315 - val_accuracy: 0.8710\n",
            "Publisher: global iteration=36\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.3799 - accuracy: 0.8926 - val_loss: 0.4279 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4847 - accuracy: 0.7273 - val_loss: 0.4028 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3516 - accuracy: 0.8017 - val_loss: 0.4303 - val_accuracy: 0.8387\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4089 - accuracy: 0.8293 - val_loss: 0.5863 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.5111 - accuracy: 0.7398 - val_loss: 0.4656 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4211 - accuracy: 0.7805 - val_loss: 0.4964 - val_accuracy: 0.7419\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.3621 - accuracy: 0.8699 - val_loss: 0.8011 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4641 - accuracy: 0.7724 - val_loss: 0.6120 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3504 - accuracy: 0.7805 - val_loss: 0.5769 - val_accuracy: 0.6774\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3773 - accuracy: 0.8760 - val_loss: 0.5998 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4347 - accuracy: 0.7934 - val_loss: 0.4784 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3562 - accuracy: 0.8017 - val_loss: 0.4305 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4228 - accuracy: 0.7967 - val_loss: 0.4605 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4282 - accuracy: 0.7724 - val_loss: 0.3980 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3701 - accuracy: 0.7967 - val_loss: 0.4014 - val_accuracy: 0.8065\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4519 - accuracy: 0.7642 - val_loss: 0.4714 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5330 - accuracy: 0.7398 - val_loss: 0.3951 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4463 - accuracy: 0.7561 - val_loss: 0.4263 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4230 - accuracy: 0.8130 - val_loss: 0.2246 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4999 - accuracy: 0.7480 - val_loss: 0.3659 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4565 - accuracy: 0.8374 - val_loss: 0.2581 - val_accuracy: 0.8387\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.3708 - accuracy: 0.8780 - val_loss: 0.5595 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5045 - accuracy: 0.7398 - val_loss: 0.4400 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3707 - accuracy: 0.7480 - val_loss: 0.4276 - val_accuracy: 0.8065\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4188 - accuracy: 0.8374 - val_loss: 0.2688 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5132 - accuracy: 0.7805 - val_loss: 0.2597 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4155 - accuracy: 0.7886 - val_loss: 0.3180 - val_accuracy: 0.9032\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3802 - accuracy: 0.8430 - val_loss: 0.6901 - val_accuracy: 0.5806\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5322 - accuracy: 0.7686 - val_loss: 0.4931 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.3735 - accuracy: 0.7769 - val_loss: 0.4671 - val_accuracy: 0.7419\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4785 - accuracy: 0.7805 - val_loss: 0.4170 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5426 - accuracy: 0.6992 - val_loss: 0.3809 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4183 - accuracy: 0.7724 - val_loss: 0.3945 - val_accuracy: 0.8387\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4650 - accuracy: 0.7480 - val_loss: 0.6052 - val_accuracy: 0.6129\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4564 - accuracy: 0.7317 - val_loss: 0.5971 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.6156 - accuracy: 0.6667 - val_loss: 0.5212 - val_accuracy: 0.6129\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.3853 - accuracy: 0.8943 - val_loss: 0.4147 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4492 - accuracy: 0.7398 - val_loss: 0.3594 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3552 - accuracy: 0.7480 - val_loss: 0.3539 - val_accuracy: 0.7742\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4296 - accuracy: 0.8211 - val_loss: 0.4718 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4893 - accuracy: 0.7561 - val_loss: 0.3886 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4218 - accuracy: 0.7642 - val_loss: 0.3907 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4122 - accuracy: 0.8293 - val_loss: 0.3847 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.5069 - accuracy: 0.7398 - val_loss: 0.3440 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3908 - accuracy: 0.7561 - val_loss: 0.3650 - val_accuracy: 0.8387\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.3982 - accuracy: 0.8374 - val_loss: 0.4772 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.4817 - accuracy: 0.7805 - val_loss: 0.4122 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.3671 - accuracy: 0.8130 - val_loss: 0.4274 - val_accuracy: 0.7419\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4196 - accuracy: 0.7724 - val_loss: 0.3473 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.4256 - accuracy: 0.7886 - val_loss: 0.3389 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3817 - accuracy: 0.7805 - val_loss: 0.3484 - val_accuracy: 0.7742\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3625 - accuracy: 0.8760 - val_loss: 0.6030 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4028 - accuracy: 0.7934 - val_loss: 0.5258 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3432 - accuracy: 0.7934 - val_loss: 0.4928 - val_accuracy: 0.7742\n",
            "Publisher: global iteration=37\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4397 - accuracy: 0.7561 - val_loss: 0.4568 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.4560 - accuracy: 0.7642 - val_loss: 0.4989 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4825 - accuracy: 0.8374 - val_loss: 0.4826 - val_accuracy: 0.6774\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4035 - accuracy: 0.7967 - val_loss: 0.6302 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4771 - accuracy: 0.7398 - val_loss: 0.4962 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3902 - accuracy: 0.7805 - val_loss: 0.4997 - val_accuracy: 0.7097\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.3738 - accuracy: 0.8347 - val_loss: 0.4161 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5119 - accuracy: 0.7603 - val_loss: 0.3040 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3541 - accuracy: 0.8099 - val_loss: 0.3178 - val_accuracy: 0.8065\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.3927 - accuracy: 0.8347 - val_loss: 0.2880 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.5702 - accuracy: 0.7273 - val_loss: 0.2457 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.3811 - accuracy: 0.7438 - val_loss: 0.2605 - val_accuracy: 0.9355\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4265 - accuracy: 0.7724 - val_loss: 0.2874 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3733 - accuracy: 0.7805 - val_loss: 0.2672 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3545 - accuracy: 0.8130 - val_loss: 0.2636 - val_accuracy: 0.9032\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4062 - accuracy: 0.8130 - val_loss: 0.3379 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4998 - accuracy: 0.7073 - val_loss: 0.3547 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4049 - accuracy: 0.8699 - val_loss: 0.3760 - val_accuracy: 0.8065\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4184 - accuracy: 0.8455 - val_loss: 0.3234 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4130 - accuracy: 0.7724 - val_loss: 0.3261 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3971 - accuracy: 0.8780 - val_loss: 0.3378 - val_accuracy: 0.8710\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.4615 - accuracy: 0.7967 - val_loss: 0.2918 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4212 - accuracy: 0.7642 - val_loss: 0.3221 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4312 - accuracy: 0.8455 - val_loss: 0.2926 - val_accuracy: 0.8387\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3589 - accuracy: 0.8780 - val_loss: 0.8466 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4347 - accuracy: 0.8049 - val_loss: 0.5649 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.3084 - accuracy: 0.8211 - val_loss: 0.5113 - val_accuracy: 0.7742\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4692 - accuracy: 0.7724 - val_loss: 0.3921 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.4367 - accuracy: 0.7642 - val_loss: 0.3917 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.4038 - accuracy: 0.7886 - val_loss: 0.4552 - val_accuracy: 0.8387\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4273 - accuracy: 0.8211 - val_loss: 0.8139 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.5127 - accuracy: 0.7398 - val_loss: 0.6015 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3848 - accuracy: 0.7886 - val_loss: 0.5927 - val_accuracy: 0.6129\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4788 - accuracy: 0.7107 - val_loss: 0.4473 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.5176 - accuracy: 0.8264 - val_loss: 0.4486 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4710 - accuracy: 0.7355 - val_loss: 0.4740 - val_accuracy: 0.7097\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4369 - accuracy: 0.7769 - val_loss: 0.2745 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4157 - accuracy: 0.7851 - val_loss: 0.2409 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3936 - accuracy: 0.8182 - val_loss: 0.2553 - val_accuracy: 0.8387\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.3508 - accuracy: 0.8678 - val_loss: 0.4444 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3571 - accuracy: 0.8264 - val_loss: 0.3314 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.2922 - accuracy: 0.8843 - val_loss: 0.3398 - val_accuracy: 0.7097\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4363 - accuracy: 0.8049 - val_loss: 0.3576 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4569 - accuracy: 0.7236 - val_loss: 0.5041 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.5387 - accuracy: 0.7967 - val_loss: 0.3565 - val_accuracy: 0.8065\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4369 - accuracy: 0.8293 - val_loss: 0.3922 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5006 - accuracy: 0.7561 - val_loss: 0.3252 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3886 - accuracy: 0.7967 - val_loss: 0.3244 - val_accuracy: 0.8710\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.4014 - accuracy: 0.8264 - val_loss: 0.4299 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3863 - accuracy: 0.7686 - val_loss: 0.3793 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3628 - accuracy: 0.8512 - val_loss: 0.3872 - val_accuracy: 0.8065\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4065 - accuracy: 0.8347 - val_loss: 0.2265 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5439 - accuracy: 0.7438 - val_loss: 0.2535 - val_accuracy: 0.9032\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3557 - accuracy: 0.8430 - val_loss: 0.3678 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=38\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3812 - accuracy: 0.8017 - val_loss: 0.3248 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4015 - accuracy: 0.8099 - val_loss: 0.3213 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4194 - accuracy: 0.8843 - val_loss: 0.2728 - val_accuracy: 0.8387\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4276 - accuracy: 0.7805 - val_loss: 0.3589 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4187 - accuracy: 0.8130 - val_loss: 0.3836 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4014 - accuracy: 0.7561 - val_loss: 0.3826 - val_accuracy: 0.8065\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3727 - accuracy: 0.8512 - val_loss: 0.3331 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3771 - accuracy: 0.7686 - val_loss: 0.3274 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3775 - accuracy: 0.8760 - val_loss: 0.3333 - val_accuracy: 0.8387\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4169 - accuracy: 0.7967 - val_loss: 0.3146 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4556 - accuracy: 0.7480 - val_loss: 0.2872 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4041 - accuracy: 0.7805 - val_loss: 0.3162 - val_accuracy: 0.8710\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3772 - accuracy: 0.8430 - val_loss: 0.3270 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4166 - accuracy: 0.7769 - val_loss: 0.3205 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3443 - accuracy: 0.8430 - val_loss: 0.3381 - val_accuracy: 0.8387\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3868 - accuracy: 0.8211 - val_loss: 0.3609 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3982 - accuracy: 0.8374 - val_loss: 0.3826 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4691 - accuracy: 0.7724 - val_loss: 0.3339 - val_accuracy: 0.7742\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.3490 - accuracy: 0.8537 - val_loss: 0.5481 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3731 - accuracy: 0.7805 - val_loss: 0.5101 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4815 - accuracy: 0.8374 - val_loss: 0.4209 - val_accuracy: 0.8710\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4382 - accuracy: 0.7603 - val_loss: 0.3701 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4069 - accuracy: 0.7851 - val_loss: 0.4029 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4475 - accuracy: 0.7438 - val_loss: 0.3975 - val_accuracy: 0.8710\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3804 - accuracy: 0.8374 - val_loss: 0.5043 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4273 - accuracy: 0.8130 - val_loss: 0.4473 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4091 - accuracy: 0.8537 - val_loss: 0.4466 - val_accuracy: 0.8065\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3948 - accuracy: 0.8130 - val_loss: 0.4217 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3986 - accuracy: 0.7967 - val_loss: 0.3928 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.3547 - accuracy: 0.8049 - val_loss: 0.3827 - val_accuracy: 0.8387\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3716 - accuracy: 0.7886 - val_loss: 0.4380 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4266 - accuracy: 0.8374 - val_loss: 0.3828 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3890 - accuracy: 0.7642 - val_loss: 0.4054 - val_accuracy: 0.7419\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.4415 - accuracy: 0.7317 - val_loss: 0.5530 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.6038 - accuracy: 0.7398 - val_loss: 0.4279 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.4440 - accuracy: 0.7805 - val_loss: 0.4256 - val_accuracy: 0.8065\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.3497 - accuracy: 0.8455 - val_loss: 0.5383 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.3653 - accuracy: 0.7886 - val_loss: 0.3848 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.3229 - accuracy: 0.8618 - val_loss: 0.3853 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.4727 - accuracy: 0.7480 - val_loss: 0.4582 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.5594 - accuracy: 0.7561 - val_loss: 0.3797 - val_accuracy: 0.8387\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.4634 - accuracy: 0.8780 - val_loss: 0.3965 - val_accuracy: 0.7742\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.3823 - accuracy: 0.7805 - val_loss: 0.2946 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.3778 - accuracy: 0.8293 - val_loss: 0.2934 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.3669 - accuracy: 0.8049 - val_loss: 0.3508 - val_accuracy: 0.8710\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3292 - accuracy: 0.8512 - val_loss: 0.5809 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3581 - accuracy: 0.8264 - val_loss: 0.3995 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.2991 - accuracy: 0.8843 - val_loss: 0.4226 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4423 - accuracy: 0.7724 - val_loss: 0.4754 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.4273 - accuracy: 0.7886 - val_loss: 0.6158 - val_accuracy: 0.6129\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4726 - accuracy: 0.7317 - val_loss: 0.4917 - val_accuracy: 0.6129\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.3031 - accuracy: 0.8595 - val_loss: 0.4196 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3143 - accuracy: 0.8512 - val_loss: 0.3546 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3192 - accuracy: 0.9174 - val_loss: 0.3384 - val_accuracy: 0.8387\n",
            "Publisher: global iteration=39\n",
            "Publisher: master=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.4069 - accuracy: 0.8049 - val_loss: 0.6126 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3911 - accuracy: 0.8049 - val_loss: 0.5775 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.3700 - accuracy: 0.8211 - val_loss: 0.7672 - val_accuracy: 0.6452\n",
            "Publisher: master=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.3503 - accuracy: 0.8699 - val_loss: 0.4377 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5167 - accuracy: 0.7805 - val_loss: 0.3059 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3367 - accuracy: 0.8455 - val_loss: 0.3433 - val_accuracy: 0.7742\n",
            "Publisher: master=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4174 - accuracy: 0.8699 - val_loss: 0.3073 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4141 - accuracy: 0.8455 - val_loss: 0.3413 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4463 - accuracy: 0.7886 - val_loss: 0.3200 - val_accuracy: 0.8387\n",
            "Publisher: master=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.3368 - accuracy: 0.8455 - val_loss: 0.3857 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3909 - accuracy: 0.8130 - val_loss: 0.3851 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4231 - accuracy: 0.8293 - val_loss: 0.3889 - val_accuracy: 0.7097\n",
            "Publisher: master=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.3411 - accuracy: 0.8512 - val_loss: 0.3481 - val_accuracy: 0.8065\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.4759 - accuracy: 0.7934 - val_loss: 0.3450 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.3537 - accuracy: 0.8264 - val_loss: 0.3621 - val_accuracy: 0.7742\n",
            "Publisher: master=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.4086 - accuracy: 0.8049 - val_loss: 0.4509 - val_accuracy: 0.7419\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.4534 - accuracy: 0.7480 - val_loss: 0.4439 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4815 - accuracy: 0.7967 - val_loss: 0.4276 - val_accuracy: 0.7419\n",
            "Publisher: master=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3734 - accuracy: 0.8618 - val_loss: 0.3697 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.3503 - accuracy: 0.7724 - val_loss: 0.4024 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4457 - accuracy: 0.7724 - val_loss: 0.3635 - val_accuracy: 0.8065\n",
            "Publisher: master=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.4357 - accuracy: 0.8455 - val_loss: 0.3645 - val_accuracy: 0.8710\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4169 - accuracy: 0.8618 - val_loss: 0.3931 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4127 - accuracy: 0.7886 - val_loss: 0.3458 - val_accuracy: 0.8065\n",
            "Publisher: master=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4021 - accuracy: 0.8293 - val_loss: 0.5866 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3860 - accuracy: 0.8455 - val_loss: 0.9346 - val_accuracy: 0.5484\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.4806 - accuracy: 0.7724 - val_loss: 0.6500 - val_accuracy: 0.6129\n",
            "Publisher: master=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.4529 - accuracy: 0.7805 - val_loss: 0.3588 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4368 - accuracy: 0.7805 - val_loss: 0.4306 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4082 - accuracy: 0.7480 - val_loss: 0.5044 - val_accuracy: 0.6774\n",
            "Publisher: master=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4625 - accuracy: 0.7967 - val_loss: 0.4546 - val_accuracy: 0.8387\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.5039 - accuracy: 0.7724 - val_loss: 0.3380 - val_accuracy: 0.8710\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4378 - accuracy: 0.7561 - val_loss: 0.3438 - val_accuracy: 0.8387\n",
            "Publisher: master=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.4478 - accuracy: 0.7642 - val_loss: 0.3837 - val_accuracy: 0.9032\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.4930 - accuracy: 0.8130 - val_loss: 0.3800 - val_accuracy: 0.7097\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.4627 - accuracy: 0.6667 - val_loss: 0.3814 - val_accuracy: 0.7742\n",
            "Publisher: master=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.3666 - accuracy: 0.8455 - val_loss: 0.5220 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3606 - accuracy: 0.8537 - val_loss: 0.5714 - val_accuracy: 0.6452\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.3595 - accuracy: 0.8211 - val_loss: 0.4746 - val_accuracy: 0.7419\n",
            "Publisher: master=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.4373 - accuracy: 0.8049 - val_loss: 0.3393 - val_accuracy: 0.9677\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4958 - accuracy: 0.7642 - val_loss: 0.2918 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4158 - accuracy: 0.8049 - val_loss: 0.3179 - val_accuracy: 0.8065\n",
            "Publisher: master=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.3519 - accuracy: 0.8537 - val_loss: 0.6091 - val_accuracy: 0.6774\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.3486 - accuracy: 0.7724 - val_loss: 0.5674 - val_accuracy: 0.8065\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.4333 - accuracy: 0.8455 - val_loss: 0.7115 - val_accuracy: 0.6774\n",
            "Publisher: master=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3565 - accuracy: 0.8211 - val_loss: 0.7153 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3628 - accuracy: 0.7967 - val_loss: 0.5137 - val_accuracy: 0.7419\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.4310 - accuracy: 0.8862 - val_loss: 0.5008 - val_accuracy: 0.7742\n",
            "Publisher: master=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3802 - accuracy: 0.8211 - val_loss: 0.3494 - val_accuracy: 0.7742\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 74ms/step - loss: 0.3669 - accuracy: 0.7724 - val_loss: 0.3101 - val_accuracy: 0.7742\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.3582 - accuracy: 0.7724 - val_loss: 0.3607 - val_accuracy: 0.8710\n",
            "Publisher: master=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.4218 - accuracy: 0.8264 - val_loss: 0.9063 - val_accuracy: 0.6452\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5668 - accuracy: 0.6942 - val_loss: 0.6018 - val_accuracy: 0.6774\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.4282 - accuracy: 0.8264 - val_loss: 0.5785 - val_accuracy: 0.6774\n",
            "Publisher: finished all global\n",
            "Accuracy on Val Data:  [0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.7759, 0.7965, 0.7802, 0.8201, 0.7802, 0.7972, 0.8342, 0.7958, 0.8009, 0.7951, 0.7846, 0.8345, 0.769]\n"
          ]
        }
      ],
      "source": [
        "acc_pdfl_covid = pair_wise_xp(np.copy(x_covid), np.copy(y_covid), get_covid_model(), [1, 2, 3, 4, 6, 9, 12, 18], 36, 40, 3, deep_copy_covid_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "mDqTPpDVChdT",
        "outputId": "b4ad78cd-9283-4302-bd97-a33151f680dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: [0.7476, 0.7476, 0.7476, 0.7476, 0.7476, 0.7476, 0.7476, 0.8353, 0.865, 0.8704, 0.8497, 0.8729, 0.8718, 0.8878, 0.8849, 0.8899, 0.8968, 0.8983, 0.9088, 0.9084, 0.9135, 0.9214, 0.92, 0.92, 0.9265, 0.9207, 0.9272, 0.9283, 0.9229, 0.9283, 0.9272, 0.9312, 0.9359, 0.928, 0.9377, 0.9348, 0.9395, 0.9348, 0.9341, 0.9399], 1: [0.7433, 0.7433, 0.7433, 0.7433, 0.7433, 0.7433, 0.7433, 0.7433, 0.8298, 0.8335, 0.8215, 0.8244, 0.8009, 0.8385, 0.844, 0.8577, 0.8682, 0.8664, 0.8733, 0.8831, 0.8537, 0.8827, 0.8653, 0.882, 0.8755, 0.8932, 0.8689, 0.8943, 0.8888, 0.9048, 0.8961, 0.9012, 0.8986, 0.9131, 0.9084, 0.9084, 0.9109, 0.9167, 0.895, 0.8736], 2: [0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.7364, 0.8009, 0.7672, 0.8085, 0.7936, 0.8389, 0.8168, 0.8284, 0.8114, 0.8331, 0.8335, 0.8302, 0.8519, 0.8483, 0.8577, 0.8559, 0.865, 0.7994, 0.8635, 0.8447, 0.8726, 0.8367, 0.8635, 0.8671, 0.8758, 0.8682, 0.8802, 0.8787], 3: [0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7332, 0.7864, 0.7904, 0.7954, 0.7744, 0.8418, 0.7578, 0.8269, 0.794, 0.8555, 0.828, 0.8693, 0.8592, 0.8726, 0.8472, 0.8657, 0.8762, 0.8809, 0.8624, 0.8715, 0.8678, 0.8805, 0.8628, 0.8921, 0.8552], 4: [0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.7448, 0.8016, 0.7654, 0.8146, 0.8244, 0.8081, 0.8501, 0.7585, 0.8494, 0.8237, 0.8139, 0.807, 0.849, 0.8407, 0.8635, 0.8045, 0.8733, 0.8443, 0.8555, 0.8689, 0.8364, 0.8769, 0.8639, 0.8707, 0.8776, 0.8454], 5: [0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7361, 0.7781, 0.7918, 0.8038, 0.7925, 0.7715, 0.7976, 0.798, 0.8266, 0.8103, 0.8378], 6: [0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7419, 0.7549, 0.7534, 0.7607, 0.7444, 0.7741, 0.7857, 0.807, 0.7886, 0.7621, 0.819, 0.8342], 7: [0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.739, 0.7759, 0.7965, 0.7802, 0.8201, 0.7802, 0.7972, 0.8342, 0.7958, 0.8009, 0.7951, 0.7846, 0.8345, 0.769]}\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(acc_pdfl_covid)\n",
        "np.save(\"acc_pdfl_covid.npy\",acc_pdfl_covid)\n",
        "pair_wise_post_process(acc_pdfl_covid,  [1, 2, 3, 4, 6, 9, 12, 18], 36, 40, [0.80, 0.75])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSvvuyuMVkqg",
        "outputId": "d9533740-c484-4362-d63a-0b38ec7eb4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6335 - accuracy: 0.7500 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6747 - accuracy: 0.7500 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5509 - accuracy: 0.7500 - val_loss: 0.7027 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5206 - accuracy: 0.7500 - val_loss: 0.6730 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4091 - accuracy: 0.8750 - val_loss: 0.5808 - val_accuracy: 1.0000\n",
            "Masterwork: peer=29\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5873 - accuracy: 0.6250 - val_loss: 0.3799 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5424 - accuracy: 0.6250 - val_loss: 0.3103 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5725 - accuracy: 0.6250 - val_loss: 0.5305 - val_accuracy: 0.6667\n",
            "Masterwork: peer=85\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.5803 - accuracy: 0.7500 - val_loss: 0.7055 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4848 - accuracy: 0.7500 - val_loss: 0.7166 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4717 - accuracy: 0.7500 - val_loss: 0.6970 - val_accuracy: 0.6667\n",
            "Publisher: master=1\n",
            "[78, 20, 87, 11, 81, 2, 37, 49, 52, 33]\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.4056 - accuracy: 0.7500 - val_loss: 0.3678 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4936 - accuracy: 0.7500 - val_loss: 0.6642 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2597 - accuracy: 0.7500 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5086 - accuracy: 0.8750 - val_loss: 0.5107 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3448 - accuracy: 0.8750 - val_loss: 0.3575 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3877 - accuracy: 0.8750 - val_loss: 0.4088 - val_accuracy: 1.0000\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.3985 - accuracy: 0.7500 - val_loss: 1.9916 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6688 - accuracy: 0.7500 - val_loss: 0.7105 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3442 - accuracy: 0.7500 - val_loss: 0.6910 - val_accuracy: 0.6667\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3021 - accuracy: 0.7500 - val_loss: 0.1148 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3266 - accuracy: 0.8750 - val_loss: 0.5892 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3094 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.3333\n",
            "Masterwork: peer=81\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.5409 - accuracy: 0.6250 - val_loss: 0.5154 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3863 - accuracy: 0.8750 - val_loss: 0.1985 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.0572 - accuracy: 0.6250 - val_loss: 0.6640 - val_accuracy: 0.3333\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.7689 - accuracy: 0.6250 - val_loss: 0.6965 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6356 - accuracy: 0.7500 - val_loss: 0.6966 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6499 - accuracy: 0.8750 - val_loss: 0.6966 - val_accuracy: 0.3333\n",
            "Masterwork: peer=37\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3963 - accuracy: 0.8750 - val_loss: 1.4948 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3159 - accuracy: 0.8750 - val_loss: 0.8217 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2509 - accuracy: 0.8750 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3909 - accuracy: 0.7500 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2842 - accuracy: 0.7500 - val_loss: 0.6965 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3410 - accuracy: 0.8750 - val_loss: 0.6100 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3563 - accuracy: 0.7500 - val_loss: 0.4908 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3981 - accuracy: 0.7500 - val_loss: 0.6967 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3308 - accuracy: 1.0000 - val_loss: 0.6969 - val_accuracy: 0.3333\n",
            "Masterwork: peer=33\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4358 - accuracy: 0.7500 - val_loss: 0.3847 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.5177 - accuracy: 0.7500 - val_loss: 0.4183 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.4005 - accuracy: 0.7500 - val_loss: 0.4133 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "[76, 38, 57, 96, 49, 50, 29, 88, 26, 11]\n",
            "Masterwork: peer=76\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.0172 - accuracy: 0.6250 - val_loss: 0.6864 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6595 - accuracy: 0.6250 - val_loss: 0.6895 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6580 - accuracy: 0.6250 - val_loss: 0.6813 - val_accuracy: 0.6667\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5840 - accuracy: 0.6250 - val_loss: 0.6475 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5281 - accuracy: 0.6250 - val_loss: 0.5295 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.1354 - accuracy: 0.6250 - val_loss: 0.6735 - val_accuracy: 0.6667\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.8089 - accuracy: 0.5000 - val_loss: 0.6959 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6619 - accuracy: 0.5000 - val_loss: 0.6949 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6665 - accuracy: 0.6250 - val_loss: 0.6911 - val_accuracy: 0.3333\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3865 - accuracy: 0.8750 - val_loss: 0.2409 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1453 - accuracy: 0.8750 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1185 - accuracy: 0.8750 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.4180 - accuracy: 0.8750 - val_loss: 0.4666 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3016 - accuracy: 0.8750 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3877 - accuracy: 0.8750 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.4065 - accuracy: 0.8750 - val_loss: 0.5450 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6261 - accuracy: 0.8750 - val_loss: 0.5976 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2597 - accuracy: 0.8750 - val_loss: 0.6251 - val_accuracy: 0.6667\n",
            "Masterwork: peer=29\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.6308 - accuracy: 0.5000 - val_loss: 0.4081 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5376 - accuracy: 0.7500 - val_loss: 0.4581 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.4954 - val_accuracy: 0.6667\n",
            "Masterwork: peer=88\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.2507 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=26\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.5251 - accuracy: 0.7500 - val_loss: 0.6139 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4239 - accuracy: 0.7500 - val_loss: 0.5088 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4185 - accuracy: 0.7500 - val_loss: 0.6358 - val_accuracy: 0.3333\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.4166 - accuracy: 0.8750 - val_loss: 0.4872 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2394 - accuracy: 0.8750 - val_loss: 0.5688 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.1617 - accuracy: 0.8750 - val_loss: 0.5479 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "[30, 63, 37, 39, 16, 29, 27, 93, 60, 80]\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4424 - accuracy: 0.7500 - val_loss: 0.7481 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7514 - accuracy: 0.7500 - val_loss: 0.6496 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4388 - accuracy: 0.7500 - val_loss: 0.6674 - val_accuracy: 0.3333\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.6940 - accuracy: 0.8750 - val_loss: 0.6638 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4099 - accuracy: 0.8750 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2663 - accuracy: 0.8750 - val_loss: 0.5412 - val_accuracy: 0.6667\n",
            "Masterwork: peer=37\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.4080 - accuracy: 0.8750 - val_loss: 0.3434 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4281 - accuracy: 0.8750 - val_loss: 0.4222 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3580 - accuracy: 0.8750 - val_loss: 0.4458 - val_accuracy: 0.6667\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3751 - accuracy: 0.8750 - val_loss: 0.3743 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4898 - accuracy: 0.8750 - val_loss: 0.5762 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.2374 - accuracy: 0.8750 - val_loss: 0.6053 - val_accuracy: 0.6667\n",
            "Masterwork: peer=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.5698 - accuracy: 0.5000 - val_loss: 0.6899 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5630 - accuracy: 1.0000 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4737 - accuracy: 0.8750 - val_loss: 0.6485 - val_accuracy: 1.0000\n",
            "Masterwork: peer=29\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3748 - accuracy: 0.8750 - val_loss: 0.2870 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3586 - accuracy: 0.8750 - val_loss: 0.2449 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2940 - accuracy: 0.8750 - val_loss: 0.2667 - val_accuracy: 1.0000\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.2109 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3984 - accuracy: 0.7500 - val_loss: 0.4859 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3917 - accuracy: 0.7500 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3306 - accuracy: 0.7500 - val_loss: 0.6706 - val_accuracy: 0.6667\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.4193 - accuracy: 0.8750 - val_loss: 0.3670 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3615 - accuracy: 0.8750 - val_loss: 0.4144 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3595 - accuracy: 0.8750 - val_loss: 0.4518 - val_accuracy: 0.6667\n",
            "Masterwork: peer=80\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.6634 - accuracy: 0.5000 - val_loss: 0.6998 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6285 - accuracy: 0.8750 - val_loss: 0.7036 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6001 - accuracy: 0.8750 - val_loss: 0.6548 - val_accuracy: 0.6667\n",
            "Publisher: master=4\n",
            "[38, 43, 57, 14, 49, 27, 79, 52, 74, 78]\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3266 - accuracy: 0.8750 - val_loss: 0.2613 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2268 - accuracy: 0.8750 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4685 - accuracy: 0.8750 - val_loss: 0.2826 - val_accuracy: 1.0000\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6698 - accuracy: 0.3750 - val_loss: 0.5528 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5160 - accuracy: 0.6250 - val_loss: 0.6969 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5580 - accuracy: 0.8750 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3965 - accuracy: 0.6250 - val_loss: 0.5062 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.9670 - accuracy: 0.6250 - val_loss: 0.6708 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4540 - accuracy: 1.0000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.2056 - accuracy: 1.0000 - val_loss: 0.6447 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.9123 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 41.6843 - val_accuracy: 0.6667\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.7461 - accuracy: 0.5000 - val_loss: 0.6899 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6124 - accuracy: 0.6250 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6678 - accuracy: 0.7500 - val_loss: 0.6894 - val_accuracy: 0.6667\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.3973 - accuracy: 0.7500 - val_loss: 0.6028 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3169 - accuracy: 0.7500 - val_loss: 0.6100 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3576 - accuracy: 0.7500 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3541 - accuracy: 0.8750 - val_loss: 0.8273 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2664 - accuracy: 0.8750 - val_loss: 0.7644 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2854 - accuracy: 0.8750 - val_loss: 0.7427 - val_accuracy: 0.3333\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.6119 - accuracy: 0.6250 - val_loss: 0.6004 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4767 - accuracy: 0.7500 - val_loss: 0.4601 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8342 - accuracy: 0.6250 - val_loss: 0.6756 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4353 - accuracy: 0.7500 - val_loss: 0.3999 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.8539 - accuracy: 0.7500 - val_loss: 0.6687 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4703 - accuracy: 0.7500 - val_loss: 0.6767 - val_accuracy: 0.6667\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3406 - accuracy: 0.7500 - val_loss: 0.6066 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3324 - accuracy: 0.7500 - val_loss: 0.4165 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3293 - accuracy: 0.7500 - val_loss: 0.6343 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "[35, 27, 53, 99, 0, 44, 52, 54, 30, 79]\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.8200 - accuracy: 0.6250 - val_loss: 0.6899 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6479 - accuracy: 0.7500 - val_loss: 0.6894 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6056 - accuracy: 0.6250 - val_loss: 0.6999 - val_accuracy: 0.3333\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.4176 - accuracy: 0.7500 - val_loss: 0.4861 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5450 - accuracy: 0.7500 - val_loss: 0.4976 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3858 - accuracy: 0.7500 - val_loss: 0.6127 - val_accuracy: 1.0000\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.8667 - accuracy: 0.7500 - val_loss: 0.6802 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6043 - accuracy: 0.7500 - val_loss: 0.6833 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5985 - accuracy: 0.7500 - val_loss: 0.6918 - val_accuracy: 0.3333\n",
            "Masterwork: peer=99\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.3942 - accuracy: 0.8750 - val_loss: 0.4217 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4476 - accuracy: 0.8750 - val_loss: 0.5459 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2728 - accuracy: 0.8750 - val_loss: 0.5613 - val_accuracy: 1.0000\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.4733 - accuracy: 0.7500 - val_loss: 0.1539 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7742 - accuracy: 0.7500 - val_loss: 0.5150 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3460 - accuracy: 0.7500 - val_loss: 0.6168 - val_accuracy: 1.0000\n",
            "Masterwork: peer=44\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4966 - accuracy: 0.8750 - val_loss: 0.4641 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4657 - accuracy: 0.8750 - val_loss: 0.4832 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3980 - accuracy: 0.8750 - val_loss: 0.5112 - val_accuracy: 1.0000\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3293 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.5273 - accuracy: 0.6250 - val_loss: 0.6674 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5096 - accuracy: 0.6250 - val_loss: 0.4467 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3952 - accuracy: 0.6250 - val_loss: 0.1693 - val_accuracy: 1.0000\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6284 - accuracy: 0.6250 - val_loss: 0.6965 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5148 - accuracy: 0.7500 - val_loss: 0.6911 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8025 - accuracy: 0.6250 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3424 - accuracy: 0.7500 - val_loss: 0.4018 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2644 - accuracy: 0.8750 - val_loss: 0.6774 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2718 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
            "Publisher: master=6\n",
            "[51, 22, 74, 20, 27, 0, 28, 77, 88, 80]\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5370 - accuracy: 0.7500 - val_loss: 0.1067 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7772 - accuracy: 0.7500 - val_loss: 0.3752 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4322 - accuracy: 0.7500 - val_loss: 0.5500 - val_accuracy: 1.0000\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3995 - accuracy: 0.7500 - val_loss: 0.5346 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3819 - accuracy: 0.8750 - val_loss: 0.6923 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3700 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.5004 - accuracy: 0.6250 - val_loss: 0.6641 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3570 - accuracy: 0.7500 - val_loss: 0.5310 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4535 - accuracy: 0.7500 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3930 - accuracy: 0.7500 - val_loss: 0.6859 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4537 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5150 - accuracy: 0.7500 - val_loss: 0.6636 - val_accuracy: 1.0000\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.2871 - accuracy: 0.8750 - val_loss: 0.2266 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3849 - accuracy: 0.8750 - val_loss: 0.5385 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1952 - accuracy: 0.8750 - val_loss: 0.6246 - val_accuracy: 1.0000\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3828 - accuracy: 0.8750 - val_loss: 0.1109 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3184 - accuracy: 0.8750 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2759 - accuracy: 0.8750 - val_loss: 0.1573 - val_accuracy: 1.0000\n",
            "Masterwork: peer=28\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.4538 - accuracy: 0.7500 - val_loss: 0.6157 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3997 - accuracy: 0.7500 - val_loss: 0.6803 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3529 - accuracy: 0.7500 - val_loss: 0.6087 - val_accuracy: 0.6667\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 1.2551 - accuracy: 0.7500 - val_loss: 0.6833 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6695 - accuracy: 0.7500 - val_loss: 0.6877 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5857 - accuracy: 0.7500 - val_loss: 0.8171 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=88\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6767 - accuracy: 0.5000 - val_loss: 0.5655 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6108 - accuracy: 0.7500 - val_loss: 0.4040 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5833 - accuracy: 0.6250 - val_loss: 0.1411 - val_accuracy: 1.0000\n",
            "Masterwork: peer=80\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.5106 - accuracy: 0.7500 - val_loss: 0.6774 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3713 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3053 - accuracy: 0.7500 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Publisher: master=7\n",
            "[1, 12, 9, 62, 21, 31, 52, 63, 35, 66]\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6072 - accuracy: 0.5000 - val_loss: 0.3729 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.1544 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5878 - accuracy: 0.5000 - val_loss: 0.3553 - val_accuracy: 0.6667\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.3966 - accuracy: 0.8750 - val_loss: 0.9937 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2954 - accuracy: 0.8750 - val_loss: 0.7306 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3097 - accuracy: 0.8750 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.5944 - accuracy: 0.7500 - val_loss: 0.3698 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4757 - accuracy: 0.7500 - val_loss: 0.3263 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4159 - accuracy: 0.7500 - val_loss: 0.3954 - val_accuracy: 1.0000\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.8008 - accuracy: 0.5000 - val_loss: 0.7032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6158 - accuracy: 0.5000 - val_loss: 0.7040 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6506 - accuracy: 0.6250 - val_loss: 0.7047 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=21\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.6532 - accuracy: 0.6250 - val_loss: 0.6866 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.6006 - accuracy: 0.7500 - val_loss: 0.6833 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5883 - accuracy: 0.6250 - val_loss: 0.6904 - val_accuracy: 0.3333\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4654 - accuracy: 0.8750 - val_loss: 0.5078 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4772 - accuracy: 0.8750 - val_loss: 0.5219 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3208 - accuracy: 0.8750 - val_loss: 0.5249 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.1679 - accuracy: 1.0000 - val_loss: 0.1314 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1112e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 1.5763 - accuracy: 0.8750 - val_loss: 0.6789 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5215 - accuracy: 0.8750 - val_loss: 0.6588 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3357 - accuracy: 0.8750 - val_loss: 0.6308 - val_accuracy: 0.6667\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.4321 - accuracy: 0.7500 - val_loss: 0.6394 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3377 - accuracy: 0.7500 - val_loss: 0.6202 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3406 - accuracy: 0.7500 - val_loss: 0.6025 - val_accuracy: 0.6667\n",
            "Masterwork: peer=66\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.6850 - accuracy: 0.6250 - val_loss: 0.6772 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6189 - accuracy: 0.7500 - val_loss: 0.5788 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4651 - accuracy: 0.7500 - val_loss: 0.3573 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "[83, 71, 20, 15, 34, 54, 17, 94, 53, 43]\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.2918 - accuracy: 0.8750 - val_loss: 0.2810 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5689 - accuracy: 0.8750 - val_loss: 0.5165 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2264 - accuracy: 0.8750 - val_loss: 0.5956 - val_accuracy: 1.0000\n",
            "Masterwork: peer=71\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3292 - accuracy: 0.7500 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7346 - accuracy: 0.7500 - val_loss: 0.4238 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2781 - accuracy: 0.7500 - val_loss: 0.6482 - val_accuracy: 1.0000\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.5235 - accuracy: 0.6250 - val_loss: 0.1115 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4916 - accuracy: 0.6250 - val_loss: 0.6549 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6485 - accuracy: 1.0000 - val_loss: 0.6894 - val_accuracy: 0.3333\n",
            "Masterwork: peer=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.5833 - accuracy: 0.8750 - val_loss: 0.3736 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5012 - accuracy: 0.7500 - val_loss: 0.4093 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3708 - accuracy: 0.7500 - val_loss: 0.4359 - val_accuracy: 1.0000\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5420 - accuracy: 0.8750 - val_loss: 0.6603 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2857 - accuracy: 0.8750 - val_loss: 0.5758 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5277 - accuracy: 0.8750 - val_loss: 0.6236 - val_accuracy: 0.6667\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.6317 - accuracy: 0.6250 - val_loss: 0.6884 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5483 - accuracy: 0.6250 - val_loss: 0.5763 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4375 - accuracy: 0.6250 - val_loss: 0.2725 - val_accuracy: 1.0000\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.4921 - accuracy: 0.7500 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5746 - accuracy: 0.7500 - val_loss: 0.4069 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3716 - accuracy: 0.7500 - val_loss: 0.4513 - val_accuracy: 1.0000\n",
            "Masterwork: peer=94\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4072 - accuracy: 0.8750 - val_loss: 0.4576 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4357 - accuracy: 0.8750 - val_loss: 0.6068 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2312 - accuracy: 0.8750 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.6489 - accuracy: 0.7500 - val_loss: 0.6731 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5246 - accuracy: 0.7500 - val_loss: 0.6545 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.5594 - val_accuracy: 1.0000\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3919 - accuracy: 0.8750 - val_loss: 1.4265 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4836 - accuracy: 0.8750 - val_loss: 0.5827 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3413 - accuracy: 0.8750 - val_loss: 0.5393 - val_accuracy: 0.3333\n",
            "Publisher: master=9\n",
            "[77, 24, 64, 34, 8, 22, 86, 53, 70, 93]\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.3956 - accuracy: 0.7500 - val_loss: 0.7576 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2979 - accuracy: 0.7500 - val_loss: 0.5301 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3278 - accuracy: 0.8750 - val_loss: 0.9336 - val_accuracy: 0.6667\n",
            "Masterwork: peer=24\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 1.0422 - accuracy: 0.6250 - val_loss: 0.7032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6730 - accuracy: 0.6250 - val_loss: 0.7034 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.7031 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4358 - accuracy: 0.7500 - val_loss: 0.6736 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3920 - accuracy: 0.7500 - val_loss: 0.5376 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.2956 - accuracy: 0.7500 - val_loss: 0.2683 - val_accuracy: 0.6667\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.4565 - accuracy: 0.7500 - val_loss: 0.4889 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2647 - accuracy: 0.7500 - val_loss: 0.4925 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.4624 - accuracy: 0.7500 - val_loss: 0.4899 - val_accuracy: 0.6667\n",
            "Masterwork: peer=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.4299 - accuracy: 0.7500 - val_loss: 0.4447 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7229 - accuracy: 0.7500 - val_loss: 0.5430 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4077 - accuracy: 0.7500 - val_loss: 0.6589 - val_accuracy: 0.6667\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.2944 - accuracy: 0.8750 - val_loss: 0.1285 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7723 - accuracy: 0.8750 - val_loss: 0.4071 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2222 - accuracy: 0.8750 - val_loss: 0.5053 - val_accuracy: 1.0000\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8863 - accuracy: 0.8750 - val_loss: 0.6026 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4471 - accuracy: 0.8750 - val_loss: 0.5573 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3785 - accuracy: 0.8750 - val_loss: 0.5777 - val_accuracy: 0.6667\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.2749 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=70\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4596 - accuracy: 0.7500 - val_loss: 0.5103 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4205 - accuracy: 0.7500 - val_loss: 0.5477 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3913 - accuracy: 0.7500 - val_loss: 0.5601 - val_accuracy: 0.6667\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.3270 - accuracy: 0.8750 - val_loss: 0.8396 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5492 - accuracy: 0.8750 - val_loss: 0.7748 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3451 - accuracy: 0.8750 - val_loss: 0.7413 - val_accuracy: 0.3333\n",
            "Publisher: global iteration=34\n",
            "Publisher: master=0\n",
            "[87, 32, 75, 13, 20, 55, 99, 95, 74, 46]\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.2793 - accuracy: 1.0000 - val_loss: 0.2835 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.6292e-06 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.2511 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3785 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.1754 - accuracy: 0.8750 - val_loss: 1.7912 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1672 - accuracy: 0.8750 - val_loss: 1.5222 - val_accuracy: 0.6667\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6426 - accuracy: 0.7500 - val_loss: 0.5394 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6437 - accuracy: 0.7500 - val_loss: 0.6177 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4591 - accuracy: 0.7500 - val_loss: 0.5974 - val_accuracy: 1.0000\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3683 - accuracy: 1.0000 - val_loss: 0.1541 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1674 - accuracy: 0.8750 - val_loss: 4.9776e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7478 - accuracy: 0.8750 - val_loss: 0.1330 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4736 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1054 - accuracy: 1.0000 - val_loss: 6.5858 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 74.2570 - val_accuracy: 0.6667\n",
            "Masterwork: peer=99\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.7094 - accuracy: 0.6250 - val_loss: 0.4948 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7291 - accuracy: 0.5000 - val_loss: 0.5008 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6865 - accuracy: 0.5000 - val_loss: 0.4848 - val_accuracy: 0.6667\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4235 - accuracy: 0.8750 - val_loss: 0.2448 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5579 - accuracy: 0.8750 - val_loss: 0.4504 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3056 - accuracy: 0.8750 - val_loss: 0.5242 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5876 - accuracy: 0.6250 - val_loss: 0.4808 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4721 - accuracy: 0.6250 - val_loss: 0.4570 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6974 - accuracy: 0.6250 - val_loss: 0.5484 - val_accuracy: 0.6667\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.5569 - accuracy: 0.6250 - val_loss: 0.6193 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5414 - accuracy: 0.6250 - val_loss: 0.6794 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5239 - accuracy: 0.6250 - val_loss: 0.6881 - val_accuracy: 0.6667\n",
            "Publisher: master=1\n",
            "[49, 45, 75, 19, 92, 27, 3, 35, 81, 23]\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.3962 - accuracy: 0.7500 - val_loss: 0.4602 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.8728 - accuracy: 0.7500 - val_loss: 0.5023 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3524 - accuracy: 0.7500 - val_loss: 0.6456 - val_accuracy: 0.6667\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5230 - accuracy: 0.6250 - val_loss: 0.3552 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5325 - accuracy: 0.8750 - val_loss: 0.3905 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4289 - accuracy: 0.8750 - val_loss: 0.4059 - val_accuracy: 1.0000\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.6164 - accuracy: 0.5000 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6653 - accuracy: 0.7500 - val_loss: 0.6711 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6008 - accuracy: 0.6250 - val_loss: 0.5766 - val_accuracy: 0.6667\n",
            "Masterwork: peer=19\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4831 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 1.1921e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=92\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.5182 - accuracy: 0.8750 - val_loss: 0.7081 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4840 - accuracy: 0.8750 - val_loss: 0.8163 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3748 - accuracy: 0.8750 - val_loss: 0.9668 - val_accuracy: 0.3333\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3483 - accuracy: 0.8750 - val_loss: 0.4169 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3319 - accuracy: 0.8750 - val_loss: 0.4126 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2916 - accuracy: 0.8750 - val_loss: 0.4501 - val_accuracy: 1.0000\n",
            "Masterwork: peer=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3961 - accuracy: 0.8750 - val_loss: 0.8180 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4613 - accuracy: 0.8750 - val_loss: 0.7255 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2737 - accuracy: 0.8750 - val_loss: 0.7086 - val_accuracy: 0.3333\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4900 - accuracy: 0.7500 - val_loss: 0.4931 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4553 - accuracy: 0.6250 - val_loss: 0.5816 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4583 - accuracy: 0.6250 - val_loss: 0.5271 - val_accuracy: 0.6667\n",
            "Masterwork: peer=81\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.5009 - accuracy: 0.8750 - val_loss: 0.1456 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7039 - accuracy: 0.6250 - val_loss: 0.5053 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4520 - accuracy: 0.6250 - val_loss: 0.6210 - val_accuracy: 1.0000\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.4699 - accuracy: 0.7500 - val_loss: 0.0901 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5182 - accuracy: 0.7500 - val_loss: 0.2952 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4861 - accuracy: 0.7500 - val_loss: 0.4899 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "[90, 34, 39, 9, 13, 32, 95, 55, 74, 22]\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.4792 - accuracy: 0.8750 - val_loss: 0.1126 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4568 - accuracy: 0.8750 - val_loss: 0.2100 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3456 - accuracy: 0.8750 - val_loss: 0.2534 - val_accuracy: 1.0000\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.4548 - accuracy: 0.8750 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2050 - accuracy: 0.8750 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.5069 - accuracy: 0.8750 - val_loss: 0.1599 - val_accuracy: 1.0000\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5391 - accuracy: 0.6250 - val_loss: 0.6324 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4006 - accuracy: 0.7500 - val_loss: 0.2753 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8207 - accuracy: 0.7500 - val_loss: 0.5683 - val_accuracy: 1.0000\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3862 - accuracy: 0.8750 - val_loss: 0.3428 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3470 - accuracy: 0.8750 - val_loss: 0.3239 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2577 - accuracy: 0.8750 - val_loss: 0.3194 - val_accuracy: 0.6667\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.7012 - accuracy: 0.6250 - val_loss: 0.6756 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6493 - accuracy: 0.6250 - val_loss: 0.6649 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6512 - accuracy: 0.6250 - val_loss: 0.6419 - val_accuracy: 0.6667\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6317 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4342 - accuracy: 0.7500 - val_loss: 0.3774 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3891 - accuracy: 0.7500 - val_loss: 0.4320 - val_accuracy: 1.0000\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.2524 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2536 - accuracy: 0.8750 - val_loss: 0.1623 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2178 - accuracy: 0.8750 - val_loss: 0.2084 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4271 - accuracy: 0.7500 - val_loss: 1.2950 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6861 - accuracy: 0.7500 - val_loss: 0.7090 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3914 - accuracy: 0.7500 - val_loss: 0.6906 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4381 - accuracy: 0.7500 - val_loss: 0.2481 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5647 - accuracy: 0.7500 - val_loss: 0.3448 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4529 - accuracy: 0.7500 - val_loss: 0.4384 - val_accuracy: 1.0000\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.4215 - accuracy: 1.0000 - val_loss: 0.7416 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.4783 - accuracy: 0.7500 - val_loss: 0.5766 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4251 - accuracy: 0.7500 - val_loss: 0.6153 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "[33, 55, 35, 68, 9, 94, 19, 60, 49, 56]\n",
            "Masterwork: peer=33\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.5585 - accuracy: 0.7500 - val_loss: 0.2609 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6212 - accuracy: 0.6250 - val_loss: 0.3079 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5173 - accuracy: 0.6250 - val_loss: 0.4076 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.5166 - accuracy: 0.8750 - val_loss: 0.6175 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5358 - accuracy: 0.7500 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3935 - accuracy: 0.7500 - val_loss: 0.6944 - val_accuracy: 0.3333\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.3675 - accuracy: 0.7500 - val_loss: 0.4676 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4809 - accuracy: 0.6250 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3864 - accuracy: 0.7500 - val_loss: 0.7058 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=68\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4301 - accuracy: 0.7500 - val_loss: 0.4002 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3130 - accuracy: 0.8750 - val_loss: 0.3654 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2966 - accuracy: 0.8750 - val_loss: 0.3984 - val_accuracy: 1.0000\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5663 - accuracy: 0.8750 - val_loss: 0.0465 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9153 - accuracy: 0.5000 - val_loss: 0.4894 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4973 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.6667\n",
            "Masterwork: peer=94\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3936 - accuracy: 0.8750 - val_loss: 0.1268 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3206 - accuracy: 0.8750 - val_loss: 0.1648 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3161 - accuracy: 0.8750 - val_loss: 0.2386 - val_accuracy: 1.0000\n",
            "Masterwork: peer=19\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.7537 - accuracy: 0.7500 - val_loss: 0.6618 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6052 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4360 - accuracy: 0.7500 - val_loss: 0.7316 - val_accuracy: 0.3333\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.5799 - accuracy: 0.8750 - val_loss: 0.1091 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5707 - accuracy: 0.7500 - val_loss: 0.2544 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4184 - accuracy: 0.7500 - val_loss: 0.3034 - val_accuracy: 1.0000\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6322 - accuracy: 0.6250 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5468 - accuracy: 0.7500 - val_loss: 0.6886 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5622 - accuracy: 0.5000 - val_loss: 0.6869 - val_accuracy: 1.0000\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.5599 - accuracy: 0.6250 - val_loss: 0.4101 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5307 - accuracy: 0.6250 - val_loss: 0.4038 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5492 - accuracy: 0.6250 - val_loss: 0.4271 - val_accuracy: 0.6667\n",
            "Publisher: master=4\n",
            "[78, 95, 52, 15, 48, 60, 14, 4, 43, 1]\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3101 - accuracy: 0.8750 - val_loss: 1.4143 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3480 - accuracy: 0.8750 - val_loss: 0.7937 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2518 - accuracy: 0.8750 - val_loss: 0.5953 - val_accuracy: 0.3333\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.5047 - accuracy: 0.7500 - val_loss: 0.6263 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4818 - accuracy: 0.7500 - val_loss: 0.6156 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4992 - accuracy: 0.7500 - val_loss: 0.6259 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.6533 - accuracy: 0.5000 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6646 - accuracy: 0.7500 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6039 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.6667\n",
            "Masterwork: peer=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4710 - accuracy: 0.8750 - val_loss: 0.3461 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3439 - accuracy: 0.8750 - val_loss: 0.3870 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3310 - accuracy: 0.8750 - val_loss: 0.4198 - val_accuracy: 0.6667\n",
            "Masterwork: peer=48\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.4590 - accuracy: 0.8750 - val_loss: 0.5622 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5493 - accuracy: 0.8750 - val_loss: 0.6014 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3533 - accuracy: 0.8750 - val_loss: 0.5959 - val_accuracy: 1.0000\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.4129 - accuracy: 1.0000 - val_loss: 3.3177 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3229 - accuracy: 0.8750 - val_loss: 2.4159 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3508 - accuracy: 0.8750 - val_loss: 1.4299 - val_accuracy: 0.3333\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4992 - accuracy: 0.8750 - val_loss: 0.2176 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.3513 - accuracy: 0.8750 - val_loss: 0.2751 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2524 - accuracy: 0.8750 - val_loss: 0.3029 - val_accuracy: 1.0000\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 0.4927 - accuracy: 0.7500 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5662 - accuracy: 0.8750 - val_loss: 0.3356 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.3188 - accuracy: 0.8750 - val_loss: 0.4194 - val_accuracy: 1.0000\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.6046 - accuracy: 0.5000 - val_loss: 0.4626 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5499 - accuracy: 0.5000 - val_loss: 0.4663 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4956 - accuracy: 0.6250 - val_loss: 0.4607 - val_accuracy: 1.0000\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 1.1453 - accuracy: 0.7500 - val_loss: 0.6938 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6858 - accuracy: 0.7500 - val_loss: 0.6819 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5472 - accuracy: 0.6250 - val_loss: 0.6357 - val_accuracy: 0.6667\n",
            "Publisher: master=5\n",
            "[73, 15, 7, 47, 36, 39, 26, 29, 82, 43]\n",
            "Masterwork: peer=73\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4459 - accuracy: 0.8750 - val_loss: 1.5091 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1307 - accuracy: 0.7500 - val_loss: 0.7217 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3921 - accuracy: 0.7500 - val_loss: 0.7116 - val_accuracy: 0.3333\n",
            "Masterwork: peer=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.4604 - accuracy: 0.8750 - val_loss: 0.1767 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.2386 - accuracy: 0.8750 - val_loss: 1.9868e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.6238 - accuracy: 0.8750 - val_loss: 0.1131 - val_accuracy: 1.0000\n",
            "Masterwork: peer=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4778 - accuracy: 0.8750 - val_loss: 0.9786 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5397 - accuracy: 0.7500 - val_loss: 0.7248 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3858 - accuracy: 0.7500 - val_loss: 0.6672 - val_accuracy: 0.3333\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3785 - accuracy: 0.7500 - val_loss: 0.3621 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6260 - accuracy: 0.7500 - val_loss: 0.5695 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3860 - accuracy: 0.7500 - val_loss: 0.6675 - val_accuracy: 0.3333\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5310 - accuracy: 0.6250 - val_loss: 0.4849 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7723 - accuracy: 0.7500 - val_loss: 0.6256 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5115 - accuracy: 0.7500 - val_loss: 0.6917 - val_accuracy: 0.6667\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4313 - accuracy: 0.8750 - val_loss: 0.8855 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4210 - accuracy: 0.7500 - val_loss: 0.6170 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3651 - accuracy: 0.7500 - val_loss: 0.6059 - val_accuracy: 0.6667\n",
            "Masterwork: peer=26\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.7270 - accuracy: 0.5000 - val_loss: 0.7004 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6136 - accuracy: 0.7500 - val_loss: 0.7026 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5396 - accuracy: 0.8750 - val_loss: 0.5096 - val_accuracy: 0.6667\n",
            "Masterwork: peer=29\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.4829 - accuracy: 0.7500 - val_loss: 1.1599 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3890 - accuracy: 0.8750 - val_loss: 0.8267 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3860 - accuracy: 0.8750 - val_loss: 0.7229 - val_accuracy: 0.6667\n",
            "Masterwork: peer=82\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6010 - accuracy: 0.7500 - val_loss: 1.4674 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5233 - accuracy: 0.6250 - val_loss: 1.1255 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4497 - accuracy: 0.6250 - val_loss: 0.8115 - val_accuracy: 0.6667\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4740 - accuracy: 0.8750 - val_loss: 0.4278 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0460 - accuracy: 1.0000 - val_loss: 8.1602 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 79.1610 - val_accuracy: 0.6667\n",
            "Publisher: master=6\n",
            "[25, 44, 36, 14, 56, 77, 88, 65, 64, 97]\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.6550 - accuracy: 0.7500 - val_loss: 0.4978 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6065 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4722 - accuracy: 0.7500 - val_loss: 0.6039 - val_accuracy: 0.6667\n",
            "Masterwork: peer=44\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3471 - accuracy: 1.0000 - val_loss: 3.2921 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 28.1993 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 79.9924 - val_accuracy: 0.6667\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.4445 - accuracy: 0.7500 - val_loss: 0.5282 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6991 - accuracy: 0.7500 - val_loss: 0.6095 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3818 - accuracy: 0.7500 - val_loss: 0.6673 - val_accuracy: 0.6667\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.6481 - accuracy: 0.7500 - val_loss: 0.5404 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8966 - accuracy: 0.7500 - val_loss: 0.4841 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.4877 - val_accuracy: 0.6667\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.5278 - accuracy: 0.7500 - val_loss: 0.3910 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4255 - accuracy: 0.7500 - val_loss: 0.1761 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4342 - accuracy: 0.7500 - val_loss: 0.2777 - val_accuracy: 1.0000\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 1.2436 - accuracy: 0.5000 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6905 - accuracy: 0.6250 - val_loss: 0.7048 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6903 - accuracy: 0.6250 - val_loss: 0.7057 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=88\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5818 - accuracy: 0.6250 - val_loss: 0.3957 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4792 - accuracy: 0.5000 - val_loss: 0.2418 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4583 - accuracy: 0.5000 - val_loss: 0.3295 - val_accuracy: 1.0000\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.5125 - accuracy: 0.8750 - val_loss: 0.1994 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2856 - accuracy: 0.8750 - val_loss: 0.1438 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3195 - accuracy: 0.8750 - val_loss: 0.1528 - val_accuracy: 1.0000\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.5033 - accuracy: 0.8750 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2992 - accuracy: 0.8750 - val_loss: 1.7762e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6451 - accuracy: 0.8750 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
            "Masterwork: peer=97\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 1.0143 - accuracy: 0.3750 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6865 - accuracy: 0.5000 - val_loss: 0.7034 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6786 - accuracy: 0.7500 - val_loss: 0.6656 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "[54, 56, 14, 17, 50, 93, 89, 46, 79, 1]\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6418 - accuracy: 0.6250 - val_loss: 0.6861 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6616 - accuracy: 0.5000 - val_loss: 0.6822 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5680 - accuracy: 0.6250 - val_loss: 0.7095 - val_accuracy: 0.3333\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.2996 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4219 - accuracy: 0.8750 - val_loss: 0.0539 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.1993 - accuracy: 0.8750 - val_loss: 0.1252 - val_accuracy: 1.0000\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6258 - accuracy: 0.6250 - val_loss: 1.2848 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5545 - accuracy: 0.7500 - val_loss: 0.8314 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5404 - accuracy: 0.6250 - val_loss: 0.7587 - val_accuracy: 0.6667\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5473 - accuracy: 0.8750 - val_loss: 0.2837 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5696 - accuracy: 0.7500 - val_loss: 0.3675 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4546 - accuracy: 0.7500 - val_loss: 0.4485 - val_accuracy: 1.0000\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4692 - accuracy: 0.8750 - val_loss: 0.2807 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5798 - accuracy: 0.7500 - val_loss: 0.5346 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4727 - accuracy: 0.7500 - val_loss: 0.6538 - val_accuracy: 1.0000\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4760 - accuracy: 0.8750 - val_loss: 0.5743 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5962 - accuracy: 0.7500 - val_loss: 0.6288 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5084 - accuracy: 0.7500 - val_loss: 0.6621 - val_accuracy: 0.3333\n",
            "Masterwork: peer=89\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.3957 - accuracy: 0.8750 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4111 - accuracy: 0.8750 - val_loss: 0.1595 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3370 - accuracy: 0.8750 - val_loss: 0.2875 - val_accuracy: 1.0000\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.4588 - accuracy: 0.8750 - val_loss: 0.7569 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4126 - accuracy: 0.8750 - val_loss: 0.8164 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2957 - accuracy: 0.8750 - val_loss: 0.8205 - val_accuracy: 0.3333\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3852 - accuracy: 0.7500 - val_loss: 0.6570 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5225 - accuracy: 0.7500 - val_loss: 0.4589 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3210 - accuracy: 0.7500 - val_loss: 0.5485 - val_accuracy: 0.6667\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3238 - accuracy: 0.7500 - val_loss: 0.6244 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3060 - accuracy: 0.7500 - val_loss: 0.6845 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3426 - accuracy: 1.0000 - val_loss: 0.6828 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "[36, 61, 1, 52, 27, 78, 49, 35, 47, 55]\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.6761 - accuracy: 0.7500 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5862 - accuracy: 0.7500 - val_loss: 0.6809 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4743 - accuracy: 0.7500 - val_loss: 0.6013 - val_accuracy: 1.0000\n",
            "Masterwork: peer=61\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 1.0937 - accuracy: 0.3750 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7698 - accuracy: 0.3750 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4556 - accuracy: 0.8750 - val_loss: 0.9936 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6941 - accuracy: 0.7500 - val_loss: 0.4747 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3980 - accuracy: 0.7500 - val_loss: 0.5527 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.6771 - accuracy: 0.8750 - val_loss: 0.5470 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5030 - accuracy: 0.7500 - val_loss: 0.6453 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4079 - accuracy: 0.7500 - val_loss: 0.6836 - val_accuracy: 0.3333\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 0.4636 - accuracy: 0.6250 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4189 - accuracy: 0.7500 - val_loss: 0.4579 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.3204 - accuracy: 0.7500 - val_loss: 0.4896 - val_accuracy: 1.0000\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.4813 - accuracy: 0.7500 - val_loss: 0.1853 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8187 - accuracy: 0.6250 - val_loss: 0.3353 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5284 - accuracy: 0.6250 - val_loss: 0.4754 - val_accuracy: 0.6667\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4736 - accuracy: 0.7500 - val_loss: 0.5177 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.9016 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4619 - accuracy: 1.0000 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3462 - accuracy: 0.8750 - val_loss: 0.2552 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3294 - accuracy: 0.8750 - val_loss: 0.3023 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4967 - accuracy: 0.8750 - val_loss: 0.4821 - val_accuracy: 0.6667\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 639ms/step - loss: 0.4006 - accuracy: 0.8750 - val_loss: 0.5507 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4355 - accuracy: 0.7500 - val_loss: 0.6704 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3188 - accuracy: 0.7500 - val_loss: 0.6882 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.5446 - accuracy: 0.7500 - val_loss: 0.5219 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4678 - accuracy: 0.7500 - val_loss: 0.5524 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3356 - accuracy: 0.7500 - val_loss: 0.5274 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "[45, 80, 76, 41, 91, 74, 55, 25, 97, 15]\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3550 - accuracy: 1.0000 - val_loss: 0.6639 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.9960 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 51.8814 - val_accuracy: 0.6667\n",
            "Masterwork: peer=80\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.5311 - accuracy: 0.8750 - val_loss: 0.6874 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3845 - accuracy: 0.7500 - val_loss: 0.7078 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3393 - accuracy: 0.7500 - val_loss: 0.7127 - val_accuracy: 0.3333\n",
            "Masterwork: peer=76\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.5737 - accuracy: 0.6250 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.9252 - accuracy: 0.6250 - val_loss: 0.6900 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5882 - accuracy: 0.6250 - val_loss: 0.6899 - val_accuracy: 0.6667\n",
            "Masterwork: peer=41\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.5885 - accuracy: 0.8750 - val_loss: 0.4323 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6989 - accuracy: 0.6250 - val_loss: 0.5844 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5945 - accuracy: 0.6250 - val_loss: 0.6279 - val_accuracy: 0.6667\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4223 - accuracy: 0.8750 - val_loss: 0.2763 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3168 - accuracy: 0.8750 - val_loss: 0.3468 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3320 - accuracy: 0.8750 - val_loss: 0.4483 - val_accuracy: 1.0000\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.5661 - accuracy: 0.8750 - val_loss: 0.4247 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5825 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4756 - accuracy: 0.7500 - val_loss: 0.6256 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.5269 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7479 - accuracy: 0.7500 - val_loss: 0.6979 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4780 - accuracy: 0.7500 - val_loss: 0.7104 - val_accuracy: 0.6667\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.6449 - accuracy: 0.5000 - val_loss: 0.3510 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6977 - accuracy: 0.3750 - val_loss: 0.6668 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6532 - accuracy: 0.6250 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Masterwork: peer=97\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4590 - accuracy: 0.8750 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3192 - accuracy: 0.8750 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3249 - accuracy: 0.8750 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
            "Masterwork: peer=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.3856 - accuracy: 0.7500 - val_loss: 0.3638 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5077 - accuracy: 0.7500 - val_loss: 0.5497 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3524 - accuracy: 0.7500 - val_loss: 0.6273 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=35\n",
            "Publisher: master=0\n",
            "[47, 1, 38, 86, 13, 0, 11, 98, 54, 70]\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.2672 - accuracy: 0.8750 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2951 - accuracy: 0.8750 - val_loss: 4.3032e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2935 - accuracy: 0.8750 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.4918 - accuracy: 0.6250 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5831 - accuracy: 0.6250 - val_loss: 0.5857 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5066 - accuracy: 0.7500 - val_loss: 0.6621 - val_accuracy: 0.6667\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 0.3012 - accuracy: 0.8750 - val_loss: 0.6537 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2428 - accuracy: 0.8750 - val_loss: 0.5233 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.1796 - accuracy: 0.8750 - val_loss: 0.4955 - val_accuracy: 0.6667\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6365 - accuracy: 0.7500 - val_loss: 0.5669 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5536 - accuracy: 0.7500 - val_loss: 0.5952 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5324 - accuracy: 0.7500 - val_loss: 0.6329 - val_accuracy: 1.0000\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.6203 - accuracy: 0.7500 - val_loss: 0.6590 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5367 - accuracy: 0.7500 - val_loss: 0.6008 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5289 - accuracy: 0.7500 - val_loss: 0.5604 - val_accuracy: 1.0000\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 1.1928 - accuracy: 0.6250 - val_loss: 0.6962 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.8807 - accuracy: 0.6250 - val_loss: 0.6672 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5794 - accuracy: 0.6250 - val_loss: 0.5406 - val_accuracy: 1.0000\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.3875 - accuracy: 0.8750 - val_loss: 0.5266 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3269 - accuracy: 0.8750 - val_loss: 0.5174 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2648 - accuracy: 0.8750 - val_loss: 0.4824 - val_accuracy: 0.6667\n",
            "Masterwork: peer=98\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.7215 - accuracy: 0.7500 - val_loss: 0.6820 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5592 - accuracy: 0.6250 - val_loss: 0.6862 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5263 - accuracy: 0.7500 - val_loss: 0.7339 - val_accuracy: 0.3333\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.3897 - accuracy: 0.7500 - val_loss: 0.3652 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3661 - accuracy: 0.7500 - val_loss: 0.4796 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3186 - accuracy: 0.8750 - val_loss: 0.5173 - val_accuracy: 1.0000\n",
            "Masterwork: peer=70\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3866 - accuracy: 0.7500 - val_loss: 0.6727 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2812 - accuracy: 0.7500 - val_loss: 0.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3533 - accuracy: 0.8750 - val_loss: 0.6944 - val_accuracy: 0.3333\n",
            "Publisher: master=1\n",
            "[8, 74, 18, 31, 7, 59, 95, 25, 5, 65]\n",
            "Masterwork: peer=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8606 - accuracy: 0.5000 - val_loss: 0.6845 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6728 - accuracy: 0.7500 - val_loss: 0.6836 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6588 - accuracy: 0.7500 - val_loss: 0.6698 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.2786 - accuracy: 0.8750 - val_loss: 0.2000 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3916 - accuracy: 0.8750 - val_loss: 0.2933 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2173 - accuracy: 0.8750 - val_loss: 0.3625 - val_accuracy: 1.0000\n",
            "Masterwork: peer=18\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3543 - accuracy: 0.7500 - val_loss: 3.2875 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3579 - accuracy: 0.7500 - val_loss: 1.4722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3299 - accuracy: 0.8750 - val_loss: 1.7317 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4701 - accuracy: 0.7500 - val_loss: 0.6727 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4594 - accuracy: 0.6250 - val_loss: 0.6186 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3972 - accuracy: 0.7500 - val_loss: 0.4265 - val_accuracy: 0.6667\n",
            "Masterwork: peer=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.3997 - accuracy: 0.7500 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4552 - accuracy: 0.7500 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2882 - accuracy: 0.8750 - val_loss: 0.3186 - val_accuracy: 1.0000\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 0.4732 - accuracy: 0.7500 - val_loss: 0.4050 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4025 - accuracy: 0.7500 - val_loss: 0.5189 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4003 - accuracy: 0.8750 - val_loss: 0.5350 - val_accuracy: 1.0000\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.6207 - accuracy: 0.5000 - val_loss: 0.6663 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5619 - accuracy: 0.7500 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5538 - accuracy: 0.6250 - val_loss: 0.5525 - val_accuracy: 1.0000\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.5759 - accuracy: 0.7500 - val_loss: 0.6969 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4703 - accuracy: 0.7500 - val_loss: 0.6976 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3577 - accuracy: 0.7500 - val_loss: 0.7913 - val_accuracy: 0.3333\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4085 - accuracy: 0.7500 - val_loss: 0.5181 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3034 - accuracy: 0.7500 - val_loss: 0.4671 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3439 - accuracy: 0.8750 - val_loss: 0.4726 - val_accuracy: 0.6667\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.6166 - accuracy: 0.6250 - val_loss: 0.6449 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5530 - accuracy: 0.8750 - val_loss: 0.4164 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5062 - accuracy: 0.6250 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
            "Publisher: master=2\n",
            "[43, 79, 73, 93, 51, 90, 67, 9, 30, 12]\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.5120 - accuracy: 0.6250 - val_loss: 0.6782 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3727 - accuracy: 0.7500 - val_loss: 0.9467 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.5701 - accuracy: 0.6250 - val_loss: 0.6957 - val_accuracy: 0.3333\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.4082 - accuracy: 0.7500 - val_loss: 0.4601 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4668 - accuracy: 0.7500 - val_loss: 0.6301 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3651 - accuracy: 0.7500 - val_loss: 0.6722 - val_accuracy: 0.6667\n",
            "Masterwork: peer=73\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.8673 - accuracy: 0.6250 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6594 - accuracy: 0.5000 - val_loss: 0.7041 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6895 - accuracy: 0.5000 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.7291 - accuracy: 0.5000 - val_loss: 0.6655 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6504 - accuracy: 0.6250 - val_loss: 0.6663 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6346 - accuracy: 0.7500 - val_loss: 0.6250 - val_accuracy: 0.6667\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.6601 - accuracy: 0.7500 - val_loss: 0.4015 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4453 - accuracy: 0.7500 - val_loss: 0.2255 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4679 - accuracy: 0.7500 - val_loss: 0.3122 - val_accuracy: 1.0000\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.1827 - accuracy: 1.0000 - val_loss: 2.0037 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 10.7398 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 59.8556 - val_accuracy: 0.6667\n",
            "Masterwork: peer=67\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.3667 - accuracy: 0.7500 - val_loss: 0.4128 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3422 - accuracy: 0.7500 - val_loss: 0.5200 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3002 - accuracy: 0.7500 - val_loss: 0.5583 - val_accuracy: 0.6667\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.3604 - accuracy: 0.7500 - val_loss: 0.2640 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3659 - accuracy: 0.7500 - val_loss: 0.5717 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3613 - accuracy: 0.7500 - val_loss: 0.5302 - val_accuracy: 0.6667\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.2600 - accuracy: 0.8750 - val_loss: 4.4604 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2548 - accuracy: 0.8750 - val_loss: 9.5538 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3469 - accuracy: 0.8750 - val_loss: 1.5990 - val_accuracy: 0.3333\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3863 - accuracy: 1.0000 - val_loss: 0.8446 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 7.8907 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 104.1198 - val_accuracy: 0.3333\n",
            "Publisher: master=3\n",
            "[1, 19, 23, 36, 59, 0, 34, 45, 84, 90]\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.1850 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.5732 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 36.3091 - val_accuracy: 0.6667\n",
            "Masterwork: peer=19\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4013 - accuracy: 0.7500 - val_loss: 2.1814 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6603 - accuracy: 0.7500 - val_loss: 0.9986 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4209 - accuracy: 0.7500 - val_loss: 0.7259 - val_accuracy: 0.3333\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5515 - accuracy: 0.7500 - val_loss: 0.7628 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4045 - accuracy: 0.7500 - val_loss: 1.2737 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6850 - accuracy: 0.7500 - val_loss: 0.8060 - val_accuracy: 0.3333\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.9162 - accuracy: 0.5000 - val_loss: 0.6912 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7331 - accuracy: 0.6250 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6917 - accuracy: 0.6250 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.7684 - accuracy: 0.5000 - val_loss: 0.7032 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7092 - accuracy: 0.6250 - val_loss: 0.7045 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.7050 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3172 - accuracy: 0.7500 - val_loss: 0.8194 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3174 - accuracy: 0.7500 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2674 - accuracy: 0.8750 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.4316 - accuracy: 0.7500 - val_loss: 0.7310 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3425 - accuracy: 0.7500 - val_loss: 1.2199 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4476 - accuracy: 0.7500 - val_loss: 0.7185 - val_accuracy: 0.6667\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.2728 - accuracy: 0.8750 - val_loss: 0.4118 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3826 - accuracy: 0.8750 - val_loss: 0.4669 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2453 - accuracy: 0.8750 - val_loss: 0.4663 - val_accuracy: 0.6667\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4526 - accuracy: 0.7500 - val_loss: 0.3633 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6618 - accuracy: 0.7500 - val_loss: 0.5805 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4565 - accuracy: 0.7500 - val_loss: 0.6086 - val_accuracy: 1.0000\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 638ms/step - loss: 0.3286 - accuracy: 0.8750 - val_loss: 1.1647 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1568 - accuracy: 0.8750 - val_loss: 2.6862 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8883 - accuracy: 0.8750 - val_loss: 0.9413 - val_accuracy: 0.3333\n",
            "Publisher: master=4\n",
            "[94, 89, 0, 75, 87, 90, 69, 33, 15, 53]\n",
            "Masterwork: peer=94\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3558 - accuracy: 0.7500 - val_loss: 1.1228 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2363 - accuracy: 0.8750 - val_loss: 2.2780 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5579 - accuracy: 0.7500 - val_loss: 0.9579 - val_accuracy: 0.3333\n",
            "Masterwork: peer=89\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.6335 - accuracy: 0.6250 - val_loss: 0.5578 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5622 - accuracy: 0.6250 - val_loss: 0.3029 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5994 - accuracy: 0.6250 - val_loss: 0.6123 - val_accuracy: 1.0000\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.6902 - accuracy: 0.5000 - val_loss: 0.5624 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5644 - accuracy: 0.6250 - val_loss: 0.4306 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5747 - accuracy: 0.6250 - val_loss: 0.6980 - val_accuracy: 0.3333\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.4765 - accuracy: 0.7500 - val_loss: 0.2343 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3958 - accuracy: 0.7500 - val_loss: 0.4814 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3136 - accuracy: 0.7500 - val_loss: 0.2538 - val_accuracy: 0.6667\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.8083 - accuracy: 0.7500 - val_loss: 0.6287 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6142 - accuracy: 0.7500 - val_loss: 0.5436 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6211 - accuracy: 0.7500 - val_loss: 0.5944 - val_accuracy: 1.0000\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.2803 - accuracy: 0.8750 - val_loss: 0.0749 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5647 - accuracy: 0.8750 - val_loss: 0.2993 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2721 - accuracy: 0.8750 - val_loss: 0.4725 - val_accuracy: 1.0000\n",
            "Masterwork: peer=69\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.5621 - accuracy: 0.6250 - val_loss: 0.1976 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4105 - accuracy: 0.6250 - val_loss: 0.6119 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5109 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.6667\n",
            "Masterwork: peer=33\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.4386 - accuracy: 0.7500 - val_loss: 0.5467 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3866 - accuracy: 0.7500 - val_loss: 0.5637 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4035 - accuracy: 0.7500 - val_loss: 0.5710 - val_accuracy: 0.6667\n",
            "Masterwork: peer=15\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.1911 - accuracy: 1.0000 - val_loss: 0.7534 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.9430 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 85.9960 - val_accuracy: 0.3333\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.5785 - accuracy: 0.7500 - val_loss: 0.6873 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5272 - accuracy: 0.7500 - val_loss: 0.7316 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4921 - accuracy: 0.7500 - val_loss: 0.7826 - val_accuracy: 0.3333\n",
            "Publisher: master=5\n",
            "[45, 83, 90, 85, 12, 21, 59, 20, 80, 56]\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.5956 - accuracy: 0.5000 - val_loss: 0.6709 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5650 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7578 - accuracy: 0.5000 - val_loss: 0.6509 - val_accuracy: 1.0000\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.8804 - accuracy: 0.5000 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.5975 - accuracy: 0.7500 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.6631 - accuracy: 0.6250 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3073 - accuracy: 0.8750 - val_loss: 0.3032 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3910 - accuracy: 0.8750 - val_loss: 0.3781 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2489 - accuracy: 0.8750 - val_loss: 0.4225 - val_accuracy: 0.6667\n",
            "Masterwork: peer=85\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.7628 - accuracy: 0.6250 - val_loss: 0.6985 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6046 - accuracy: 0.7500 - val_loss: 0.7128 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6048 - accuracy: 0.6250 - val_loss: 0.7228 - val_accuracy: 0.6667\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.5523 - accuracy: 0.6250 - val_loss: 0.6730 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4587 - accuracy: 0.6250 - val_loss: 0.6313 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4624 - accuracy: 0.6250 - val_loss: 0.6830 - val_accuracy: 0.6667\n",
            "Masterwork: peer=21\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.2183 - accuracy: 1.0000 - val_loss: 0.5891 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0183 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 41.1159 - val_accuracy: 0.6667\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5882 - accuracy: 0.7500 - val_loss: 0.5560 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5127 - accuracy: 0.7500 - val_loss: 0.4802 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5735 - accuracy: 0.7500 - val_loss: 0.5772 - val_accuracy: 1.0000\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.4701 - accuracy: 0.7500 - val_loss: 0.2392 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5669 - accuracy: 0.7500 - val_loss: 0.3006 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4396 - accuracy: 0.7500 - val_loss: 0.3321 - val_accuracy: 1.0000\n",
            "Masterwork: peer=80\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.2669 - accuracy: 0.8750 - val_loss: 0.0961 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.2294 - accuracy: 0.8750 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2458 - accuracy: 0.8750 - val_loss: 0.1961 - val_accuracy: 1.0000\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.6908 - accuracy: 0.7500 - val_loss: 0.6711 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6102 - accuracy: 0.7500 - val_loss: 0.6314 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5906 - accuracy: 0.7500 - val_loss: 0.6125 - val_accuracy: 0.6667\n",
            "Publisher: master=6\n",
            "[75, 11, 30, 31, 63, 41, 51, 70, 77, 78]\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.3135 - accuracy: 0.8750 - val_loss: 0.2812 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2803 - accuracy: 0.8750 - val_loss: 0.2817 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2073 - accuracy: 0.8750 - val_loss: 0.2694 - val_accuracy: 0.6667\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 1.2467 - accuracy: 0.7500 - val_loss: 0.6899 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7764 - accuracy: 0.7500 - val_loss: 0.6675 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6360 - accuracy: 0.7500 - val_loss: 0.6203 - val_accuracy: 1.0000\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.5690 - accuracy: 0.7500 - val_loss: 0.2798 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4266 - accuracy: 0.7500 - val_loss: 0.2359 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3977 - accuracy: 0.7500 - val_loss: 0.2574 - val_accuracy: 1.0000\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.2590 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6015 - accuracy: 0.6250 - val_loss: 0.6627 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5483 - accuracy: 0.5000 - val_loss: 0.5643 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4905 - accuracy: 0.5000 - val_loss: 0.5389 - val_accuracy: 0.6667\n",
            "Masterwork: peer=41\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.5632 - accuracy: 0.6250 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4798 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4348 - accuracy: 0.7500 - val_loss: 0.6871 - val_accuracy: 0.6667\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3343 - accuracy: 0.8750 - val_loss: 0.6183 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4022 - accuracy: 0.8750 - val_loss: 0.4970 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3022 - accuracy: 0.8750 - val_loss: 0.4822 - val_accuracy: 0.6667\n",
            "Masterwork: peer=70\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.6489 - accuracy: 0.6250 - val_loss: 0.5806 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5959 - accuracy: 0.6250 - val_loss: 0.5310 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5581 - accuracy: 0.6250 - val_loss: 0.5147 - val_accuracy: 0.6667\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 1.1373 - accuracy: 0.6250 - val_loss: 0.6896 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6667 - accuracy: 0.6250 - val_loss: 0.6895 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6851 - accuracy: 0.6250 - val_loss: 0.6851 - val_accuracy: 1.0000\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.5319 - accuracy: 0.7500 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5024 - accuracy: 0.7500 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.4295 - accuracy: 0.7500 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "[53, 69, 45, 13, 27, 39, 47, 84, 9, 1]\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.4273 - accuracy: 0.8750 - val_loss: 0.2696 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4054 - accuracy: 0.8750 - val_loss: 0.2879 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2643 - accuracy: 0.8750 - val_loss: 0.3081 - val_accuracy: 1.0000\n",
            "Masterwork: peer=69\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.1589 - accuracy: 1.0000 - val_loss: 0.7215 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 15.1643 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 62.9397 - val_accuracy: 0.6667\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.2942 - accuracy: 0.8750 - val_loss: 1.9079 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2436 - accuracy: 0.8750 - val_loss: 1.7341 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1364 - accuracy: 0.8750 - val_loss: 1.9399 - val_accuracy: 0.3333\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4509 - accuracy: 0.6250 - val_loss: 4.0433 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.9017 - accuracy: 0.6250 - val_loss: 1.1092 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.4217 - accuracy: 0.6250 - val_loss: 0.7220 - val_accuracy: 0.6667\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.1950 - accuracy: 1.0000 - val_loss: 0.0729 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.5689 - accuracy: 0.5000 - val_loss: 0.3293 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4007 - accuracy: 0.7500 - val_loss: 0.2272 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2642 - accuracy: 0.5000 - val_loss: 0.3879 - val_accuracy: 1.0000\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.6073 - accuracy: 0.6250 - val_loss: 0.2218 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4614 - accuracy: 0.6250 - val_loss: 0.3125 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4854 - accuracy: 0.7500 - val_loss: 0.2853 - val_accuracy: 0.6667\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.4583 - accuracy: 0.6250 - val_loss: 0.7164 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5593 - accuracy: 0.7500 - val_loss: 0.5058 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5044 - accuracy: 0.8750 - val_loss: 0.5516 - val_accuracy: 0.3333\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4025 - accuracy: 0.8750 - val_loss: 0.7109 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4509 - accuracy: 0.8750 - val_loss: 0.7367 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2491 - accuracy: 0.8750 - val_loss: 0.7603 - val_accuracy: 0.3333\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.3370 - accuracy: 0.7500 - val_loss: 0.4550 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3645 - accuracy: 0.7500 - val_loss: 0.4631 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4880 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "[42, 1, 87, 18, 91, 62, 20, 27, 98, 68]\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.0956 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.1650 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 35.1205 - val_accuracy: 0.6667\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4371 - accuracy: 0.7500 - val_loss: 0.6967 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4439 - accuracy: 0.6250 - val_loss: 0.6625 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3790 - accuracy: 0.7500 - val_loss: 0.6892 - val_accuracy: 0.3333\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.3530 - accuracy: 0.7500 - val_loss: 0.5235 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3618 - accuracy: 0.7500 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3689 - accuracy: 0.8750 - val_loss: 0.6947 - val_accuracy: 0.3333\n",
            "Masterwork: peer=18\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.6489 - accuracy: 0.5000 - val_loss: 0.4762 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5573 - accuracy: 0.8750 - val_loss: 0.4680 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7960 - accuracy: 0.5000 - val_loss: 0.4794 - val_accuracy: 1.0000\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.2159 - accuracy: 1.0000 - val_loss: 1.4401 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 10.5257 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 63.4893 - val_accuracy: 0.6667\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.5424 - accuracy: 0.7500 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4551 - accuracy: 0.7500 - val_loss: 0.6902 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4500 - accuracy: 0.8750 - val_loss: 0.6660 - val_accuracy: 0.6667\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4995 - accuracy: 0.6250 - val_loss: 0.4194 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3510 - accuracy: 0.6250 - val_loss: 0.0497 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.5305 - accuracy: 0.6250 - val_loss: 0.6026 - val_accuracy: 0.3333\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4596 - accuracy: 0.7500 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3926 - accuracy: 0.7500 - val_loss: 0.3501 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2869 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
            "Masterwork: peer=98\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5818 - accuracy: 0.7500 - val_loss: 0.6804 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5183 - accuracy: 0.7500 - val_loss: 0.6807 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5078 - accuracy: 0.7500 - val_loss: 0.6883 - val_accuracy: 0.3333\n",
            "Masterwork: peer=68\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.9435 - accuracy: 0.5000 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6778 - accuracy: 0.5000 - val_loss: 0.7046 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7051 - val_accuracy: 0.0000e+00\n",
            "Publisher: master=9\n",
            "[33, 96, 57, 17, 42, 4, 62, 61, 23, 91]\n",
            "Masterwork: peer=33\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5143 - accuracy: 0.6250 - val_loss: 0.5138 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8961 - accuracy: 0.6250 - val_loss: 0.5748 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5024 - accuracy: 0.7500 - val_loss: 0.6593 - val_accuracy: 1.0000\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4287 - accuracy: 0.6250 - val_loss: 0.6102 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4174 - accuracy: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5838 - accuracy: 0.6250 - val_loss: 0.5829 - val_accuracy: 0.6667\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.5195 - accuracy: 0.7500 - val_loss: 0.6909 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4249 - accuracy: 0.7500 - val_loss: 0.6938 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4474 - accuracy: 0.6250 - val_loss: 0.6920 - val_accuracy: 0.6667\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.4807 - accuracy: 0.7500 - val_loss: 0.6212 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4849 - accuracy: 0.7500 - val_loss: 0.5715 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3543 - accuracy: 0.7500 - val_loss: 0.5617 - val_accuracy: 0.3333\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6996 - accuracy: 0.5000 - val_loss: 0.6404 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5854 - accuracy: 0.6250 - val_loss: 0.5616 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6181 - accuracy: 0.5000 - val_loss: 0.6706 - val_accuracy: 1.0000\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 1.2043 - accuracy: 0.3750 - val_loss: 0.7039 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6999 - accuracy: 0.6250 - val_loss: 0.7048 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6903 - accuracy: 0.6250 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.4632 - accuracy: 0.7500 - val_loss: 1.1629 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5853 - accuracy: 0.7500 - val_loss: 0.8291 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3755 - accuracy: 0.7500 - val_loss: 0.7892 - val_accuracy: 0.6667\n",
            "Masterwork: peer=61\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.2689 - accuracy: 1.0000 - val_loss: 0.2494 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.5089e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 1.1186 - accuracy: 0.7500 - val_loss: 0.6840 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5520 - accuracy: 0.7500 - val_loss: 0.6420 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4769 - accuracy: 0.7500 - val_loss: 0.6292 - val_accuracy: 0.6667\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4227 - accuracy: 0.8750 - val_loss: 0.1244 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5571 - accuracy: 0.8750 - val_loss: 0.3531 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2923 - accuracy: 0.8750 - val_loss: 0.5340 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=36\n",
            "Publisher: master=0\n",
            "[49, 71, 32, 5, 64, 41, 81, 23, 14, 52]\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.8198 - accuracy: 0.7500 - val_loss: 0.6898 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7016 - accuracy: 0.8750 - val_loss: 0.6747 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4642 - accuracy: 0.8750 - val_loss: 0.6995 - val_accuracy: 0.6667\n",
            "Masterwork: peer=71\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4775 - accuracy: 0.7500 - val_loss: 1.7364 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.0512 - accuracy: 0.7500 - val_loss: 0.6199 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3582 - accuracy: 0.7500 - val_loss: 0.6149 - val_accuracy: 0.6667\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.1804 - accuracy: 1.0000 - val_loss: 0.1729 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.3373e-04 - accuracy: 1.0000 - val_loss: 1.1563e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5511 - accuracy: 0.6250 - val_loss: 0.6731 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5378 - accuracy: 0.7500 - val_loss: 0.4826 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4185 - accuracy: 0.7500 - val_loss: 0.3859 - val_accuracy: 1.0000\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3106 - accuracy: 0.8750 - val_loss: 0.9498 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 10.0785 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 90.3219 - val_accuracy: 0.6667\n",
            "Masterwork: peer=41\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.4905 - accuracy: 1.0000 - val_loss: 0.1877 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9550 - accuracy: 0.6250 - val_loss: 0.3535 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5402 - accuracy: 0.6250 - val_loss: 0.4580 - val_accuracy: 0.6667\n",
            "Masterwork: peer=81\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.7915 - accuracy: 0.6250 - val_loss: 0.7048 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6547 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6600 - accuracy: 0.6250 - val_loss: 0.6852 - val_accuracy: 1.0000\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.9919 - accuracy: 0.6250 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6075 - accuracy: 0.7500 - val_loss: 0.6930 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4944 - accuracy: 0.7500 - val_loss: 0.7684 - val_accuracy: 0.3333\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.4572 - accuracy: 0.8750 - val_loss: 2.8622 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6996 - accuracy: 0.6250 - val_loss: 0.8221 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4212 - accuracy: 0.7500 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 1.2385 - accuracy: 0.6250 - val_loss: 0.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6020 - accuracy: 0.7500 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5372 - accuracy: 0.6250 - val_loss: 0.5988 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "[20, 91, 50, 43, 96, 60, 21, 94, 48, 32]\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5951 - accuracy: 0.7500 - val_loss: 0.5270 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3664 - accuracy: 0.8750 - val_loss: 0.2459 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3504 - accuracy: 0.8750 - val_loss: 0.2235 - val_accuracy: 1.0000\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.6390 - accuracy: 0.8750 - val_loss: 0.4260 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3973 - accuracy: 0.8750 - val_loss: 0.2043 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3596 - accuracy: 0.8750 - val_loss: 0.1806 - val_accuracy: 1.0000\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4876 - accuracy: 0.7500 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5268 - accuracy: 0.7500 - val_loss: 0.5384 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.4521 - accuracy: 0.6250 - val_loss: 0.6090 - val_accuracy: 1.0000\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.6271 - accuracy: 0.6250 - val_loss: 0.6964 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4871 - accuracy: 0.7500 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4626 - accuracy: 0.6250 - val_loss: 0.6891 - val_accuracy: 0.6667\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4223 - accuracy: 0.8750 - val_loss: 0.2559 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3921 - accuracy: 0.8750 - val_loss: 0.2566 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2660 - accuracy: 0.8750 - val_loss: 0.3159 - val_accuracy: 0.6667\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3378 - accuracy: 0.7500 - val_loss: 0.4234 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2673 - accuracy: 0.8750 - val_loss: 0.4423 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2169 - accuracy: 0.8750 - val_loss: 0.4558 - val_accuracy: 0.6667\n",
            "Masterwork: peer=21\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.4236 - accuracy: 0.8750 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=94\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.4519 - accuracy: 0.7500 - val_loss: 0.1789 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.9082 - accuracy: 0.7500 - val_loss: 0.4926 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4066 - accuracy: 0.7500 - val_loss: 0.6745 - val_accuracy: 0.6667\n",
            "Masterwork: peer=48\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.4544 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5804 - accuracy: 0.7500 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4717 - accuracy: 0.7500 - val_loss: 0.2230 - val_accuracy: 1.0000\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 1.4844 - accuracy: 0.7500 - val_loss: 0.6536 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6927 - accuracy: 0.7500 - val_loss: 0.7055 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6498 - accuracy: 0.8750 - val_loss: 0.7057 - val_accuracy: 0.0000e+00\n",
            "Publisher: master=2\n",
            "[25, 78, 50, 98, 42, 62, 65, 36, 53, 91]\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 1.0379 - accuracy: 0.8750 - val_loss: 0.6832 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5268 - accuracy: 0.8750 - val_loss: 0.4538 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3542 - accuracy: 0.8750 - val_loss: 0.2716 - val_accuracy: 1.0000\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.3700 - accuracy: 0.7500 - val_loss: 0.6907 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.6143 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3217 - accuracy: 0.8750 - val_loss: 0.6114 - val_accuracy: 1.0000\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5369 - accuracy: 0.6250 - val_loss: 0.1629 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.8189 - accuracy: 0.7500 - val_loss: 0.4810 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4751 - accuracy: 0.7500 - val_loss: 0.5867 - val_accuracy: 1.0000\n",
            "Masterwork: peer=98\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3398 - accuracy: 1.0000 - val_loss: 0.2551 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2285 - accuracy: 0.8750 - val_loss: 0.2452 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3895 - accuracy: 0.8750 - val_loss: 0.2390 - val_accuracy: 1.0000\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5252 - accuracy: 1.0000 - val_loss: 0.7103 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5526 - accuracy: 0.7500 - val_loss: 0.6035 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4197 - accuracy: 0.7500 - val_loss: 0.6509 - val_accuracy: 0.3333\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.7663 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6861 - accuracy: 0.7500 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6901 - accuracy: 0.6250 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.4234 - accuracy: 0.7500 - val_loss: 0.6700 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5582 - accuracy: 0.7500 - val_loss: 0.6921 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3342 - accuracy: 0.7500 - val_loss: 0.6918 - val_accuracy: 0.6667\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.7284 - accuracy: 0.8750 - val_loss: 0.6543 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5516 - accuracy: 0.6250 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4878 - accuracy: 0.6250 - val_loss: 0.3692 - val_accuracy: 1.0000\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4246 - accuracy: 0.8750 - val_loss: 0.4545 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.9030 - accuracy: 0.8750 - val_loss: 0.5637 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.6029 - val_accuracy: 0.6667\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.6221 - accuracy: 0.7500 - val_loss: 0.5577 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5831 - accuracy: 0.7500 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4172 - accuracy: 0.7500 - val_loss: 0.6054 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "[77, 71, 79, 52, 2, 36, 13, 97, 59, 47]\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.5010 - accuracy: 0.7500 - val_loss: 0.2264 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8916 - accuracy: 0.7500 - val_loss: 0.5012 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3426 - accuracy: 0.7500 - val_loss: 0.6352 - val_accuracy: 0.3333\n",
            "Masterwork: peer=71\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.7564 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6560 - accuracy: 0.7500 - val_loss: 0.7038 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6253 - accuracy: 0.5000 - val_loss: 0.7076 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5132 - accuracy: 0.7500 - val_loss: 0.2874 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.7241 - accuracy: 0.7500 - val_loss: 0.4116 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4401 - accuracy: 0.7500 - val_loss: 0.4942 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.5187 - accuracy: 0.8750 - val_loss: 2.2734 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2213 - accuracy: 0.8750 - val_loss: 12.5880 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9430 - accuracy: 0.8750 - val_loss: 2.8462 - val_accuracy: 0.6667\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4162 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0633 - accuracy: 1.0000 - val_loss: 5.2898 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 72.4907 - val_accuracy: 0.6667\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.7961 - accuracy: 0.7500 - val_loss: 0.6898 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6590 - accuracy: 0.7500 - val_loss: 0.6993 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6118 - accuracy: 0.6250 - val_loss: 0.7210 - val_accuracy: 0.3333\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.4226 - accuracy: 0.8750 - val_loss: 0.6402 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6796 - accuracy: 0.7500 - val_loss: 0.6331 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3810 - accuracy: 0.7500 - val_loss: 0.6679 - val_accuracy: 1.0000\n",
            "Masterwork: peer=97\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.4096 - accuracy: 0.8750 - val_loss: 0.2620 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3998 - accuracy: 0.7500 - val_loss: 0.3237 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3949 - accuracy: 0.7500 - val_loss: 0.4106 - val_accuracy: 1.0000\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.7404 - accuracy: 0.6250 - val_loss: 0.4742 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6569 - accuracy: 0.6250 - val_loss: 0.4635 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6106 - accuracy: 0.6250 - val_loss: 0.4558 - val_accuracy: 0.6667\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4594 - accuracy: 0.7500 - val_loss: 0.4533 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.9530 - accuracy: 0.6250 - val_loss: 0.6452 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4704 - accuracy: 0.6250 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Publisher: master=4\n",
            "[96, 0, 35, 31, 74, 83, 69, 14, 30, 60]\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6740 - accuracy: 0.6250 - val_loss: 0.6882 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6518 - accuracy: 0.6250 - val_loss: 0.6888 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6182 - accuracy: 0.6250 - val_loss: 0.6905 - val_accuracy: 0.6667\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.5719 - accuracy: 0.7500 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4670 - accuracy: 0.6250 - val_loss: 0.3180 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8312 - accuracy: 0.6250 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 1.6185 - accuracy: 0.7500 - val_loss: 0.6933 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6994 - accuracy: 0.6250 - val_loss: 0.7154 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5376 - accuracy: 0.7500 - val_loss: 0.7837 - val_accuracy: 0.3333\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 808ms/step - loss: 0.6373 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6392 - accuracy: 0.7500 - val_loss: 0.6939 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6151 - accuracy: 0.6250 - val_loss: 0.6274 - val_accuracy: 1.0000\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5229 - accuracy: 0.8750 - val_loss: 0.4406 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6003 - accuracy: 0.7500 - val_loss: 0.6122 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4183 - accuracy: 0.7500 - val_loss: 0.6650 - val_accuracy: 0.6667\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4017 - accuracy: 0.8750 - val_loss: 0.5408 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8288 - accuracy: 0.6250 - val_loss: 0.6094 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3232 - accuracy: 0.7500 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=69\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3832 - accuracy: 0.8750 - val_loss: 0.2985 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7018 - accuracy: 0.7500 - val_loss: 0.4213 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3717 - accuracy: 0.7500 - val_loss: 0.6003 - val_accuracy: 0.6667\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4408 - accuracy: 0.8750 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2757 - accuracy: 0.8750 - val_loss: 0.1633 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2306 - accuracy: 0.8750 - val_loss: 0.2301 - val_accuracy: 1.0000\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3950 - accuracy: 0.8750 - val_loss: 0.6423 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.1182 - accuracy: 0.6250 - val_loss: 0.5976 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4322 - accuracy: 0.6250 - val_loss: 0.6963 - val_accuracy: 0.3333\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.6061 - accuracy: 0.7500 - val_loss: 0.6119 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4972 - accuracy: 0.8750 - val_loss: 0.5950 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4013 - accuracy: 0.7500 - val_loss: 0.5807 - val_accuracy: 0.6667\n",
            "Publisher: master=5\n",
            "[20, 53, 72, 83, 48, 59, 65, 54, 82, 50]\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3994 - accuracy: 0.8750 - val_loss: 0.9073 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2319 - accuracy: 0.8750 - val_loss: 1.1305 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4626 - accuracy: 0.8750 - val_loss: 0.6059 - val_accuracy: 0.6667\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.9761 - accuracy: 0.3750 - val_loss: 0.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6873 - accuracy: 0.6250 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.7061 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=72\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.5521 - accuracy: 0.7500 - val_loss: 0.8635 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.7875 - accuracy: 0.7500 - val_loss: 0.7089 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4829 - accuracy: 0.7500 - val_loss: 0.6949 - val_accuracy: 0.3333\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.8395 - accuracy: 0.5000 - val_loss: 0.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6666 - accuracy: 0.7500 - val_loss: 0.7058 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6881 - accuracy: 0.7500 - val_loss: 0.7067 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=48\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4574 - accuracy: 0.6250 - val_loss: 0.4657 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.7298 - accuracy: 0.5000 - val_loss: 0.6491 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5772 - accuracy: 0.7500 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.6188 - accuracy: 0.8750 - val_loss: 0.4673 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6444 - accuracy: 0.7500 - val_loss: 0.6357 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5676 - accuracy: 0.7500 - val_loss: 0.6562 - val_accuracy: 0.6667\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3790 - accuracy: 1.0000 - val_loss: 0.5839 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2568 - accuracy: 0.8750 - val_loss: 0.5526 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.1823 - accuracy: 0.8750 - val_loss: 0.6070 - val_accuracy: 0.3333\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.5047 - accuracy: 0.6250 - val_loss: 0.5755 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4277 - accuracy: 0.6250 - val_loss: 0.1604 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.8954 - accuracy: 0.6250 - val_loss: 0.6895 - val_accuracy: 0.3333\n",
            "Masterwork: peer=82\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.5608 - accuracy: 0.8750 - val_loss: 0.6825 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5910 - accuracy: 0.6250 - val_loss: 0.6859 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4731 - accuracy: 0.6250 - val_loss: 0.6874 - val_accuracy: 0.6667\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.4340 - accuracy: 0.7500 - val_loss: 0.5127 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3584 - accuracy: 0.7500 - val_loss: 0.3306 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5647 - accuracy: 0.6250 - val_loss: 0.5313 - val_accuracy: 0.3333\n",
            "Publisher: master=6\n",
            "[21, 2, 73, 74, 22, 57, 46, 36, 80, 48]\n",
            "Masterwork: peer=21\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3623 - accuracy: 0.8750 - val_loss: 0.3122 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3973 - accuracy: 0.8750 - val_loss: 0.4526 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2499 - accuracy: 0.8750 - val_loss: 0.5200 - val_accuracy: 0.6667\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.9451 - accuracy: 0.7500 - val_loss: 0.5928 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6463 - accuracy: 0.7500 - val_loss: 0.5445 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5501 - accuracy: 0.7500 - val_loss: 0.3052 - val_accuracy: 1.0000\n",
            "Masterwork: peer=73\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.7676 - accuracy: 0.3750 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6851 - accuracy: 0.6250 - val_loss: 0.6891 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6868 - accuracy: 0.6250 - val_loss: 0.6891 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4002 - accuracy: 0.8750 - val_loss: 1.2855 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3929 - accuracy: 0.7500 - val_loss: 0.7583 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2962 - accuracy: 0.7500 - val_loss: 0.5901 - val_accuracy: 0.6667\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.4359 - accuracy: 0.8750 - val_loss: 0.2984 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3589 - accuracy: 0.7500 - val_loss: 0.5377 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2871 - accuracy: 0.8750 - val_loss: 0.5026 - val_accuracy: 0.3333\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.4112 - accuracy: 0.6250 - val_loss: 0.4514 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5128 - accuracy: 0.7500 - val_loss: 0.6603 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4010 - accuracy: 0.6250 - val_loss: 0.6996 - val_accuracy: 0.3333\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.5724 - accuracy: 0.6250 - val_loss: 0.2424 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5231 - accuracy: 0.6250 - val_loss: 0.2318 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4415 - accuracy: 0.6250 - val_loss: 0.2266 - val_accuracy: 1.0000\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5207 - accuracy: 0.8750 - val_loss: 0.1839 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.0679 - accuracy: 0.6250 - val_loss: 0.3340 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4932 - accuracy: 0.6250 - val_loss: 0.5775 - val_accuracy: 0.6667\n",
            "Masterwork: peer=80\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.5503 - accuracy: 0.6250 - val_loss: 0.4590 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4217 - accuracy: 0.7500 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5790 - accuracy: 0.6250 - val_loss: 0.4561 - val_accuracy: 0.6667\n",
            "Masterwork: peer=48\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.5341 - accuracy: 0.8750 - val_loss: 0.5935 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0961 - accuracy: 1.0000 - val_loss: 13.6371 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 211.6635 - val_accuracy: 0.3333\n",
            "Publisher: master=7\n",
            "[75, 91, 38, 22, 90, 55, 54, 87, 19, 9]\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.6019 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6212 - accuracy: 0.7500 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6005 - accuracy: 0.8750 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.3733 - accuracy: 0.8750 - val_loss: 0.4555 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5487 - accuracy: 0.8750 - val_loss: 0.4866 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.2778 - accuracy: 0.8750 - val_loss: 0.5216 - val_accuracy: 0.3333\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4227 - accuracy: 0.8750 - val_loss: 0.4693 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2130 - accuracy: 0.8750 - val_loss: 0.4919 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2236 - accuracy: 0.8750 - val_loss: 0.5424 - val_accuracy: 0.6667\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 1.2555 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6845 - accuracy: 0.8750 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6837 - accuracy: 0.8750 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 0.4026 - accuracy: 0.8750 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3633 - accuracy: 0.8750 - val_loss: 0.3586 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2612 - accuracy: 0.8750 - val_loss: 0.4020 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.7434 - accuracy: 0.8750 - val_loss: 0.4653 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6360 - accuracy: 0.7500 - val_loss: 0.6222 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6173 - accuracy: 0.7500 - val_loss: 0.6651 - val_accuracy: 0.6667\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.6410 - accuracy: 0.5000 - val_loss: 0.5126 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6428 - accuracy: 0.5000 - val_loss: 0.6926 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6707 - accuracy: 0.7500 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3223 - accuracy: 0.8750 - val_loss: 0.2478 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6057 - accuracy: 0.7500 - val_loss: 0.4941 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2980 - accuracy: 0.7500 - val_loss: 0.6548 - val_accuracy: 0.6667\n",
            "Masterwork: peer=19\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.5646 - accuracy: 0.7500 - val_loss: 0.6460 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5240 - accuracy: 0.6250 - val_loss: 0.6595 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4148 - accuracy: 0.6250 - val_loss: 0.4797 - val_accuracy: 1.0000\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.5308 - accuracy: 0.8750 - val_loss: 0.4741 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4518 - accuracy: 0.7500 - val_loss: 0.6795 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3708 - accuracy: 0.7500 - val_loss: 0.6951 - val_accuracy: 0.6667\n",
            "Publisher: master=8\n",
            "[84, 46, 4, 19, 27, 79, 25, 11, 18, 64]\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.6289 - accuracy: 0.5000 - val_loss: 0.5234 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3935 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5081 - accuracy: 0.8750 - val_loss: 0.5852 - val_accuracy: 0.6667\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 1.3762 - accuracy: 0.7500 - val_loss: 0.7024 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6979 - accuracy: 0.8750 - val_loss: 0.6989 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6955 - accuracy: 0.5000 - val_loss: 0.6588 - val_accuracy: 1.0000\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.6698 - accuracy: 0.8750 - val_loss: 0.5932 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3833 - accuracy: 0.8750 - val_loss: 0.4972 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2850 - accuracy: 0.8750 - val_loss: 0.5433 - val_accuracy: 0.6667\n",
            "Masterwork: peer=19\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.5663 - accuracy: 0.8750 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.1062 - accuracy: 0.7500 - val_loss: 0.4910 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4986 - accuracy: 0.7500 - val_loss: 0.5760 - val_accuracy: 1.0000\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.4534 - accuracy: 0.6250 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6348 - accuracy: 0.7500 - val_loss: 0.2234 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3353 - accuracy: 0.7500 - val_loss: 0.4563 - val_accuracy: 1.0000\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.4443 - accuracy: 0.8750 - val_loss: 0.2616 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.0448 - accuracy: 0.6250 - val_loss: 0.4911 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5101 - accuracy: 0.6250 - val_loss: 0.6763 - val_accuracy: 0.6667\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.4630 - accuracy: 0.8750 - val_loss: 0.6262 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4046 - accuracy: 0.8750 - val_loss: 0.7063 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3521 - accuracy: 0.7500 - val_loss: 0.4653 - val_accuracy: 0.6667\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.0327 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5254 - accuracy: 0.8750 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3638 - accuracy: 0.8750 - val_loss: 0.1990 - val_accuracy: 1.0000\n",
            "Masterwork: peer=18\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5228 - accuracy: 0.6250 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5887 - accuracy: 0.8750 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4963 - accuracy: 0.8750 - val_loss: 0.6888 - val_accuracy: 0.6667\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.2210 - accuracy: 1.0000 - val_loss: 1.2768 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.7748e-05 - accuracy: 1.0000 - val_loss: 4.4362 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.5614 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "[54, 74, 99, 66, 65, 0, 24, 63, 23, 89]\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4190 - accuracy: 1.0000 - val_loss: 0.6523 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5694 - accuracy: 0.7500 - val_loss: 0.3065 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3710 - accuracy: 0.7500 - val_loss: 0.3787 - val_accuracy: 1.0000\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4880 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1954 - accuracy: 0.8750 - val_loss: 1.6239 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4754 - accuracy: 0.8750 - val_loss: 0.7095 - val_accuracy: 0.6667\n",
            "Masterwork: peer=99\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.4995 - accuracy: 0.6250 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8075 - accuracy: 0.7500 - val_loss: 0.4381 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4107 - accuracy: 0.7500 - val_loss: 0.6153 - val_accuracy: 1.0000\n",
            "Masterwork: peer=66\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.2577 - accuracy: 0.8750 - val_loss: 0.1813 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.3408 - accuracy: 1.0000 - val_loss: 4.2853 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.1831 - accuracy: 0.8750 - val_loss: 8.5971 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3843 - accuracy: 0.8750 - val_loss: 5.6792 - val_accuracy: 0.6667\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.4858 - accuracy: 0.8750 - val_loss: 0.5089 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6664 - accuracy: 0.8750 - val_loss: 0.4971 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3254 - accuracy: 0.8750 - val_loss: 0.5622 - val_accuracy: 0.6667\n",
            "Masterwork: peer=24\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.6185 - accuracy: 0.7500 - val_loss: 0.6686 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.6715 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4277 - accuracy: 0.8750 - val_loss: 0.7182 - val_accuracy: 0.3333\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.5870 - accuracy: 0.7500 - val_loss: 0.5406 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.7555 - accuracy: 0.7500 - val_loss: 0.6714 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5533 - accuracy: 0.7500 - val_loss: 0.6718 - val_accuracy: 0.6667\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 1.3055 - accuracy: 0.6250 - val_loss: 0.6714 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.7884 - accuracy: 0.5000 - val_loss: 0.6538 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6723 - accuracy: 0.6250 - val_loss: 0.6070 - val_accuracy: 1.0000\n",
            "Masterwork: peer=89\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.6840 - accuracy: 0.6250 - val_loss: 0.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6750 - accuracy: 0.6250 - val_loss: 0.7036 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6345 - accuracy: 0.6250 - val_loss: 0.6927 - val_accuracy: 0.6667\n",
            "Publisher: global iteration=37\n",
            "Publisher: master=0\n",
            "[36, 6, 45, 79, 4, 47, 5, 46, 52, 29]\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6642 - accuracy: 0.6250 - val_loss: 0.6808 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5987 - accuracy: 0.6250 - val_loss: 0.6699 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5400 - accuracy: 0.6250 - val_loss: 0.6669 - val_accuracy: 0.3333\n",
            "Masterwork: peer=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.5744 - accuracy: 0.6250 - val_loss: 0.4462 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7243 - accuracy: 0.3750 - val_loss: 0.6795 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5769 - accuracy: 0.8750 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.3835 - accuracy: 0.7500 - val_loss: 0.5282 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4117 - accuracy: 0.7500 - val_loss: 0.5485 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3194 - accuracy: 0.7500 - val_loss: 0.5793 - val_accuracy: 0.6667\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.2899 - accuracy: 0.8750 - val_loss: 0.4944 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.3352 - accuracy: 0.8750 - val_loss: 0.4839 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.2143 - accuracy: 0.8750 - val_loss: 0.4717 - val_accuracy: 0.6667\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4432 - accuracy: 0.8750 - val_loss: 0.1156 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3222 - accuracy: 0.8750 - val_loss: 0.1168 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3551 - accuracy: 0.8750 - val_loss: 0.2314 - val_accuracy: 1.0000\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.3334 - accuracy: 0.8750 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2227 - accuracy: 0.8750 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8884 - accuracy: 0.8750 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4705 - accuracy: 0.7500 - val_loss: 0.6448 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3483 - accuracy: 0.7500 - val_loss: 0.4886 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4837 - accuracy: 0.7500 - val_loss: 0.5256 - val_accuracy: 1.0000\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5864 - accuracy: 0.5000 - val_loss: 0.7046 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6345 - accuracy: 1.0000 - val_loss: 0.7010 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 0.6702 - val_accuracy: 1.0000\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.9083 - accuracy: 0.7500 - val_loss: 0.4933 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5290 - accuracy: 0.7500 - val_loss: 0.4162 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5864 - accuracy: 0.7500 - val_loss: 0.3908 - val_accuracy: 1.0000\n",
            "Masterwork: peer=29\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4967 - accuracy: 0.7500 - val_loss: 0.6997 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4878 - accuracy: 0.7500 - val_loss: 0.6937 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4701 - accuracy: 0.6250 - val_loss: 0.6748 - val_accuracy: 0.6667\n",
            "Publisher: master=1\n",
            "[75, 76, 91, 5, 20, 60, 12, 28, 87, 49]\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.5631 - accuracy: 0.6250 - val_loss: 0.6221 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5821 - accuracy: 0.6250 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4458 - accuracy: 0.6250 - val_loss: 0.4556 - val_accuracy: 0.6667\n",
            "Masterwork: peer=76\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.5935 - accuracy: 0.7500 - val_loss: 0.4529 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5412 - accuracy: 0.6250 - val_loss: 0.3605 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4722 - accuracy: 0.6250 - val_loss: 0.2671 - val_accuracy: 1.0000\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5637 - accuracy: 0.8750 - val_loss: 0.3093 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2808 - accuracy: 0.8750 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4981 - accuracy: 0.8750 - val_loss: 0.1883 - val_accuracy: 1.0000\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4730 - accuracy: 0.7500 - val_loss: 0.2472 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3806 - accuracy: 0.7500 - val_loss: 0.2510 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5654 - accuracy: 0.7500 - val_loss: 0.4101 - val_accuracy: 1.0000\n",
            "Masterwork: peer=20\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.4322 - accuracy: 0.8750 - val_loss: 0.9639 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 4.6801 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.7684e-07 - accuracy: 1.0000 - val_loss: 37.2335 - val_accuracy: 0.6667\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.3636 - accuracy: 1.0000 - val_loss: 0.6260 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.8156 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3478e-05 - accuracy: 1.0000 - val_loss: 64.3394 - val_accuracy: 0.3333\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4119 - accuracy: 0.8750 - val_loss: 0.4893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4291 - accuracy: 0.8750 - val_loss: 0.5571 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.2039 - accuracy: 0.8750 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
            "Masterwork: peer=28\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 1.3178 - accuracy: 0.2500 - val_loss: 0.5800 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6092 - accuracy: 0.7500 - val_loss: 0.7059 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6447 - accuracy: 0.8750 - val_loss: 0.7069 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.6244 - accuracy: 0.5000 - val_loss: 0.5563 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5105 - accuracy: 0.6250 - val_loss: 0.3213 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8589 - accuracy: 0.5000 - val_loss: 0.6160 - val_accuracy: 1.0000\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4229 - accuracy: 0.6250 - val_loss: 0.3138 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4909 - accuracy: 0.6250 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3837 - accuracy: 0.6250 - val_loss: 0.6749 - val_accuracy: 0.3333\n",
            "Publisher: master=2\n",
            "[73, 16, 14, 92, 51, 4, 43, 1, 90, 50]\n",
            "Masterwork: peer=73\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.7364 - accuracy: 0.6250 - val_loss: 0.6452 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6977 - accuracy: 0.5000 - val_loss: 0.6732 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6886 - accuracy: 0.6250 - val_loss: 0.6193 - val_accuracy: 0.3333\n",
            "Masterwork: peer=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4800 - accuracy: 0.7500 - val_loss: 0.6485 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4372 - accuracy: 0.7500 - val_loss: 0.6577 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3858 - accuracy: 0.7500 - val_loss: 0.6723 - val_accuracy: 0.3333\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.6394 - accuracy: 0.7500 - val_loss: 0.6713 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5537 - accuracy: 0.7500 - val_loss: 0.6445 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5742 - accuracy: 0.7500 - val_loss: 0.6780 - val_accuracy: 1.0000\n",
            "Masterwork: peer=92\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3459 - accuracy: 0.8750 - val_loss: 0.1569 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5444 - accuracy: 0.8750 - val_loss: 0.3073 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2575 - accuracy: 0.8750 - val_loss: 0.4033 - val_accuracy: 1.0000\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3763 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 10.2448 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 127.8791 - val_accuracy: 0.3333\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.5210 - accuracy: 0.5000 - val_loss: 0.2482 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6322 - accuracy: 0.5000 - val_loss: 0.4650 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5599 - accuracy: 0.6250 - val_loss: 0.5531 - val_accuracy: 0.6667\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4908 - accuracy: 0.6250 - val_loss: 0.4708 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6270 - accuracy: 0.6250 - val_loss: 0.6725 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4695 - accuracy: 0.7500 - val_loss: 0.6875 - val_accuracy: 0.6667\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3842 - accuracy: 0.7500 - val_loss: 0.2449 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4525 - accuracy: 0.7500 - val_loss: 0.4496 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3528 - accuracy: 0.7500 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3634 - accuracy: 0.8750 - val_loss: 0.2884 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5246 - accuracy: 0.8750 - val_loss: 0.3934 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3150 - accuracy: 0.8750 - val_loss: 0.4379 - val_accuracy: 1.0000\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.5234 - accuracy: 0.8750 - val_loss: 0.4436 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3999 - accuracy: 0.8750 - val_loss: 0.4439 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5225 - accuracy: 0.8750 - val_loss: 0.4428 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "[50, 67, 38, 64, 83, 14, 77, 63, 6, 35]\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4635 - accuracy: 0.8750 - val_loss: 0.0665 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6454 - accuracy: 0.8750 - val_loss: 0.1572 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3458 - accuracy: 0.8750 - val_loss: 0.2629 - val_accuracy: 1.0000\n",
            "Masterwork: peer=67\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3131 - accuracy: 1.0000 - val_loss: 1.6225 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 10.7351 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5206e-05 - accuracy: 1.0000 - val_loss: 102.2497 - val_accuracy: 0.3333\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.5885 - accuracy: 0.6250 - val_loss: 3.1168 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4728 - accuracy: 0.6250 - val_loss: 9.2277 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1033 - accuracy: 0.6250 - val_loss: 3.8505 - val_accuracy: 0.6667\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 1.0551 - accuracy: 0.7500 - val_loss: 0.5557 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5204 - accuracy: 0.7500 - val_loss: 0.3998 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5887 - accuracy: 0.7500 - val_loss: 0.4873 - val_accuracy: 1.0000\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 643ms/step - loss: 0.5105 - accuracy: 0.7500 - val_loss: 0.2665 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5545 - accuracy: 0.6250 - val_loss: 0.4643 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4362 - accuracy: 0.6250 - val_loss: 0.5195 - val_accuracy: 0.6667\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.4899 - accuracy: 0.8750 - val_loss: 0.3465 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4967 - accuracy: 0.7500 - val_loss: 0.4639 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3519 - accuracy: 0.7500 - val_loss: 0.4253 - val_accuracy: 1.0000\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5492 - accuracy: 0.6250 - val_loss: 0.3386 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4890 - accuracy: 0.7500 - val_loss: 0.5733 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4191 - accuracy: 0.7500 - val_loss: 0.6010 - val_accuracy: 1.0000\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.5514 - accuracy: 0.7500 - val_loss: 0.4164 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5507 - accuracy: 0.7500 - val_loss: 0.5354 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4600 - accuracy: 0.7500 - val_loss: 0.6456 - val_accuracy: 1.0000\n",
            "Masterwork: peer=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5248 - accuracy: 0.6250 - val_loss: 0.5169 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4525 - accuracy: 0.8750 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4327 - accuracy: 0.6250 - val_loss: 0.4521 - val_accuracy: 0.6667\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.2767 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 3.3578 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.1095e-07 - accuracy: 1.0000 - val_loss: 41.2189 - val_accuracy: 0.0000e+00\n",
            "Publisher: master=4\n",
            "[2, 12, 5, 32, 46, 84, 7, 86, 81, 92]\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.1700 - accuracy: 1.0000 - val_loss: 0.7204 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.8782e-04 - accuracy: 1.0000 - val_loss: 1.2851 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 9.0618 - val_accuracy: 0.3333\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.4833 - accuracy: 0.8750 - val_loss: 0.5069 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2417 - accuracy: 0.8750 - val_loss: 5.0506 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.4329 - accuracy: 0.8750 - val_loss: 0.6773 - val_accuracy: 0.6667\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3078 - accuracy: 0.8750 - val_loss: 0.2144 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.1550 - accuracy: 0.8750 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3237 - accuracy: 0.8750 - val_loss: 0.1458 - val_accuracy: 1.0000\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.5978 - accuracy: 0.8750 - val_loss: 0.5541 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3289 - accuracy: 0.8750 - val_loss: 0.5481 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3508 - accuracy: 0.8750 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6217 - accuracy: 0.7500 - val_loss: 0.4241 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7028 - accuracy: 0.7500 - val_loss: 0.4480 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4908 - accuracy: 0.7500 - val_loss: 0.4781 - val_accuracy: 0.6667\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4624 - accuracy: 0.8750 - val_loss: 0.3009 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3863 - accuracy: 0.8750 - val_loss: 0.2856 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2312 - accuracy: 0.8750 - val_loss: 0.2906 - val_accuracy: 0.6667\n",
            "Masterwork: peer=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.4276 - accuracy: 0.8750 - val_loss: 0.6540 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2748 - accuracy: 0.8750 - val_loss: 0.9567 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7437 - accuracy: 0.8750 - val_loss: 0.7008 - val_accuracy: 0.3333\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.7043 - accuracy: 0.8750 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4244 - accuracy: 0.8750 - val_loss: 0.3231 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3611 - accuracy: 0.8750 - val_loss: 0.2115 - val_accuracy: 1.0000\n",
            "Masterwork: peer=81\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.5942 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5502 - accuracy: 0.7500 - val_loss: 0.6707 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4472 - accuracy: 0.6250 - val_loss: 0.6020 - val_accuracy: 0.6667\n",
            "Masterwork: peer=92\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6094 - accuracy: 0.3750 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5740 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.9672 - accuracy: 0.3750 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Publisher: master=5\n",
            "[50, 68, 31, 35, 14, 64, 61, 21, 0, 34]\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.4208 - accuracy: 0.7500 - val_loss: 0.3922 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3492 - accuracy: 0.7500 - val_loss: 0.3883 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2709 - accuracy: 0.7500 - val_loss: 0.5113 - val_accuracy: 0.6667\n",
            "Masterwork: peer=68\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4958 - accuracy: 0.6250 - val_loss: 0.6403 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4839 - accuracy: 0.6250 - val_loss: 0.7054 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4681 - accuracy: 0.7500 - val_loss: 0.7067 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4138 - accuracy: 0.8750 - val_loss: 0.0616 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3134 - accuracy: 0.8750 - val_loss: 0.0880 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3376 - accuracy: 0.8750 - val_loss: 0.1566 - val_accuracy: 1.0000\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6548 - accuracy: 0.8750 - val_loss: 0.8662 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.5289 - accuracy: 0.7500 - val_loss: 0.7754 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.3968 - accuracy: 0.7500 - val_loss: 0.8250 - val_accuracy: 0.3333\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.3614 - accuracy: 0.8750 - val_loss: 0.4654 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3394 - accuracy: 0.7500 - val_loss: 0.4458 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3173 - accuracy: 0.7500 - val_loss: 0.4915 - val_accuracy: 0.6667\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.5363 - accuracy: 0.6250 - val_loss: 0.3776 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5700 - accuracy: 0.7500 - val_loss: 0.5167 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4274 - accuracy: 0.7500 - val_loss: 0.5828 - val_accuracy: 0.6667\n",
            "Masterwork: peer=61\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6045 - accuracy: 0.7500 - val_loss: 0.6699 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4681 - accuracy: 0.7500 - val_loss: 0.6443 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4484 - accuracy: 0.7500 - val_loss: 0.6561 - val_accuracy: 0.6667\n",
            "Masterwork: peer=21\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4683 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 2.9230 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.0431e-07 - accuracy: 1.0000 - val_loss: 55.7503 - val_accuracy: 0.6667\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.3996 - accuracy: 1.0000 - val_loss: 0.6702 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 2.7258 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 52.5214 - val_accuracy: 0.3333\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5795 - accuracy: 0.7500 - val_loss: 0.1858 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5516 - accuracy: 0.6250 - val_loss: 0.0383 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7160 - accuracy: 0.6250 - val_loss: 0.3051 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "[86, 2, 83, 25, 42, 34, 47, 43, 6, 62]\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5930 - accuracy: 0.7500 - val_loss: 0.6840 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4992 - accuracy: 0.6250 - val_loss: 0.7038 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4927 - accuracy: 0.6250 - val_loss: 0.6968 - val_accuracy: 0.6667\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5814 - accuracy: 0.7500 - val_loss: 0.6706 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4223 - accuracy: 0.7500 - val_loss: 0.6020 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.4187 - accuracy: 0.7500 - val_loss: 0.6878 - val_accuracy: 0.6667\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3075 - accuracy: 0.8750 - val_loss: 0.2319 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 6.0944e-06 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.5595 - accuracy: 0.6250 - val_loss: 0.6740 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5936 - accuracy: 0.6250 - val_loss: 0.6902 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5312 - accuracy: 0.6250 - val_loss: 0.6816 - val_accuracy: 1.0000\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.6152 - accuracy: 0.7500 - val_loss: 0.4154 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5299 - accuracy: 0.7500 - val_loss: 0.4041 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4007 - accuracy: 0.7500 - val_loss: 0.4001 - val_accuracy: 0.6667\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4809 - accuracy: 0.7500 - val_loss: 0.6647 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4457 - accuracy: 0.6250 - val_loss: 0.6588 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3767 - accuracy: 0.8750 - val_loss: 0.5289 - val_accuracy: 1.0000\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4938 - accuracy: 0.6250 - val_loss: 0.4151 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8856 - accuracy: 0.6250 - val_loss: 0.4867 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4985 - accuracy: 0.6250 - val_loss: 0.6388 - val_accuracy: 1.0000\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.4377 - accuracy: 0.8750 - val_loss: 0.1926 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3377 - accuracy: 0.8750 - val_loss: 0.2382 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4116 - accuracy: 0.8750 - val_loss: 0.3285 - val_accuracy: 1.0000\n",
            "Masterwork: peer=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.3621 - accuracy: 0.8750 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3044 - accuracy: 0.8750 - val_loss: 0.6597 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3131 - accuracy: 0.8750 - val_loss: 0.6936 - val_accuracy: 0.6667\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5541 - accuracy: 0.6250 - val_loss: 0.4945 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6489 - accuracy: 0.6250 - val_loss: 0.5114 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4878 - accuracy: 0.7500 - val_loss: 0.6305 - val_accuracy: 0.3333\n",
            "Publisher: master=7\n",
            "[9, 71, 23, 63, 26, 34, 62, 52, 40, 10]\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.4859 - accuracy: 0.8750 - val_loss: 0.6671 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5101 - accuracy: 0.7500 - val_loss: 0.6010 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5402 - accuracy: 0.7500 - val_loss: 0.6999 - val_accuracy: 0.6667\n",
            "Masterwork: peer=71\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 0.2790 - accuracy: 1.0000 - val_loss: 1.0963 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 7.6492 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 85.7721 - val_accuracy: 0.3333\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 637ms/step - loss: 0.3855 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 7.9473e-08 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 1.8929 - accuracy: 0.7500 - val_loss: 0.4975 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7934 - accuracy: 0.7500 - val_loss: 0.4130 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4933 - accuracy: 0.7500 - val_loss: 0.3099 - val_accuracy: 1.0000\n",
            "Masterwork: peer=26\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.4652 - accuracy: 0.8750 - val_loss: 1.6669 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5286 - accuracy: 0.8750 - val_loss: 1.7189 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2539 - accuracy: 0.8750 - val_loss: 1.7563 - val_accuracy: 0.3333\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.5681 - accuracy: 0.8750 - val_loss: 0.8961 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3551 - accuracy: 0.8750 - val_loss: 0.9432 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2831 - accuracy: 0.8750 - val_loss: 0.8847 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.6141 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5648 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5567 - accuracy: 0.6250 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.2264 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 3.5954e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.4273e-07 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=40\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4861 - accuracy: 0.8750 - val_loss: 0.7353 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2748 - accuracy: 0.8750 - val_loss: 0.9794 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2760 - accuracy: 0.8750 - val_loss: 0.9332 - val_accuracy: 0.3333\n",
            "Masterwork: peer=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.6019 - accuracy: 0.6250 - val_loss: 0.5043 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5098 - accuracy: 0.7500 - val_loss: 0.4872 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.8800 - accuracy: 0.5000 - val_loss: 0.4869 - val_accuracy: 0.6667\n",
            "Publisher: master=8\n",
            "[57, 37, 53, 45, 95, 84, 0, 49, 97, 56]\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.3087 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0364 - accuracy: 1.0000 - val_loss: 6.5026 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 162.3033 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=37\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 1.2764 - accuracy: 0.2500 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.8044 - accuracy: 0.7500 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6869 - accuracy: 0.7500 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.4366 - accuracy: 0.8750 - val_loss: 0.8391 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3111 - accuracy: 0.8750 - val_loss: 0.6366 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2266 - accuracy: 0.8750 - val_loss: 0.6250 - val_accuracy: 0.3333\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.9919 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6899 - accuracy: 0.5000 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.6584 - accuracy: 0.5000 - val_loss: 0.7050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6315 - accuracy: 0.6250 - val_loss: 0.7043 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5417 - accuracy: 0.7500 - val_loss: 0.6680 - val_accuracy: 0.6667\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.5854 - accuracy: 0.7500 - val_loss: 0.5715 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4867 - accuracy: 0.8750 - val_loss: 0.5754 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5208 - accuracy: 0.8750 - val_loss: 0.5846 - val_accuracy: 0.6667\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.3829 - accuracy: 1.0000 - val_loss: 0.6918 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 4.6086 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 93.8419 - val_accuracy: 0.3333\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.5888 - accuracy: 0.7500 - val_loss: 0.4419 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5438 - accuracy: 0.6250 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5693 - accuracy: 0.7500 - val_loss: 0.6617 - val_accuracy: 0.6667\n",
            "Masterwork: peer=97\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.6026 - accuracy: 0.5000 - val_loss: 0.6171 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6025 - accuracy: 0.7500 - val_loss: 0.4996 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5729 - accuracy: 0.3750 - val_loss: 0.5943 - val_accuracy: 0.6667\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.2555 - accuracy: 0.8750 - val_loss: 0.1673 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2001 - accuracy: 0.8750 - val_loss: 0.0922 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3387 - accuracy: 0.8750 - val_loss: 0.1996 - val_accuracy: 1.0000\n",
            "Publisher: master=9\n",
            "[58, 83, 16, 87, 10, 36, 38, 30, 78, 29]\n",
            "Masterwork: peer=58\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.5582 - accuracy: 0.7500 - val_loss: 0.4879 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.4903 - accuracy: 0.6250 - val_loss: 0.5502 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.4691 - accuracy: 0.6250 - val_loss: 0.5690 - val_accuracy: 1.0000\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4998 - accuracy: 0.8750 - val_loss: 0.2366 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8367 - accuracy: 0.7500 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5332 - accuracy: 0.7500 - val_loss: 0.6766 - val_accuracy: 1.0000\n",
            "Masterwork: peer=16\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4002 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.6215 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 32.3589 - val_accuracy: 0.6667\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4591 - accuracy: 0.7500 - val_loss: 0.4492 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5090 - accuracy: 0.7500 - val_loss: 0.4434 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4657 - accuracy: 0.7500 - val_loss: 0.6006 - val_accuracy: 0.6667\n",
            "Masterwork: peer=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5295 - accuracy: 0.7500 - val_loss: 0.2385 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6018 - accuracy: 0.7500 - val_loss: 0.3368 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5011 - accuracy: 0.7500 - val_loss: 0.4420 - val_accuracy: 1.0000\n",
            "Masterwork: peer=36\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.7875 - accuracy: 0.6250 - val_loss: 0.6986 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6363 - accuracy: 0.8750 - val_loss: 0.6875 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5787 - accuracy: 0.6250 - val_loss: 0.6772 - val_accuracy: 0.3333\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.4109 - accuracy: 0.8750 - val_loss: 0.4418 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4575 - accuracy: 0.8750 - val_loss: 0.5161 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2575 - accuracy: 0.8750 - val_loss: 0.5559 - val_accuracy: 0.6667\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.4686 - accuracy: 0.6250 - val_loss: 0.6751 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4542 - accuracy: 0.6250 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4423 - accuracy: 0.6250 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.2512 - accuracy: 0.8750 - val_loss: 0.4946 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2447 - accuracy: 0.8750 - val_loss: 0.8013 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1935 - accuracy: 0.8750 - val_loss: 0.4812 - val_accuracy: 0.3333\n",
            "Masterwork: peer=29\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.6295 - accuracy: 0.6250 - val_loss: 0.4997 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.7950 - accuracy: 0.5000 - val_loss: 0.5627 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5649 - accuracy: 0.5000 - val_loss: 0.5467 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=38\n",
            "Publisher: master=0\n",
            "[52, 59, 39, 95, 57, 17, 99, 60, 51, 87]\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 1.5061 - accuracy: 0.7500 - val_loss: 0.6887 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8236 - accuracy: 0.7500 - val_loss: 0.6724 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6397 - accuracy: 0.7500 - val_loss: 0.6205 - val_accuracy: 1.0000\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.6791 - accuracy: 0.5000 - val_loss: 0.5565 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5353 - accuracy: 0.7500 - val_loss: 0.1991 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7289 - accuracy: 0.7500 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.0715 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 7.9719e-06 - accuracy: 1.0000 - val_loss: 5.1631 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 60.1883 - val_accuracy: 0.6667\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.0985 - accuracy: 1.0000 - val_loss: 1.6604 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1325e-06 - accuracy: 1.0000 - val_loss: 23.6958 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 151.2814 - val_accuracy: 0.3333\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 1.5954 - accuracy: 0.6250 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7202 - accuracy: 0.5000 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.7022 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.8996 - accuracy: 0.6250 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5910 - accuracy: 0.7500 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5987 - accuracy: 0.7500 - val_loss: 0.6944 - val_accuracy: 0.3333\n",
            "Masterwork: peer=99\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.7631 - accuracy: 0.5000 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6341 - accuracy: 0.6250 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6077 - accuracy: 0.6250 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.2554 - accuracy: 0.8750 - val_loss: 0.6188 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3485 - accuracy: 0.8750 - val_loss: 0.6313 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2890 - accuracy: 0.8750 - val_loss: 0.6464 - val_accuracy: 0.6667\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.6205 - accuracy: 0.6250 - val_loss: 0.4307 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6625 - accuracy: 0.7500 - val_loss: 0.5933 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6003 - accuracy: 0.5000 - val_loss: 0.5304 - val_accuracy: 0.3333\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.1621 - accuracy: 1.0000 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "[10, 99, 17, 67, 77, 42, 8, 52, 70, 79]\n",
            "Masterwork: peer=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.7405 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6379 - accuracy: 0.8750 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6727 - accuracy: 0.6250 - val_loss: 0.6938 - val_accuracy: 0.3333\n",
            "Masterwork: peer=99\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.9555 - accuracy: 0.5000 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7734 - accuracy: 0.6250 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6889 - accuracy: 0.6250 - val_loss: 0.6976 - val_accuracy: 0.3333\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.8151 - accuracy: 0.6250 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5891 - accuracy: 0.6250 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6117 - accuracy: 0.7500 - val_loss: 0.6973 - val_accuracy: 0.3333\n",
            "Masterwork: peer=67\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.1913 - accuracy: 0.8750 - val_loss: 0.7606 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1645 - accuracy: 0.8750 - val_loss: 1.8416 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1334 - accuracy: 0.8750 - val_loss: 0.6329 - val_accuracy: 0.3333\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.2784 - accuracy: 0.8750 - val_loss: 2.7667 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4539 - accuracy: 0.8750 - val_loss: 1.3424 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2030 - accuracy: 0.8750 - val_loss: 1.0131 - val_accuracy: 0.6667\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.2906 - accuracy: 0.8750 - val_loss: 0.6316 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2242 - accuracy: 0.8750 - val_loss: 0.5027 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3033 - accuracy: 0.8750 - val_loss: 0.5874 - val_accuracy: 0.6667\n",
            "Masterwork: peer=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5290 - accuracy: 0.6250 - val_loss: 0.7111 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5523 - accuracy: 0.7500 - val_loss: 0.7109 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5362 - accuracy: 0.6250 - val_loss: 0.7795 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.3788 - accuracy: 0.7500 - val_loss: 0.2277 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3940 - accuracy: 0.7500 - val_loss: 0.2803 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3904 - accuracy: 0.7500 - val_loss: 0.3075 - val_accuracy: 1.0000\n",
            "Masterwork: peer=70\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.5602 - accuracy: 0.7500 - val_loss: 0.7981 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4329 - accuracy: 0.7500 - val_loss: 0.8990 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4215 - accuracy: 0.7500 - val_loss: 0.8071 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3903 - accuracy: 0.7500 - val_loss: 0.3159 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3377 - accuracy: 0.7500 - val_loss: 0.2662 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3459 - accuracy: 0.7500 - val_loss: 0.5159 - val_accuracy: 0.6667\n",
            "Publisher: master=2\n",
            "[46, 6, 83, 24, 51, 70, 25, 53, 96, 37]\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.5307 - accuracy: 0.7500 - val_loss: 0.6823 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4256 - accuracy: 0.7500 - val_loss: 0.6865 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4146 - accuracy: 0.7500 - val_loss: 0.6742 - val_accuracy: 0.6667\n",
            "Masterwork: peer=6\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3047 - accuracy: 0.7500 - val_loss: 0.8850 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3636 - accuracy: 0.7500 - val_loss: 0.6574 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2654 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.3112 - accuracy: 0.8750 - val_loss: 1.0518 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4392 - accuracy: 0.8750 - val_loss: 0.4019 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2362 - accuracy: 0.8750 - val_loss: 0.4034 - val_accuracy: 0.6667\n",
            "Masterwork: peer=24\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.3662 - accuracy: 0.7500 - val_loss: 0.4803 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3327 - accuracy: 0.7500 - val_loss: 0.2809 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4224 - accuracy: 0.7500 - val_loss: 0.5274 - val_accuracy: 0.6667\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.4108 - accuracy: 0.8750 - val_loss: 0.5203 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2706 - accuracy: 0.8750 - val_loss: 0.4848 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2213 - accuracy: 0.8750 - val_loss: 0.5059 - val_accuracy: 0.6667\n",
            "Masterwork: peer=70\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5121 - accuracy: 0.6250 - val_loss: 0.4936 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4332 - accuracy: 0.7500 - val_loss: 0.1024 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.8408 - accuracy: 0.6250 - val_loss: 0.5136 - val_accuracy: 0.6667\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.9892 - accuracy: 0.8750 - val_loss: 0.5676 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4262 - accuracy: 0.8750 - val_loss: 0.3476 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3705 - accuracy: 0.8750 - val_loss: 0.1352 - val_accuracy: 1.0000\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.2541 - accuracy: 0.8750 - val_loss: 1.2674 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2235 - accuracy: 0.8750 - val_loss: 0.7258 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3149 - accuracy: 0.8750 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.1936 - accuracy: 1.0000 - val_loss: 1.3879 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 9.3395 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 30.2673 - val_accuracy: 0.6667\n",
            "Masterwork: peer=37\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4453 - accuracy: 0.8750 - val_loss: 0.5975 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3919 - accuracy: 0.8750 - val_loss: 0.4253 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3653 - accuracy: 0.7500 - val_loss: 0.4449 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "[94, 90, 38, 3, 69, 45, 57, 14, 92, 2]\n",
            "Masterwork: peer=94\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.3164 - accuracy: 0.8750 - val_loss: 3.6502e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5030 - accuracy: 0.8750 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3389 - accuracy: 0.8750 - val_loss: 0.1893 - val_accuracy: 1.0000\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.2698 - accuracy: 0.8750 - val_loss: 1.5917 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.2705 - accuracy: 0.8750 - val_loss: 2.7549 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2328 - accuracy: 0.8750 - val_loss: 1.3190 - val_accuracy: 0.3333\n",
            "Masterwork: peer=38\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.5353 - accuracy: 0.6250 - val_loss: 4.3599 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3956 - accuracy: 0.7500 - val_loss: 2.8722 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4317 - accuracy: 0.8750 - val_loss: 4.3173 - val_accuracy: 0.3333\n",
            "Masterwork: peer=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 0.4523 - accuracy: 0.6250 - val_loss: 0.5866 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3497 - accuracy: 0.6250 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3314 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=69\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.4008 - accuracy: 0.8750 - val_loss: 0.4456 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3785 - accuracy: 0.8750 - val_loss: 0.4986 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4923 - accuracy: 0.8750 - val_loss: 0.5590 - val_accuracy: 0.6667\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3586 - accuracy: 0.8750 - val_loss: 0.1199 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4591 - accuracy: 0.8750 - val_loss: 0.1907 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2823 - accuracy: 0.8750 - val_loss: 0.2240 - val_accuracy: 1.0000\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.1616 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.4058 - accuracy: 0.7500 - val_loss: 0.4575 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4089 - accuracy: 0.7500 - val_loss: 0.4963 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4128 - accuracy: 0.6250 - val_loss: 0.5189 - val_accuracy: 0.6667\n",
            "Masterwork: peer=92\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.4371 - accuracy: 0.7500 - val_loss: 0.5630 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4657 - accuracy: 0.7500 - val_loss: 0.6855 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4373 - accuracy: 0.7500 - val_loss: 0.6818 - val_accuracy: 1.0000\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3550 - accuracy: 0.8750 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3319 - accuracy: 0.8750 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3039 - accuracy: 0.8750 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "[31, 58, 9, 13, 62, 45, 23, 56, 89, 79]\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.8069 - accuracy: 0.5000 - val_loss: 0.7050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5786 - accuracy: 0.8750 - val_loss: 0.7058 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5633 - accuracy: 0.8750 - val_loss: 0.7066 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=58\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.7298 - accuracy: 0.5000 - val_loss: 0.5675 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5923 - accuracy: 0.6250 - val_loss: 0.6577 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6287 - accuracy: 0.7500 - val_loss: 0.6456 - val_accuracy: 0.6667\n",
            "Masterwork: peer=9\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.6471 - accuracy: 0.7500 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5162 - accuracy: 0.7500 - val_loss: 0.6770 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.4184 - accuracy: 0.7500 - val_loss: 0.5160 - val_accuracy: 0.6667\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.3415 - accuracy: 0.7500 - val_loss: 0.4621 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5151 - accuracy: 0.7500 - val_loss: 0.5805 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4934 - accuracy: 0.8750 - val_loss: 0.6923 - val_accuracy: 0.6667\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 650ms/step - loss: 0.2100 - accuracy: 0.8750 - val_loss: 0.6184 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2600 - accuracy: 0.8750 - val_loss: 0.3949 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.1598 - accuracy: 0.8750 - val_loss: 0.3765 - val_accuracy: 0.6667\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.6722 - accuracy: 0.7500 - val_loss: 0.6174 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6482 - accuracy: 0.7500 - val_loss: 0.5769 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.6773 - accuracy: 0.7500 - val_loss: 0.6235 - val_accuracy: 1.0000\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3467 - accuracy: 0.8750 - val_loss: 0.3064 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.3285 - accuracy: 0.8750 - val_loss: 0.4390 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2655 - accuracy: 0.8750 - val_loss: 0.4158 - val_accuracy: 1.0000\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5359 - accuracy: 0.7500 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4299 - accuracy: 0.8750 - val_loss: 0.6870 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3468 - accuracy: 0.7500 - val_loss: 0.5669 - val_accuracy: 1.0000\n",
            "Masterwork: peer=89\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.4434 - accuracy: 0.7500 - val_loss: 0.6311 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4026 - accuracy: 0.7500 - val_loss: 0.5270 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5804 - accuracy: 0.7500 - val_loss: 0.6631 - val_accuracy: 1.0000\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4456 - accuracy: 0.7500 - val_loss: 0.4477 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5088 - accuracy: 0.7500 - val_loss: 0.4569 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3919 - accuracy: 0.7500 - val_loss: 0.4726 - val_accuracy: 0.6667\n",
            "Publisher: master=5\n",
            "[27, 66, 34, 55, 68, 8, 54, 95, 52, 4]\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.3094 - accuracy: 0.8750 - val_loss: 1.6326 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6501 - accuracy: 0.7500 - val_loss: 0.6042 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2995 - accuracy: 0.7500 - val_loss: 0.4588 - val_accuracy: 1.0000\n",
            "Masterwork: peer=66\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.9074 - accuracy: 0.7500 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6911 - accuracy: 0.7500 - val_loss: 0.6210 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5593 - accuracy: 0.7500 - val_loss: 0.5924 - val_accuracy: 0.6667\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.4654 - accuracy: 0.6250 - val_loss: 0.5145 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4108 - accuracy: 0.6250 - val_loss: 0.6965 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4631 - accuracy: 0.8750 - val_loss: 0.7022 - val_accuracy: 0.3333\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.3273 - accuracy: 0.8750 - val_loss: 0.1634 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5030 - accuracy: 0.8750 - val_loss: 0.4172 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3114 - accuracy: 0.8750 - val_loss: 0.5170 - val_accuracy: 1.0000\n",
            "Masterwork: peer=68\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 0.4768 - accuracy: 0.7500 - val_loss: 0.6031 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4289 - accuracy: 0.7500 - val_loss: 0.6069 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4599 - accuracy: 0.7500 - val_loss: 0.6351 - val_accuracy: 0.6667\n",
            "Masterwork: peer=8\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7146 - accuracy: 0.5000 - val_loss: 0.6927 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6508 - accuracy: 0.6250 - val_loss: 0.6942 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6420 - accuracy: 0.6250 - val_loss: 0.6918 - val_accuracy: 0.6667\n",
            "Masterwork: peer=54\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.2453 - accuracy: 0.8750 - val_loss: 1.9320 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7570 - accuracy: 0.8750 - val_loss: 0.8476 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4383 - accuracy: 0.8750 - val_loss: 0.6696 - val_accuracy: 0.3333\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.3285 - accuracy: 0.8750 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5933 - accuracy: 0.8750 - val_loss: 0.3003 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2215 - accuracy: 0.8750 - val_loss: 0.5573 - val_accuracy: 1.0000\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 0.1770 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.9144 - accuracy: 0.5000 - val_loss: 0.6814 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6157 - accuracy: 0.5000 - val_loss: 0.6806 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6717 - accuracy: 0.6250 - val_loss: 0.6800 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "[27, 21, 88, 77, 56, 32, 65, 67, 55, 74]\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.3683 - accuracy: 0.8750 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2384 - accuracy: 0.8750 - val_loss: 0.0198 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2239 - accuracy: 0.8750 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Masterwork: peer=21\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.3347 - accuracy: 0.8750 - val_loss: 0.3312 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3854 - accuracy: 0.8750 - val_loss: 0.3783 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.2044 - accuracy: 0.8750 - val_loss: 0.4792 - val_accuracy: 0.6667\n",
            "Masterwork: peer=88\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.3312 - accuracy: 0.7500 - val_loss: 0.6901 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3165 - accuracy: 0.7500 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3040 - accuracy: 0.8750 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 2.1404 - accuracy: 0.5000 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7251 - accuracy: 0.6250 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6976 - val_accuracy: 0.3333\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.3362 - accuracy: 0.8750 - val_loss: 0.5213 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3492 - accuracy: 0.8750 - val_loss: 0.4957 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2663 - accuracy: 0.8750 - val_loss: 0.4670 - val_accuracy: 0.6667\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.6913 - accuracy: 0.6250 - val_loss: 0.7049 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5799 - accuracy: 0.7500 - val_loss: 0.6397 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5439 - accuracy: 0.8750 - val_loss: 0.4118 - val_accuracy: 1.0000\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 0.3503 - accuracy: 0.8750 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4408 - accuracy: 0.8750 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2253 - accuracy: 0.8750 - val_loss: 0.1339 - val_accuracy: 1.0000\n",
            "Masterwork: peer=67\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.4503 - accuracy: 0.7500 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4126 - accuracy: 0.8750 - val_loss: 0.4941 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4625 - accuracy: 0.7500 - val_loss: 0.5735 - val_accuracy: 0.6667\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3610 - accuracy: 0.7500 - val_loss: 1.4344 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5297 - accuracy: 0.7500 - val_loss: 0.7653 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3871 - accuracy: 0.7500 - val_loss: 0.7010 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.4804 - accuracy: 0.6250 - val_loss: 0.4114 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4114 - accuracy: 1.0000 - val_loss: 0.2517 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6972 - accuracy: 0.6250 - val_loss: 0.4056 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "[91, 68, 52, 39, 57, 26, 11, 78, 75, 30]\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3907 - accuracy: 0.8750 - val_loss: 0.3286 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4128 - accuracy: 0.8750 - val_loss: 0.4827 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3232 - accuracy: 0.7500 - val_loss: 0.5374 - val_accuracy: 0.6667\n",
            "Masterwork: peer=68\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.1793 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 10.1015 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 92.4509 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.0987 - accuracy: 1.0000 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.9473e-08 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3643 - accuracy: 0.6250 - val_loss: 0.4626 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3692 - accuracy: 0.6250 - val_loss: 0.5715 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3773 - accuracy: 0.8750 - val_loss: 0.6710 - val_accuracy: 1.0000\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5721 - accuracy: 0.8750 - val_loss: 0.5200 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3133 - accuracy: 0.8750 - val_loss: 0.2661 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2503 - accuracy: 0.8750 - val_loss: 0.2545 - val_accuracy: 1.0000\n",
            "Masterwork: peer=26\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.7828 - accuracy: 0.7500 - val_loss: 0.6434 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5159 - accuracy: 0.7500 - val_loss: 0.6011 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4699 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.6667\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4713 - accuracy: 0.7500 - val_loss: 0.4501 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4679 - accuracy: 0.7500 - val_loss: 0.4967 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4335 - accuracy: 0.7500 - val_loss: 0.4982 - val_accuracy: 0.6667\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 646ms/step - loss: 0.1552 - accuracy: 1.0000 - val_loss: 1.7417 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 16.2574 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 111.0068 - val_accuracy: 0.6667\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.5792 - accuracy: 0.6250 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4847 - accuracy: 0.7500 - val_loss: 1.0000 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.5032 - accuracy: 0.6250 - val_loss: 0.6887 - val_accuracy: 0.6667\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.6626 - accuracy: 0.6250 - val_loss: 0.3670 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7064 - accuracy: 0.6250 - val_loss: 0.5092 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6144 - accuracy: 0.6250 - val_loss: 0.5866 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "[59, 83, 88, 4, 75, 25, 18, 53, 34, 1]\n",
            "Masterwork: peer=59\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 0.2912 - accuracy: 0.8750 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4903 - accuracy: 0.8750 - val_loss: 0.3794 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2181 - accuracy: 0.8750 - val_loss: 0.5612 - val_accuracy: 1.0000\n",
            "Masterwork: peer=83\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.1922 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.2269 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 53.1231 - val_accuracy: 0.6667\n",
            "Masterwork: peer=88\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.3378 - accuracy: 0.8750 - val_loss: 0.8942 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.3260 - accuracy: 0.8750 - val_loss: 0.8139 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.3058 - accuracy: 0.8750 - val_loss: 0.7402 - val_accuracy: 0.3333\n",
            "Masterwork: peer=4\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.4455 - accuracy: 0.8750 - val_loss: 0.6602 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3378 - accuracy: 0.8750 - val_loss: 0.5684 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2671 - accuracy: 0.8750 - val_loss: 0.5796 - val_accuracy: 0.6667\n",
            "Masterwork: peer=75\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.2763 - accuracy: 0.8750 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6683 - accuracy: 0.8750 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2119 - accuracy: 0.8750 - val_loss: 0.1335 - val_accuracy: 1.0000\n",
            "Masterwork: peer=25\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 1.1418 - accuracy: 0.7500 - val_loss: 0.6969 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6083 - accuracy: 0.7500 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6249 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Masterwork: peer=18\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 654ms/step - loss: 0.8478 - accuracy: 0.2500 - val_loss: 0.6931 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5735 - accuracy: 1.0000 - val_loss: 0.7060 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6135 - accuracy: 1.0000 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 0.4871 - accuracy: 0.8750 - val_loss: 0.6824 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3526 - accuracy: 0.8750 - val_loss: 0.6656 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3185 - accuracy: 0.8750 - val_loss: 0.6755 - val_accuracy: 0.6667\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.5274 - accuracy: 0.7500 - val_loss: 0.6343 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5039 - accuracy: 0.7500 - val_loss: 0.6787 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4378 - accuracy: 0.7500 - val_loss: 0.5608 - val_accuracy: 1.0000\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 0.6477 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5028 - accuracy: 0.7500 - val_loss: 0.5359 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.4258 - accuracy: 0.7500 - val_loss: 0.3604 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "[93, 17, 3, 60, 48, 87, 18, 14, 24, 63]\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3430 - accuracy: 0.8750 - val_loss: 1.4507 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4251 - accuracy: 0.8750 - val_loss: 0.7841 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2788 - accuracy: 0.8750 - val_loss: 0.6441 - val_accuracy: 0.3333\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.6322 - accuracy: 0.6250 - val_loss: 0.6456 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5943 - accuracy: 0.5000 - val_loss: 0.4305 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6746 - accuracy: 0.6250 - val_loss: 0.6839 - val_accuracy: 0.6667\n",
            "Masterwork: peer=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.9700 - accuracy: 0.3750 - val_loss: 0.6972 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6521 - accuracy: 0.7500 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6323 - accuracy: 0.8750 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=60\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.4445 - accuracy: 0.6250 - val_loss: 0.6971 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3843 - accuracy: 0.8750 - val_loss: 0.6898 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.3707 - accuracy: 0.6250 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Masterwork: peer=48\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.4744 - accuracy: 0.7500 - val_loss: 0.5648 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4084 - accuracy: 0.7500 - val_loss: 0.6007 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3582 - accuracy: 0.7500 - val_loss: 0.6857 - val_accuracy: 0.6667\n",
            "Masterwork: peer=87\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4387 - accuracy: 0.7500 - val_loss: 0.2889 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5734 - accuracy: 0.7500 - val_loss: 0.4542 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4356 - accuracy: 0.7500 - val_loss: 0.4788 - val_accuracy: 0.6667\n",
            "Masterwork: peer=18\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 664ms/step - loss: 0.6366 - accuracy: 0.6250 - val_loss: 0.6538 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4565 - accuracy: 0.6250 - val_loss: 0.1392 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.1042 - accuracy: 0.6250 - val_loss: 0.6981 - val_accuracy: 0.3333\n",
            "Masterwork: peer=14\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 1.5326 - accuracy: 0.5000 - val_loss: 0.6893 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8238 - accuracy: 0.6250 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6888 - val_accuracy: 0.6667\n",
            "Masterwork: peer=24\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 0.4929 - accuracy: 0.8750 - val_loss: 0.7055 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4529 - accuracy: 0.8750 - val_loss: 0.7450 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.3242 - accuracy: 0.8750 - val_loss: 0.9209 - val_accuracy: 0.3333\n",
            "Masterwork: peer=63\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.6872 - accuracy: 0.7500 - val_loss: 0.4357 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.4503 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5681 - accuracy: 0.7500 - val_loss: 0.4425 - val_accuracy: 0.6667\n",
            "Publisher: global iteration=39\n",
            "Publisher: master=0\n",
            "[18, 1, 65, 89, 84, 27, 76, 22, 23, 62]\n",
            "Masterwork: peer=18\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.3877 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4445 - accuracy: 0.7500 - val_loss: 0.3037 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3526 - accuracy: 0.7500 - val_loss: 0.4404 - val_accuracy: 1.0000\n",
            "Masterwork: peer=1\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.4677 - accuracy: 0.8750 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8227 - accuracy: 0.6250 - val_loss: 0.4736 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4009 - accuracy: 0.6250 - val_loss: 0.6555 - val_accuracy: 0.3333\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 1.2018 - accuracy: 0.7500 - val_loss: 0.8620 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5642 - accuracy: 0.8750 - val_loss: 1.4122 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4315 - accuracy: 0.8750 - val_loss: 1.5492 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=89\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.4588 - accuracy: 0.7500 - val_loss: 2.0468 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5782 - accuracy: 0.8750 - val_loss: 0.9723 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3464 - accuracy: 0.8750 - val_loss: 0.9047 - val_accuracy: 0.0000e+00\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.5175 - accuracy: 0.7500 - val_loss: 0.6880 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6860 - accuracy: 0.7500 - val_loss: 0.6217 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4699 - accuracy: 0.7500 - val_loss: 0.6277 - val_accuracy: 0.6667\n",
            "Masterwork: peer=27\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 641ms/step - loss: 0.5022 - accuracy: 0.8750 - val_loss: 0.1558 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6224 - accuracy: 0.7500 - val_loss: 0.2951 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4535 - accuracy: 0.7500 - val_loss: 0.4051 - val_accuracy: 1.0000\n",
            "Masterwork: peer=76\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6661 - accuracy: 0.7500 - val_loss: 0.7145 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5701 - accuracy: 0.6250 - val_loss: 0.7543 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5333 - accuracy: 0.6250 - val_loss: 1.1929 - val_accuracy: 0.3333\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6045 - accuracy: 0.6250 - val_loss: 0.6616 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5962 - accuracy: 0.6250 - val_loss: 0.5612 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4805 - accuracy: 0.7500 - val_loss: 0.5699 - val_accuracy: 0.6667\n",
            "Masterwork: peer=23\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.8672 - accuracy: 0.5000 - val_loss: 0.6975 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6977 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6979 - val_accuracy: 0.3333\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6216 - accuracy: 0.7500 - val_loss: 0.6072 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5362 - accuracy: 0.7500 - val_loss: 0.6050 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5111 - accuracy: 0.7500 - val_loss: 0.6007 - val_accuracy: 0.6667\n",
            "Publisher: master=1\n",
            "[53, 86, 79, 65, 0, 5, 56, 77, 7, 93]\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.2976 - accuracy: 0.8750 - val_loss: 0.2878 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2948 - accuracy: 0.7500 - val_loss: 0.6346 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.2516 - accuracy: 0.7500 - val_loss: 0.6784 - val_accuracy: 0.3333\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3284 - accuracy: 0.7500 - val_loss: 0.1650 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5136 - accuracy: 0.7500 - val_loss: 0.4380 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2302 - accuracy: 0.8750 - val_loss: 0.4757 - val_accuracy: 0.6667\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 0.4244 - accuracy: 0.8750 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5145 - accuracy: 0.7500 - val_loss: 0.3054 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3511 - accuracy: 0.7500 - val_loss: 0.5834 - val_accuracy: 1.0000\n",
            "Masterwork: peer=65\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.4249 - accuracy: 0.8750 - val_loss: 1.3888 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3373 - accuracy: 0.8750 - val_loss: 0.9832 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2897 - accuracy: 0.8750 - val_loss: 0.8212 - val_accuracy: 0.3333\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.6826 - accuracy: 0.7500 - val_loss: 0.5378 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5085 - accuracy: 0.7500 - val_loss: 0.5470 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4814 - accuracy: 0.7500 - val_loss: 0.5396 - val_accuracy: 1.0000\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.3121 - accuracy: 1.0000 - val_loss: 0.5680 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5010 - accuracy: 0.7500 - val_loss: 0.6708 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3424 - accuracy: 0.7500 - val_loss: 0.6950 - val_accuracy: 0.6667\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6095 - accuracy: 0.6250 - val_loss: 0.6118 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5442 - accuracy: 0.8750 - val_loss: 0.4719 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.0054 - accuracy: 0.6250 - val_loss: 0.6606 - val_accuracy: 0.6667\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.7422 - accuracy: 0.7500 - val_loss: 0.5312 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6269 - accuracy: 0.7500 - val_loss: 0.5664 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5415 - accuracy: 0.7500 - val_loss: 0.6031 - val_accuracy: 1.0000\n",
            "Masterwork: peer=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.3970 - accuracy: 0.8750 - val_loss: 0.2396 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.3236 - accuracy: 0.8750 - val_loss: 0.2491 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.2249 - accuracy: 0.8750 - val_loss: 0.2863 - val_accuracy: 0.6667\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.8312 - accuracy: 0.5000 - val_loss: 0.7060 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6895 - accuracy: 0.6250 - val_loss: 0.7069 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.6898 - accuracy: 0.6250 - val_loss: 0.7078 - val_accuracy: 0.0000e+00\n",
            "Publisher: master=2\n",
            "[47, 11, 86, 62, 82, 99, 96, 35, 91, 3]\n",
            "Masterwork: peer=47\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.2145 - accuracy: 1.0000 - val_loss: 0.2602 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.9987e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=11\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.3374 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.1747 - accuracy: 0.8750 - val_loss: 2.9091 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5300 - accuracy: 0.8750 - val_loss: 0.9418 - val_accuracy: 0.6667\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.4555 - accuracy: 0.7500 - val_loss: 0.1464 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5536 - accuracy: 0.7500 - val_loss: 0.4300 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3773 - accuracy: 0.8750 - val_loss: 0.4757 - val_accuracy: 0.6667\n",
            "Masterwork: peer=62\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4352 - accuracy: 0.7500 - val_loss: 0.8655 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5195 - accuracy: 0.6250 - val_loss: 0.6795 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.4602 - accuracy: 0.8750 - val_loss: 0.6787 - val_accuracy: 1.0000\n",
            "Masterwork: peer=82\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5658 - accuracy: 0.8750 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.9797 - accuracy: 0.5000 - val_loss: 0.3420 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5032 - accuracy: 0.5000 - val_loss: 0.5045 - val_accuracy: 1.0000\n",
            "Masterwork: peer=99\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5543 - accuracy: 0.7500 - val_loss: 0.0668 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.1951 - accuracy: 0.6250 - val_loss: 0.3474 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5549 - accuracy: 0.6250 - val_loss: 0.5338 - val_accuracy: 1.0000\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4789 - accuracy: 0.8750 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.1678 - accuracy: 0.8750 - val_loss: 8.6217e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1588 - accuracy: 0.8750 - val_loss: 5.5785e-05 - val_accuracy: 1.0000\n",
            "Masterwork: peer=35\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.3923 - accuracy: 0.8750 - val_loss: 0.6410 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4327 - accuracy: 0.8750 - val_loss: 0.5001 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.2872 - accuracy: 0.8750 - val_loss: 0.5048 - val_accuracy: 0.6667\n",
            "Masterwork: peer=91\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.5663 - accuracy: 0.8750 - val_loss: 0.4171 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.9226 - accuracy: 0.7500 - val_loss: 0.5185 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5638 - accuracy: 0.7500 - val_loss: 0.5745 - val_accuracy: 0.6667\n",
            "Masterwork: peer=3\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.3783 - accuracy: 0.6250 - val_loss: 0.2291 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6175 - accuracy: 0.7500 - val_loss: 0.2554 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3639 - accuracy: 0.7500 - val_loss: 0.3897 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "[12, 5, 53, 64, 86, 22, 97, 41, 13, 73]\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 0.4742 - accuracy: 0.8750 - val_loss: 0.1868 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3493 - accuracy: 0.8750 - val_loss: 0.2119 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2934 - accuracy: 0.8750 - val_loss: 0.2334 - val_accuracy: 1.0000\n",
            "Masterwork: peer=5\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.3965 - accuracy: 0.8750 - val_loss: 1.7553 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3482 - accuracy: 0.7500 - val_loss: 3.5960 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3528 - accuracy: 0.7500 - val_loss: 1.7431 - val_accuracy: 0.6667\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.5369 - accuracy: 0.6250 - val_loss: 0.1978 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5370 - accuracy: 0.6250 - val_loss: 0.6227 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5077 - accuracy: 0.6250 - val_loss: 0.6537 - val_accuracy: 1.0000\n",
            "Masterwork: peer=64\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.9193 - accuracy: 0.7500 - val_loss: 0.5523 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5279 - accuracy: 0.8750 - val_loss: 0.4719 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4481 - accuracy: 0.8750 - val_loss: 0.5296 - val_accuracy: 0.6667\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4397 - accuracy: 0.8750 - val_loss: 0.3062 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.2240 - accuracy: 0.8750 - val_loss: 0.3405 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2776 - accuracy: 0.8750 - val_loss: 0.3726 - val_accuracy: 0.6667\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.8923 - accuracy: 0.7500 - val_loss: 0.6890 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6611 - accuracy: 0.5000 - val_loss: 0.6894 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6639 - accuracy: 0.6250 - val_loss: 0.6884 - val_accuracy: 0.6667\n",
            "Masterwork: peer=97\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.3671 - accuracy: 0.8750 - val_loss: 0.2703 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7539 - accuracy: 0.7500 - val_loss: 0.3706 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2991 - accuracy: 0.7500 - val_loss: 0.4037 - val_accuracy: 1.0000\n",
            "Masterwork: peer=41\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.3235 - accuracy: 0.8750 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.4145 - accuracy: 0.8750 - val_loss: 0.4592 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.3190 - accuracy: 0.8750 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Masterwork: peer=13\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.4451 - accuracy: 0.7500 - val_loss: 0.2792 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.7048 - accuracy: 0.6250 - val_loss: 0.4921 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.4265 - accuracy: 0.7500 - val_loss: 0.6740 - val_accuracy: 0.6667\n",
            "Masterwork: peer=73\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.4791 - accuracy: 0.8750 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6079 - accuracy: 0.7500 - val_loss: 0.2773 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.3916 - accuracy: 0.7500 - val_loss: 0.3516 - val_accuracy: 0.6667\n",
            "Publisher: master=4\n",
            "[37, 19, 42, 58, 30, 55, 57, 17, 82, 77]\n",
            "Masterwork: peer=37\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.3261 - accuracy: 1.0000 - val_loss: 0.2375 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7496e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=19\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6915 - accuracy: 0.7500 - val_loss: 0.6555 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5646 - accuracy: 0.6250 - val_loss: 0.4701 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.9425 - accuracy: 0.6250 - val_loss: 0.6388 - val_accuracy: 0.6667\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.4100 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.2855 - accuracy: 0.8750 - val_loss: 0.4550 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3778 - accuracy: 0.8750 - val_loss: 0.4427 - val_accuracy: 0.6667\n",
            "Masterwork: peer=58\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.6409 - accuracy: 0.6250 - val_loss: 0.5875 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6111 - accuracy: 0.7500 - val_loss: 0.5713 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6073 - accuracy: 0.7500 - val_loss: 0.4964 - val_accuracy: 0.3333\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.4429 - accuracy: 0.7500 - val_loss: 0.6867 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4377 - accuracy: 0.7500 - val_loss: 0.4260 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6285 - accuracy: 0.6250 - val_loss: 0.6898 - val_accuracy: 0.6667\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.4895 - accuracy: 0.7500 - val_loss: 0.8383 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6230 - accuracy: 0.7500 - val_loss: 0.7113 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4853 - accuracy: 0.7500 - val_loss: 0.6995 - val_accuracy: 0.3333\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.4687 - accuracy: 0.7500 - val_loss: 0.2525 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.9451 - accuracy: 0.6250 - val_loss: 0.4971 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4329 - accuracy: 0.6250 - val_loss: 0.6297 - val_accuracy: 0.6667\n",
            "Masterwork: peer=17\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 0.4229 - accuracy: 0.8750 - val_loss: 0.1635 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2566 - accuracy: 0.8750 - val_loss: 0.1468 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2891 - accuracy: 0.8750 - val_loss: 0.1899 - val_accuracy: 1.0000\n",
            "Masterwork: peer=82\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 647ms/step - loss: 0.6506 - accuracy: 0.5000 - val_loss: 0.3956 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5798 - accuracy: 0.8750 - val_loss: 0.1933 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4778 - accuracy: 0.6250 - val_loss: 0.2820 - val_accuracy: 0.6667\n",
            "Masterwork: peer=77\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.7922 - accuracy: 0.7500 - val_loss: 0.5506 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4229 - accuracy: 0.8750 - val_loss: 0.6778 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5565 - accuracy: 0.8750 - val_loss: 0.6837 - val_accuracy: 0.6667\n",
            "Publisher: master=5\n",
            "[42, 74, 31, 40, 50, 39, 95, 45, 84, 78]\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5403 - accuracy: 0.6250 - val_loss: 0.2252 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8041 - accuracy: 0.6250 - val_loss: 0.2635 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5777 - accuracy: 0.6250 - val_loss: 0.3712 - val_accuracy: 0.6667\n",
            "Masterwork: peer=74\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.6004 - accuracy: 0.7500 - val_loss: 0.4542 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5761 - accuracy: 0.6250 - val_loss: 0.4535 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5182 - accuracy: 0.6250 - val_loss: 0.3030 - val_accuracy: 1.0000\n",
            "Masterwork: peer=31\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.3314 - accuracy: 0.8750 - val_loss: 0.1925 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3407 - accuracy: 0.8750 - val_loss: 0.2911 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2317 - accuracy: 0.8750 - val_loss: 0.3363 - val_accuracy: 1.0000\n",
            "Masterwork: peer=40\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3116 - accuracy: 0.8750 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=50\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.3986 - accuracy: 0.7500 - val_loss: 0.6189 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3414 - accuracy: 0.7500 - val_loss: 0.2740 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5114 - accuracy: 0.6250 - val_loss: 0.6698 - val_accuracy: 0.6667\n",
            "Masterwork: peer=39\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.3915 - accuracy: 0.7500 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7510 - accuracy: 0.6250 - val_loss: 0.4525 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.4301 - accuracy: 0.6250 - val_loss: 0.6939 - val_accuracy: 0.3333\n",
            "Masterwork: peer=95\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.4527 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.8274 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 58.1373 - val_accuracy: 0.6667\n",
            "Masterwork: peer=45\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.4574 - accuracy: 0.8750 - val_loss: 0.8410 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.8361 - accuracy: 0.7500 - val_loss: 0.7007 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4747 - accuracy: 0.7500 - val_loss: 0.6929 - val_accuracy: 0.6667\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.4653 - accuracy: 0.8750 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.8583 - accuracy: 0.7500 - val_loss: 0.3501 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3828 - accuracy: 0.7500 - val_loss: 0.6564 - val_accuracy: 0.6667\n",
            "Masterwork: peer=78\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.3661 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.4948 - accuracy: 0.7500 - val_loss: 0.7165 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3037 - accuracy: 0.7500 - val_loss: 0.6794 - val_accuracy: 0.3333\n",
            "Publisher: master=6\n",
            "[51, 0, 66, 97, 56, 30, 2, 32, 79, 57]\n",
            "Masterwork: peer=51\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 0.5034 - accuracy: 0.8750 - val_loss: 0.1125 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5727 - accuracy: 0.7500 - val_loss: 0.2341 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4623 - accuracy: 0.7500 - val_loss: 0.3543 - val_accuracy: 1.0000\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.5221 - accuracy: 1.0000 - val_loss: 0.0857 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.2692 - accuracy: 0.8750 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.3727 - accuracy: 0.8750 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
            "Masterwork: peer=66\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 0.4623 - accuracy: 0.7500 - val_loss: 0.3702 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3624 - accuracy: 0.8750 - val_loss: 0.3641 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.3475 - accuracy: 0.8750 - val_loss: 0.3330 - val_accuracy: 0.6667\n",
            "Masterwork: peer=97\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.9302 - accuracy: 0.6250 - val_loss: 0.7056 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6462 - accuracy: 0.6250 - val_loss: 0.6785 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6117 - accuracy: 0.7500 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Masterwork: peer=56\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.4797 - accuracy: 0.8750 - val_loss: 0.6309 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.3025 - accuracy: 0.8750 - val_loss: 0.5871 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.2573 - accuracy: 0.8750 - val_loss: 0.5624 - val_accuracy: 0.6667\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.4118 - accuracy: 0.7500 - val_loss: 0.3408 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.8059 - accuracy: 0.7500 - val_loss: 0.6327 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3670 - accuracy: 0.7500 - val_loss: 0.6967 - val_accuracy: 0.3333\n",
            "Masterwork: peer=2\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6685 - accuracy: 0.7500 - val_loss: 0.6968 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5553 - accuracy: 0.7500 - val_loss: 0.6926 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4367 - accuracy: 0.8750 - val_loss: 0.6070 - val_accuracy: 1.0000\n",
            "Masterwork: peer=32\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.5121 - accuracy: 0.6250 - val_loss: 1.4969 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.4335 - accuracy: 0.7500 - val_loss: 1.1105 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3666 - accuracy: 0.8750 - val_loss: 0.7647 - val_accuracy: 0.6667\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.1970 - accuracy: 0.8750 - val_loss: 1.1940 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 15.9753 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 174.8713 - val_accuracy: 0.3333\n",
            "Masterwork: peer=57\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3325 - accuracy: 0.7500 - val_loss: 0.6402 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6914 - accuracy: 0.8750 - val_loss: 0.7052 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3470 - accuracy: 0.8750 - val_loss: 0.6994 - val_accuracy: 0.6667\n",
            "Publisher: master=7\n",
            "[93, 96, 53, 79, 7, 37, 49, 86, 90, 71]\n",
            "Masterwork: peer=93\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 677ms/step - loss: 0.4846 - accuracy: 0.7500 - val_loss: 0.4962 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5841 - accuracy: 0.6250 - val_loss: 0.4695 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4730 - accuracy: 0.7500 - val_loss: 0.4628 - val_accuracy: 0.6667\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.4027 - accuracy: 0.8750 - val_loss: 0.3220 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.1750 - accuracy: 0.8750 - val_loss: 0.8830 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.8295 - accuracy: 0.8750 - val_loss: 0.3025 - val_accuracy: 0.6667\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.3498 - accuracy: 1.0000 - val_loss: 2.2395 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 11.1286 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 82.0112 - val_accuracy: 0.6667\n",
            "Masterwork: peer=79\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.4411 - accuracy: 0.8750 - val_loss: 0.2424 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.3220 - accuracy: 0.8750 - val_loss: 0.2274 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.4449 - accuracy: 0.7500 - val_loss: 0.2762 - val_accuracy: 1.0000\n",
            "Masterwork: peer=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 0.3916 - accuracy: 0.8750 - val_loss: 0.2508 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.3489 - accuracy: 0.7500 - val_loss: 0.5070 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.2270 - accuracy: 0.7500 - val_loss: 0.6270 - val_accuracy: 0.6667\n",
            "Masterwork: peer=37\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.5044 - accuracy: 0.7500 - val_loss: 1.8294 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5428 - accuracy: 0.8750 - val_loss: 0.7957 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2107 - accuracy: 0.8750 - val_loss: 0.8153 - val_accuracy: 0.3333\n",
            "Masterwork: peer=49\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.3837 - accuracy: 0.7500 - val_loss: 0.2045 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3431 - accuracy: 0.7500 - val_loss: 0.2606 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.3109 - accuracy: 0.7500 - val_loss: 0.2972 - val_accuracy: 0.6667\n",
            "Masterwork: peer=86\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.4473 - accuracy: 0.8750 - val_loss: 1.5356 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.3839 - accuracy: 0.7500 - val_loss: 3.1668 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.3771 - accuracy: 0.7500 - val_loss: 3.5364 - val_accuracy: 0.6667\n",
            "Masterwork: peer=90\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.2967 - accuracy: 1.0000 - val_loss: 0.6369 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 5.2509 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 55.7034 - val_accuracy: 0.6667\n",
            "Masterwork: peer=71\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.3301 - accuracy: 0.8750 - val_loss: 0.5235 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6104 - accuracy: 0.8750 - val_loss: 0.5062 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2710 - accuracy: 0.8750 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
            "Publisher: master=8\n",
            "[71, 7, 30, 0, 88, 42, 46, 52, 12, 55]\n",
            "Masterwork: peer=71\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.2838 - accuracy: 1.0000 - val_loss: 0.6055 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 15.3736 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 133.3599 - val_accuracy: 0.3333\n",
            "Masterwork: peer=7\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 0.3207 - accuracy: 0.8750 - val_loss: 0.4444 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0525 - accuracy: 1.0000 - val_loss: 1.7039 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 64.7327 - val_accuracy: 0.6667\n",
            "Masterwork: peer=30\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.8057 - accuracy: 0.7500 - val_loss: 0.6617 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6507 - accuracy: 0.8750 - val_loss: 0.6366 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6435 - accuracy: 0.7500 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
            "Masterwork: peer=0\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.3482 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.2992 - accuracy: 0.8750 - val_loss: 0.4725 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.3685 - accuracy: 0.8750 - val_loss: 0.5249 - val_accuracy: 0.6667\n",
            "Masterwork: peer=88\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5630 - accuracy: 0.5000 - val_loss: 0.4817 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5403 - accuracy: 0.8750 - val_loss: 0.4709 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7019 - accuracy: 0.6250 - val_loss: 0.4808 - val_accuracy: 0.3333\n",
            "Masterwork: peer=42\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.1533 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.3053 - accuracy: 0.8750 - val_loss: 0.3257 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.1572 - accuracy: 0.8750 - val_loss: 0.4553 - val_accuracy: 0.6667\n",
            "Masterwork: peer=46\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 1.1198 - accuracy: 0.8750 - val_loss: 0.6453 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5287 - accuracy: 0.7500 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.4566 - accuracy: 0.7500 - val_loss: 0.6123 - val_accuracy: 0.6667\n",
            "Masterwork: peer=52\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.7200 - accuracy: 0.8750 - val_loss: 0.4199 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6117 - accuracy: 0.7500 - val_loss: 0.5385 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3639 - accuracy: 0.7500 - val_loss: 0.5142 - val_accuracy: 1.0000\n",
            "Masterwork: peer=12\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6093 - accuracy: 0.6250 - val_loss: 0.4394 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5766 - accuracy: 0.7500 - val_loss: 0.3023 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5103 - accuracy: 0.7500 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
            "Masterwork: peer=55\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.5157 - accuracy: 0.7500 - val_loss: 0.4597 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5420 - accuracy: 0.7500 - val_loss: 0.5754 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4176 - accuracy: 0.7500 - val_loss: 0.5573 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "[96, 53, 34, 10, 22, 84, 43, 82, 70, 81]\n",
            "Masterwork: peer=96\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.4310 - accuracy: 0.7500 - val_loss: 0.5848 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.2959 - accuracy: 0.7500 - val_loss: 1.0061 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.3912 - accuracy: 0.7500 - val_loss: 0.5542 - val_accuracy: 0.6667\n",
            "Masterwork: peer=53\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.2716 - accuracy: 1.0000 - val_loss: 0.2011 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 4.3710e-07 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Masterwork: peer=34\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.4847 - accuracy: 0.6250 - val_loss: 0.1027 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.1456 - accuracy: 0.6250 - val_loss: 0.2621 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.4769 - accuracy: 0.6250 - val_loss: 0.4646 - val_accuracy: 0.6667\n",
            "Masterwork: peer=10\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.5072 - accuracy: 0.7500 - val_loss: 0.3733 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.7720 - accuracy: 0.8750 - val_loss: 0.5592 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.3633 - accuracy: 0.8750 - val_loss: 0.5953 - val_accuracy: 0.6667\n",
            "Masterwork: peer=22\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.1810 - accuracy: 1.0000 - val_loss: 0.6742 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.7971 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 54.6083 - val_accuracy: 0.6667\n",
            "Masterwork: peer=84\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 0.5260 - accuracy: 0.8750 - val_loss: 0.3536 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0851 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 3.8743e-07 - accuracy: 1.0000 - val_loss: 20.3988 - val_accuracy: 0.6667\n",
            "Masterwork: peer=43\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 1.2126 - accuracy: 0.3750 - val_loss: 0.6974 - val_accuracy: 0.3333\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.7231 - accuracy: 0.5000 - val_loss: 0.6978 - val_accuracy: 0.3333\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6898 - accuracy: 0.6250 - val_loss: 0.6980 - val_accuracy: 0.3333\n",
            "Masterwork: peer=82\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.3425 - accuracy: 0.7500 - val_loss: 0.5650 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.3518 - accuracy: 0.6250 - val_loss: 0.3553 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.0773 - accuracy: 0.6250 - val_loss: 0.6832 - val_accuracy: 0.6667\n",
            "Masterwork: peer=70\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5291 - accuracy: 0.7500 - val_loss: 0.1298 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7651 - accuracy: 0.6250 - val_loss: 0.3725 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5057 - accuracy: 0.6250 - val_loss: 0.5316 - val_accuracy: 0.6667\n",
            "Masterwork: peer=81\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.3096 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.6667\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.1750 - accuracy: 0.8750 - val_loss: 0.9521 - val_accuracy: 0.6667\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5765 - accuracy: 0.8750 - val_loss: 0.4246 - val_accuracy: 0.6667\n",
            "Publisher: finished all global\n",
            "Accuracy on Val Data:  [0.74, 0.74, 0.74, 0.74, 0.74, 0.7408, 0.7404, 0.3432, 0.7404, 0.323, 0.7621, 0.5742, 0.58, 0.349, 0.6224, 0.332, 0.7542, 0.3392, 0.6904, 0.4786, 0.6705, 0.5771, 0.5945, 0.4012, 0.6513, 0.593, 0.6857, 0.5648, 0.6159, 0.5659, 0.7013, 0.5684, 0.7321, 0.5934, 0.727, 0.6133, 0.6394, 0.7842, 0.6235, 0.7393]\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for i in [500, 1000]:\n",
        "    result = pair_wise_xp(np.copy(x_covid), np.copy(y_covid), get_covid_model(), [1, 2, 5, 10], i, 40, 3, deep_copy_covid_model, sample_value=0.1, random_state=1)\n",
        "    np.save(f\"{i}.npy\", result)\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "6DOsigV_eaqS",
        "outputId": "9ef24705-fa3f-4ff5-fe3c-31eae20b7a98"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_a927e84c-d4a2-4c25-bc62-5b28a7713ce7\", \"1000.npy\", 4654)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('1000.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "id": "I8k6kRoP3eYM",
        "outputId": "03b05df0-384a-4f72-b482-41d4061f784b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.74, 0.7404, 0.79, 0.7683, 0.8038, 0.798, 0.7839, 0.8132, 0.8255, 0.7831, 0.8215, 0.8085]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(results[0][0])\n",
        "pair_wise_post_process(results[1],  [1, 2, 5, 10], 100, 40, [0.80, 0.75])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsdipKWMCb1L"
      },
      "source": [
        "# Fraud Detection Dataset (Not used as data is split 90 to 10, so model only predicts one class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d_o4PIUuJXw"
      },
      "outputs": [],
      "source": [
        "! kaggle datasets download rohitrox/healthcare-provider-fraud-detection-analysis\n",
        "! unzip healthcare-provider-fraud-detection-analysis.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyUTg6w7CnrU"
      },
      "outputs": [],
      "source": [
        "def read_fraud_data():\n",
        "    def read_data(tp = \"Train\", N = 1542865627584):\n",
        "        target = pd.read_csv(\"./{}-{}.csv\".format(tp.title(), N))\n",
        "        pt = pd.read_csv(\"./{}_Beneficiarydata-{}.csv\".format(tp.title(), N))\n",
        "        in_pt = pd.read_csv(\"./{}_Inpatientdata-{}.csv\".format(tp.title(), N))\n",
        "        out_pt = pd.read_csv(\"./{}_Outpatientdata-{}.csv\".format(tp.title(), N))\n",
        "        return (in_pt, out_pt, pt, target)\n",
        "    def N_unique_values(df):\n",
        "        return np.array([len(set([i for i in x[~pd.isnull(x)]])) for x in df.values])\n",
        "    ### Load data\n",
        "    in_pt, out_pt, ben, target = read_data()\n",
        "    ben = ben.replace({'ChronicCond_Alzheimer': 2, 'ChronicCond_Heartfailure': 2, 'ChronicCond_KidneyDisease': 2,\n",
        "                    'ChronicCond_Cancer': 2, 'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2,\n",
        "                    'ChronicCond_Diabetes': 2, 'ChronicCond_IschemicHeart': 2, 'ChronicCond_Osteoporasis': 2,\n",
        "                    'ChronicCond_rheumatoidarthritis': 2, 'ChronicCond_stroke': 2, 'Gender': 2 }, \n",
        "                    0)\n",
        "    ben = ben.replace({'RenalDiseaseIndicator': 'Y'}, 1).astype({'RenalDiseaseIndicator': 'int64'})\n",
        "    # Change target variable to binary\n",
        "    target[\"target\"] = np.where(target.PotentialFraud == \"Yes\", 1, 0) \n",
        "    target.drop('PotentialFraud', axis=1, inplace=True)\n",
        "    data = pd.merge(in_pt, out_pt,\n",
        "                    left_on = [ idx for idx in out_pt.columns if idx in in_pt.columns],\n",
        "                    right_on = [ idx for idx in out_pt.columns if idx in in_pt.columns],\n",
        "                    how = 'outer').\\\n",
        "          merge(ben,left_on='BeneID',right_on='BeneID',how='inner')\n",
        "    patient_merge_id = [i for i in out_pt.columns if i in in_pt.columns]\n",
        "    # Merge in_pt, out_pt and ben df into a single patient dataset\n",
        "    data = pd.merge(in_pt, out_pt,\n",
        "                        left_on = patient_merge_id,\n",
        "                        right_on = patient_merge_id,\n",
        "                        how = 'outer').\\\n",
        "            merge(ben,left_on='BeneID',right_on='BeneID',how='inner')\n",
        "    # We find the number of unique physicians \n",
        "    data['N_unique_Physicians'] = N_unique_values(data[['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']]) \n",
        "    # We separate the types of physicians into numeric values\n",
        "    data[['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']] = np.where(data[['AttendingPhysician','OperatingPhysician',\n",
        "                                                                                        'OtherPhysician']].isnull(), 0, 1)\n",
        "    # We count the number of types of physicians that attend the patient\n",
        "    data['N_Types_Physicians'] = data['AttendingPhysician'] +  data['OperatingPhysician'] + data['OtherPhysician']\n",
        "    # Now we create a variable to check if there is a single doctor on a patient that was attended by more than 1 type of doctor\n",
        "    # This helps us finds those cases that are only looked at by 1 physicians\n",
        "    data['Same_Physician'] = data.apply(lambda x: 1 if (x['N_unique_Physicians'] == 1 and x['N_Types_Physicians'] > 1) else 0,axis=1)\n",
        "    # Similar to Same_Physician, we create a variable to see if 1 physicians has had multiple roles, but has not been alone reviewing the case\n",
        "    data['Same_Physician2'] = data.apply(lambda x: 1 if (x['N_unique_Physicians'] == 2 and x['N_Types_Physicians'] > 2) else 0,axis=1)\n",
        "    # We count the number of procedures for each claim, we drop the initial variables\n",
        "    ClmProcedure_vars = ['ClmProcedureCode_{}'.format(x) for x in range(1,7)]\n",
        "    data['N_Procedure'] = N_unique_values(data[ClmProcedure_vars])\n",
        "    data = data.drop(ClmProcedure_vars, axis = 1)\n",
        "    # We count the number of claims, we also separate this by unique claims and extra claims, we drop the initial variables\n",
        "    ClmDiagnosisCode_vars =['ClmAdmitDiagnosisCode'] + ['ClmDiagnosisCode_{}'.format(x) for x in range(1, 11)]\n",
        "    data['N_Unique_Claims'] = N_unique_values(data[ClmDiagnosisCode_vars])\n",
        "    data['N_Total_Claims'] = data[ClmDiagnosisCode_vars].notnull().to_numpy().sum(axis = 1)\n",
        "    data['N_Extra_Claims'] = data['N_Total_Claims'] - data['N_Unique_Claims']\n",
        "    ClmDiagnosisCode_vars.append('N_Total_Claims')\n",
        "    data = data.drop(ClmDiagnosisCode_vars, axis = 1)\n",
        "    #  Transform string columns of date into type date\n",
        "    data['AdmissionDt'] = pd.to_datetime(data['AdmissionDt'] , format = '%Y-%m-%d')\n",
        "    data['DischargeDt'] = pd.to_datetime(data['DischargeDt'],format = '%Y-%m-%d')\n",
        "    data['ClaimStartDt'] = pd.to_datetime(data['ClaimStartDt'] , format = '%Y-%m-%d')\n",
        "    data['ClaimEndDt'] = pd.to_datetime(data['ClaimEndDt'],format = '%Y-%m-%d')\n",
        "    data['DOB'] = pd.to_datetime(data['DOB'] , format = '%Y-%m-%d')\n",
        "    data['DOD'] = pd.to_datetime(data['DOD'],format = '%Y-%m-%d')\n",
        "    # Number of days\n",
        "    data['Admission_Days'] = ((data['DischargeDt'] - data['AdmissionDt']).dt.days) + 1\n",
        "    # Number of claim days \n",
        "    data['Claim_Days'] = ((data['ClaimEndDt'] - data['ClaimStartDt']).dt.days) + 1\n",
        "    # Age at the time of claim\n",
        "    data['Age'] = round(((data['ClaimStartDt'] - data['DOB']).dt.days + 1)/365.25)\n",
        "    # We create a Hospitalization flag \n",
        "    data['Hospt'] = np.where(data.DiagnosisGroupCode.notnull(), 1, 0)\n",
        "    data = data.drop(['DiagnosisGroupCode'], axis = 1)\n",
        "    # Variable if patient is dead\n",
        "    data['Dead']= 0\n",
        "    data.loc[data.DOD.notna(),'Dead'] = 1\n",
        "    data['Missing_Deductible_Amount_Paid'] = 0\n",
        "    data.loc[data['DeductibleAmtPaid'].isnull(), 'Missing_Deductible_Amount_Paid'] = 1 \n",
        "    data = data.fillna(0).copy()\n",
        "    _sum = data.groupby(['Provider'], as_index = False)[['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'RenalDiseaseIndicator', \n",
        "                                                    'ChronicCond_Alzheimer', 'AttendingPhysician', 'OperatingPhysician', \n",
        "                                                    'OtherPhysician', 'N_unique_Physicians', 'ChronicCond_Heartfailure', \n",
        "                                                    'N_Types_Physicians', 'Same_Physician',\n",
        "                                                    'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', \n",
        "                                                    'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', \n",
        "                                                    'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', \n",
        "                                                    'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n",
        "                                                    'ChronicCond_stroke', 'Dead', \n",
        "                                                    'N_Procedure','N_Unique_Claims', 'N_Extra_Claims', 'Admission_Days',\n",
        "                                                    'Claim_Days', 'Hospt', 'Missing_Deductible_Amount_Paid']].sum()\n",
        "\n",
        "    # To separate our variables, we shall add '_sum' at the end of their names\n",
        "    _sum = _sum.add_suffix('_sum')\n",
        "    ### Count number of records\n",
        "    _count = data[['BeneID', 'ClaimID']].groupby(data['Provider']).nunique().reset_index()\n",
        "    _count.rename(columns={'BeneID':'BeneID_count','ClaimID':'ClaimID_count'},inplace=True)\n",
        "    ### Calculate mean for all numeric variables\n",
        "    _mean = data.groupby(['Provider'], as_index = False)[['NoOfMonths_PartACov', 'NoOfMonths_PartBCov',\n",
        "                                                        'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n",
        "                                                        'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n",
        "                                                        'AttendingPhysician', 'OperatingPhysician','OtherPhysician',\n",
        "                                                        'N_unique_Physicians', 'ChronicCond_Heartfailure', \n",
        "                                                        'N_Types_Physicians', 'Same_Physician',\n",
        "                                                        'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', \n",
        "                                                        'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', \n",
        "                                                        'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', \n",
        "                                                        'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n",
        "                                                        'ChronicCond_stroke', 'Dead', 'N_Procedure','N_Unique_Claims', \n",
        "                                                        'N_Extra_Claims', 'Admission_Days','Claim_Days', 'Hospt',\n",
        "                                                        'Missing_Deductible_Amount_Paid'\n",
        "                                                    ]].mean()\n",
        "    # To separate our variables, we shall add '_mean' at the end of their names\n",
        "    _mean = _mean.add_suffix('_mean')\n",
        "    # We create a dataset that holds all the variables\n",
        "    _total = _count.merge(_sum, how='left',left_on='Provider',right_on='Provider_sum').\\\n",
        "                    merge(_mean, how='left',left_on='Provider',right_on='Provider_mean').\\\n",
        "                    drop(['Provider_sum','Provider_mean'], axis=1).\\\n",
        "                    merge(target, on='Provider', how='left')\n",
        "    df = _total[['InscClaimAmtReimbursed_sum','N_Extra_Claims_sum','Claim_Days_sum',\n",
        "             'AttendingPhysician_mean','Missing_Deductible_Amount_Paid_mean','Dead_mean','Claim_Days_mean','N_Extra_Claims_mean',\n",
        "             'BeneID_count','ClaimID_count',\n",
        "             'Provider','target']]\n",
        "    print(df.head(3))\n",
        "    all_data = df.drop(['Provider'], axis=1)\n",
        "    x = all_data.drop(['target'], axis=1)\n",
        "    y = all_data.target\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    x = np.stack(x,axis=0)\n",
        "    return x,y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BynbCvCFs6W"
      },
      "outputs": [],
      "source": [
        "def get_fraud_model():\n",
        "    sim_model = models.Sequential()\n",
        "    sim_model.add(layers.Dense(8, activation='relu', input_dim=10))\n",
        "    sim_model.add(layers.Dense(4, activation='relu'))\n",
        "    sim_model.add(layers.Dense(2))\n",
        "\n",
        "\n",
        "    sim_model.compile(\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer= optimizers.RMSprop(lr=0.01), metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n",
        "    sim_model.summary()\n",
        "    return sim_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL4OgW-nHags"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import optimizers\n",
        "def deep_copy_fraud_model(model):\n",
        "    model_copy= keras.models.clone_model(model)\n",
        "    model_copy.compile(\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "        optimizer=optimizers.RMSprop(lr=0.01), metrics=['accuracy']\n",
        "    )\n",
        "    model_copy.set_weights(model.get_weights())\n",
        "    return model_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMsKBzmJCn1N",
        "outputId": "bf46c656-94d1-486f-f23e-2aa897119543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   InscClaimAmtReimbursed_sum  N_Extra_Claims_sum  Claim_Days_sum  \\\n",
            "0                      104640                   0              61   \n",
            "1                      605670                  10             617   \n",
            "2                       52170                   3             362   \n",
            "\n",
            "   AttendingPhysician_mean  Missing_Deductible_Amount_Paid_mean  Dead_mean  \\\n",
            "0                      1.0                                  0.0   0.000000   \n",
            "1                      1.0                                  0.0   0.007576   \n",
            "2                      1.0                                  0.0   0.006711   \n",
            "\n",
            "   Claim_Days_mean  N_Extra_Claims_mean  BeneID_count  ClaimID_count  \\\n",
            "0         2.440000             0.000000            24             25   \n",
            "1         4.674242             0.075758           117            132   \n",
            "2         2.429530             0.020134           138            149   \n",
            "\n",
            "   Provider  target  \n",
            "0  PRV51001       0  \n",
            "1  PRV51003       1  \n",
            "2  PRV51004       0  \n",
            "(5410, 10)\n",
            "(5410,)\n"
          ]
        }
      ],
      "source": [
        "x_fraud, y_fraud = read_fraud_data()\n",
        "print(x_fraud.shape)\n",
        "print(y_fraud.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhcUrzZEHnyw",
        "outputId": "69f88219-c331-45de-f024-86bf0fc026cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_23 (Dense)            (None, 8)                 88        \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 2)                 10        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134\n",
            "Trainable params: 134\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "------------------------------------------------------------------\n",
            "XP Parameters: peers in grp=1, no groups=1\n",
            "------------------------------------------------------------------\n",
            "Publisher: global iteration=0\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 1s 12ms/step - loss: 10809.1113 - val_loss: 8789.7900\n",
            "Epoch 2/2\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 7212.9062 - val_loss: 6464.6558\n",
            "Publisher: finished all global\n",
            "Accuracy on Val Data:  [0.098]\n"
          ]
        }
      ],
      "source": [
        "test2 = complete_xp(np.copy(x_fraud), np.copy(y_fraud), get_fraud_model(), [1], [1], 1, 2, deep_copy_fraud_model,random_state=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "IHuQKL8ECn5G",
        "outputId": "d67e9c5d-bf26-4f66-a24c-0f0a185dbcb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 29ms/step - loss: 0.7311 - accuracy: 0.0694 - val_loss: 0.7111 - val_accuracy: 0.1351\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 0.7815 - accuracy: 0.0694 - val_loss: 0.7396 - val_accuracy: 0.1622\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7517 - accuracy: 0.0694 - val_loss: 0.7231 - val_accuracy: 0.1622\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.7311 - accuracy: 0.0694 - val_loss: 0.7098 - val_accuracy: 0.1622\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.7751 - accuracy: 0.0972 - val_loss: 0.7467 - val_accuracy: 0.1081\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.7454 - accuracy: 0.0972 - val_loss: 0.7278 - val_accuracy: 0.1081\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7253 - accuracy: 0.0972 - val_loss: 0.7125 - val_accuracy: 0.1081\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 620ms/step - loss: 0.7720 - accuracy: 0.0972 - val_loss: 3683.6145 - val_accuracy: 0.8378\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1265.3853 - accuracy: 0.9097 - val_loss: 0.7444 - val_accuracy: 0.1622\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7494 - accuracy: 0.0972 - val_loss: 0.7275 - val_accuracy: 0.1622\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 606ms/step - loss: 0.7707 - accuracy: 0.1250 - val_loss: 0.7467 - val_accuracy: 0.1081\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7445 - accuracy: 0.1250 - val_loss: 0.7278 - val_accuracy: 0.1081\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.7263 - accuracy: 0.1250 - val_loss: 0.7125 - val_accuracy: 0.1081\n",
            "Epoch 1/3\n",
            "1/1 [==============================] - 1s 590ms/step - loss: 0.7803 - accuracy: 0.0758 - val_loss: 0.7608 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.7509 - accuracy: 0.0758 - val_loss: 0.7371 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.7305 - accuracy: 0.0758 - val_loss: 0.7177 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-b11788e64049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Centralized FL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0macc_fl_fraud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplete_xp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_fraud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_fraud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_fraud_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fraud_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-a7395ac17661>\u001b[0m in \u001b[0;36mcomplete_xp\u001b[0;34m(x, y, model, no_grps_list, peers_in_grp_list, global_rounds, local_epochs, deep_copy_fn, random_state)\u001b[0m\n\u001b[1;32m     10\u001b[0m            acc = publisher(\n\u001b[1;32m     11\u001b[0m                \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_grps_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeers_in_grp_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                \u001b[0mglobal_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m            )\n\u001b[1;32m     14\u001b[0m            \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-85485d4dc6f3>\u001b[0m in \u001b[0;36mpublisher\u001b[0;34m(x, y, model, no_grps, peers_in_grp, global_rounds, local_epochs, deep_copy_fn, random_state)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 master_work(\n\u001b[1;32m     25\u001b[0m                     \u001b[0mx_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                     \u001b[0mpeers_in_grp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 )\n\u001b[1;32m     28\u001b[0m             )\n",
            "\u001b[0;32m<ipython-input-8-ce33bc17ccec>\u001b[0m in \u001b[0;36mmaster_work\u001b[0;34m(x, y, model, no_peers, local_epochs, deep_copy_fn)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mclient_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_weight_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep_copy_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-770d610092c3>\u001b[0m in \u001b[0;36mmodel_weight_ensemble\u001b[0;34m(models, deep_copy_fn)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# collect this layer from each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlayer_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# weighted average of weights for this layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# avg_layer_weights = np.average(layer_weights, axis=0, weights=weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-770d610092c3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# collect this layer from each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlayer_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# weighted average of weights for this layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# avg_layer_weights = np.average(layer_weights, axis=0, weights=weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2328\u001b[0m     \"\"\"\n\u001b[1;32m   2329\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtraceback_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m         \u001b[0moutput_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1919\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   3957\u001b[0m   \"\"\"\n\u001b[1;32m   3958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3959\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3960\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3961\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3957\u001b[0m   \"\"\"\n\u001b[1;32m   3958\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3959\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3960\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3961\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    676\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \"\"\"\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m   \u001b[0;34m\"\"\"Records that `variable` was accessed for the tape and FuncGraph.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"watch_variable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   6308\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6309\u001b[0m   \"\"\"\n\u001b[0;32m-> 6310\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5816\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5817\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5818\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_default_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5819\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_default_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5820\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Centralized FL\n",
        "acc_fl_fraud = complete_xp(np.copy(x_fraud), np.copy(y_fraud), get_fraud_model(), [1], [6, 12, 18, 24, 36, 48, 72], 10, 3, deep_copy_fraud_model,random_state=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-k643USdiPs"
      },
      "outputs": [],
      "source": [
        "plot_accuracy_curve_cfl(acc_fl_fraud,[6, 12, 18, 24, 36, 48, 72])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xuc3meCyU3JA",
        "outputId": "228e965a-7956-40f0-b484-f06201f5f0c5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tmp = get_metrics(acc_fl_fraud, [0.70, 0.8])\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[0], \"Final Accuracy\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[1], \"Max Accuracy\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[2][0], \"Rounds to 70%\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[2][1], \"Rounds to 80%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArKJ5s4GOEKr",
        "outputId": "c81b38ee-1fe4-47ba-f818-7a208bdbf176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6189 - accuracy: 0.9583 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6248 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6295 - accuracy: 0.8958 - val_loss: 0.6223 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6189 - accuracy: 0.9583 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6353 - accuracy: 0.8750 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6331 - accuracy: 0.8750 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6227 - accuracy: 0.9524 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6200 - accuracy: 0.9524 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6189 - accuracy: 0.9583 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6387 - accuracy: 0.8542 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6366 - accuracy: 0.8542 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6184 - accuracy: 0.9792 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6154 - accuracy: 0.9792 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.6190 - accuracy: 0.9583 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6305 - accuracy: 0.9048 - val_loss: 0.6273 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6281 - accuracy: 0.9048 - val_loss: 0.6249 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6641 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6631 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6295 - accuracy: 0.8958 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6118 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6455 - accuracy: 0.8125 - val_loss: 0.6641 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6437 - accuracy: 0.8125 - val_loss: 0.6631 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6510 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6495 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6382 - accuracy: 0.8571 - val_loss: 0.6273 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6361 - accuracy: 0.8571 - val_loss: 0.6249 - val_accuracy: 0.9091\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6190 - accuracy: 0.9583 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6190 - accuracy: 0.9583 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6455 - accuracy: 0.8125 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6437 - accuracy: 0.8125 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6421 - accuracy: 0.8333 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6402 - accuracy: 0.8333 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6223 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6455 - accuracy: 0.8125 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6437 - accuracy: 0.8125 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6190 - accuracy: 0.9583 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6460 - accuracy: 0.8095 - val_loss: 0.6273 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6442 - accuracy: 0.8095 - val_loss: 0.6248 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6387 - accuracy: 0.8542 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6366 - accuracy: 0.8542 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6421 - accuracy: 0.8333 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6402 - accuracy: 0.8333 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6387 - accuracy: 0.8542 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6366 - accuracy: 0.8542 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6353 - accuracy: 0.8750 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6331 - accuracy: 0.8750 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6188 - accuracy: 0.9762 - val_loss: 0.6582 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6159 - accuracy: 0.9762 - val_loss: 0.6569 - val_accuracy: 0.7273\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6190 - accuracy: 0.9583 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6183 - accuracy: 0.9792 - val_loss: 0.6511 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6154 - accuracy: 0.9792 - val_loss: 0.6495 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6251 - accuracy: 0.9375 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6225 - accuracy: 0.9375 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6353 - accuracy: 0.8750 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6331 - accuracy: 0.8750 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6641 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6631 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6460 - accuracy: 0.8095 - val_loss: 0.6118 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6442 - accuracy: 0.8095 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6319 - accuracy: 0.8958 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6296 - accuracy: 0.8958 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.6421 - accuracy: 0.8333 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6402 - accuracy: 0.8333 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.6387 - accuracy: 0.8542 - val_loss: 0.6249 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6366 - accuracy: 0.8542 - val_loss: 0.6224 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6387 - accuracy: 0.8542 - val_loss: 0.6248 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6366 - accuracy: 0.8542 - val_loss: 0.6222 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6285 - accuracy: 0.9167 - val_loss: 0.6380 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6260 - accuracy: 0.9167 - val_loss: 0.6360 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6217 - accuracy: 0.9583 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6190 - accuracy: 0.9583 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6353 - accuracy: 0.8750 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6331 - accuracy: 0.8750 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6227 - accuracy: 0.9524 - val_loss: 0.6119 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6200 - accuracy: 0.9524 - val_loss: 0.6088 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=4\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6480 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6465 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6324 - accuracy: 0.8542 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6456 - accuracy: 0.7917 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6439 - accuracy: 0.7917 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6324 - accuracy: 0.8542 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6298 - accuracy: 0.8810 - val_loss: 0.6391 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6276 - accuracy: 0.8810 - val_loss: 0.6372 - val_accuracy: 0.8182\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6529 - accuracy: 0.7500 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6515 - accuracy: 0.7500 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6480 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6171 - accuracy: 0.9375 - val_loss: 0.6465 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6480 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6465 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6130 - accuracy: 0.9762 - val_loss: 0.6224 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6101 - accuracy: 0.9762 - val_loss: 0.6200 - val_accuracy: 0.9091\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6172 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6325 - accuracy: 0.8542 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6125 - accuracy: 0.9792 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6096 - accuracy: 0.9792 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6256 - accuracy: 0.9048 - val_loss: 0.6224 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6232 - accuracy: 0.9048 - val_loss: 0.6200 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6324 - accuracy: 0.8542 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6161 - accuracy: 0.9583 - val_loss: 0.6197 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6133 - accuracy: 0.9583 - val_loss: 0.6171 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6493 - accuracy: 0.7708 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6477 - accuracy: 0.7708 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6026 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6382 - accuracy: 0.8333 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6125 - accuracy: 0.9792 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6096 - accuracy: 0.9792 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6621 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6611 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6346 - accuracy: 0.8542 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6325 - accuracy: 0.8542 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6419 - accuracy: 0.8125 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6401 - accuracy: 0.8125 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6162 - accuracy: 0.9583 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6134 - accuracy: 0.9583 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6424 - accuracy: 0.8095 - val_loss: 0.6224 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6406 - accuracy: 0.8095 - val_loss: 0.6199 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6382 - accuracy: 0.8333 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6197 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6171 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6382 - accuracy: 0.8333 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.6308 - accuracy: 0.8750 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6125 - accuracy: 0.9792 - val_loss: 0.6480 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6095 - accuracy: 0.9792 - val_loss: 0.6465 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.6214 - accuracy: 0.9286 - val_loss: 0.6224 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6188 - accuracy: 0.9286 - val_loss: 0.6200 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6125 - accuracy: 0.9792 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6096 - accuracy: 0.9792 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6197 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6171 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6198 - accuracy: 0.9375 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6172 - accuracy: 0.9375 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6346 - accuracy: 0.8542 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6325 - accuracy: 0.8542 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6382 - accuracy: 0.8333 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6340 - accuracy: 0.8571 - val_loss: 0.6391 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6319 - accuracy: 0.8571 - val_loss: 0.6372 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6272 - accuracy: 0.8958 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6248 - accuracy: 0.8958 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6235 - accuracy: 0.9167 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6324 - accuracy: 0.8542 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6325 - accuracy: 0.8542 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6345 - accuracy: 0.8542 - val_loss: 0.6198 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6324 - accuracy: 0.8542 - val_loss: 0.6173 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6088 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6058 - accuracy: 1.0000 - val_loss: 0.6319 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6309 - accuracy: 0.8750 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6286 - accuracy: 0.8750 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6172 - accuracy: 0.9524 - val_loss: 0.6058 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6145 - accuracy: 0.9524 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=5\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6225 - accuracy: 0.8958 - val_loss: 0.6147 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6201 - accuracy: 0.8958 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6304 - accuracy: 0.8542 - val_loss: 0.5995 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6283 - accuracy: 0.8542 - val_loss: 0.5964 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6066 - accuracy: 0.9792 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6037 - accuracy: 0.9792 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6146 - accuracy: 0.9375 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6383 - accuracy: 0.8125 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6365 - accuracy: 0.8125 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6263 - accuracy: 0.8750 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6241 - accuracy: 0.8750 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6208 - accuracy: 0.9048 - val_loss: 0.6533 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6183 - accuracy: 0.9048 - val_loss: 0.6521 - val_accuracy: 0.7273\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6383 - accuracy: 0.8125 - val_loss: 0.6753 - val_accuracy: 0.6154\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6365 - accuracy: 0.8125 - val_loss: 0.6748 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6225 - accuracy: 0.8958 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6201 - accuracy: 0.8958 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6066 - accuracy: 0.9792 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6037 - accuracy: 0.9792 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6296 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6276 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.5965 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6117 - accuracy: 0.9524 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6090 - accuracy: 0.9524 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6145 - accuracy: 0.9375 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6225 - accuracy: 0.8958 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6201 - accuracy: 0.8958 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.6147 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6145 - accuracy: 0.9375 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.5965 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6066 - accuracy: 0.9792 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6037 - accuracy: 0.9792 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6146 - accuracy: 0.9375 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6253 - accuracy: 0.8810 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6230 - accuracy: 0.8810 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6147 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 674ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6449 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6434 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6145 - accuracy: 0.9375 - val_loss: 0.5995 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6118 - accuracy: 0.9375 - val_loss: 0.5965 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6423 - accuracy: 0.7917 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6406 - accuracy: 0.7917 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6253 - accuracy: 0.8810 - val_loss: 0.6354 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6230 - accuracy: 0.8810 - val_loss: 0.6336 - val_accuracy: 0.8182\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6146 - accuracy: 0.9375 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.5965 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6225 - accuracy: 0.8958 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6201 - accuracy: 0.8958 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6304 - accuracy: 0.8542 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6283 - accuracy: 0.8542 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6343 - accuracy: 0.8333 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6324 - accuracy: 0.8333 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6343 - accuracy: 0.8333 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6324 - accuracy: 0.8333 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.6389 - accuracy: 0.8095 - val_loss: 0.6175 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6371 - accuracy: 0.8095 - val_loss: 0.6151 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6343 - accuracy: 0.8333 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6324 - accuracy: 0.8333 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.6145 - accuracy: 0.9375 - val_loss: 0.6147 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.6121 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6304 - accuracy: 0.8542 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6283 - accuracy: 0.8542 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6304 - accuracy: 0.8542 - val_loss: 0.5995 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6283 - accuracy: 0.8542 - val_loss: 0.5964 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6117 - accuracy: 0.9524 - val_loss: 0.6354 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6090 - accuracy: 0.9524 - val_loss: 0.6336 - val_accuracy: 0.8182\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6304 - accuracy: 0.8542 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6283 - accuracy: 0.8542 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.5995 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6159 - accuracy: 0.9167 - val_loss: 0.5964 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6066 - accuracy: 0.9792 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6037 - accuracy: 0.9792 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6066 - accuracy: 0.9792 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6037 - accuracy: 0.9792 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6383 - accuracy: 0.8125 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6365 - accuracy: 0.8125 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.6298 - accuracy: 0.8571 - val_loss: 0.6354 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6277 - accuracy: 0.8571 - val_loss: 0.6336 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6225 - accuracy: 0.8958 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6201 - accuracy: 0.8958 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6146 - accuracy: 0.9375 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6119 - accuracy: 0.9375 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.6450 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.6435 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6264 - accuracy: 0.8750 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6242 - accuracy: 0.8750 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6263 - accuracy: 0.8750 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6241 - accuracy: 0.8750 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6225 - accuracy: 0.8958 - val_loss: 0.6148 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6201 - accuracy: 0.8958 - val_loss: 0.6122 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 678ms/step - loss: 0.6106 - accuracy: 0.9583 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6078 - accuracy: 0.9583 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6299 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6160 - accuracy: 0.9167 - val_loss: 0.6279 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6117 - accuracy: 0.9524 - val_loss: 0.5996 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6090 - accuracy: 0.9524 - val_loss: 0.5966 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=6\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6178 - accuracy: 0.8958 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6177 - accuracy: 0.8958 - val_loss: 0.6257 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6237 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6050 - accuracy: 0.9583 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6023 - accuracy: 0.9583 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6347 - accuracy: 0.8125 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6329 - accuracy: 0.8125 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6008 - accuracy: 0.9792 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5979 - accuracy: 0.9792 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6219 - accuracy: 0.8750 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6197 - accuracy: 0.8750 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.6208 - accuracy: 0.8810 - val_loss: 0.6318 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6185 - accuracy: 0.8810 - val_loss: 0.6300 - val_accuracy: 0.8182\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6517 - accuracy: 0.7292 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6505 - accuracy: 0.7292 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6178 - accuracy: 0.8958 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6050 - accuracy: 0.9583 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6023 - accuracy: 0.9583 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6177 - accuracy: 0.8958 - val_loss: 0.6094 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6068 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6262 - accuracy: 0.8542 - val_loss: 0.6096 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6242 - accuracy: 0.8542 - val_loss: 0.6070 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6062 - accuracy: 0.9524 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6035 - accuracy: 0.9524 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6050 - accuracy: 0.9583 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6023 - accuracy: 0.9583 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6177 - accuracy: 0.8958 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6092 - accuracy: 0.9375 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.6262 - accuracy: 0.8542 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6242 - accuracy: 0.8542 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6092 - accuracy: 0.9375 - val_loss: 0.5934 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.5904 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6050 - accuracy: 0.9583 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6023 - accuracy: 0.9583 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6159 - accuracy: 0.9048 - val_loss: 0.6126 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6135 - accuracy: 0.9048 - val_loss: 0.6102 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6096 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6096 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6177 - accuracy: 0.8958 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6096 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6070 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6007 - accuracy: 0.9792 - val_loss: 0.6256 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5978 - accuracy: 0.9792 - val_loss: 0.6235 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6432 - accuracy: 0.7708 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6417 - accuracy: 0.7708 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6159 - accuracy: 0.9048 - val_loss: 0.6509 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6135 - accuracy: 0.9048 - val_loss: 0.6497 - val_accuracy: 0.7273\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6008 - accuracy: 0.9792 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5979 - accuracy: 0.9792 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6262 - accuracy: 0.8542 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6242 - accuracy: 0.8542 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6420 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6405 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6262 - accuracy: 0.8542 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6242 - accuracy: 0.8542 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6305 - accuracy: 0.8333 - val_loss: 0.6258 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6286 - accuracy: 0.8333 - val_loss: 0.6238 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6050 - accuracy: 0.9583 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6023 - accuracy: 0.9583 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6256 - accuracy: 0.8571 - val_loss: 0.6509 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6235 - accuracy: 0.8571 - val_loss: 0.6497 - val_accuracy: 0.7273\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6092 - accuracy: 0.9375 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6262 - accuracy: 0.8542 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6242 - accuracy: 0.8542 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6092 - accuracy: 0.9375 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6178 - accuracy: 0.8958 - val_loss: 0.6582 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6573 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6219 - accuracy: 0.8750 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.6420 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.6406 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.5934 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.5903 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6159 - accuracy: 0.9048 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6135 - accuracy: 0.9048 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6008 - accuracy: 0.9792 - val_loss: 0.6258 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5979 - accuracy: 0.9792 - val_loss: 0.6238 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.6420 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.6406 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6092 - accuracy: 0.9375 - val_loss: 0.6096 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6347 - accuracy: 0.8125 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6329 - accuracy: 0.8125 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6135 - accuracy: 0.9167 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6110 - accuracy: 0.9167 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6256 - accuracy: 0.8571 - val_loss: 0.6318 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6235 - accuracy: 0.8571 - val_loss: 0.6300 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6066 - accuracy: 0.9375 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6305 - accuracy: 0.8333 - val_loss: 0.6096 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6286 - accuracy: 0.8333 - val_loss: 0.6071 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6259 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6239 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6220 - accuracy: 0.8750 - val_loss: 0.6255 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6198 - accuracy: 0.8750 - val_loss: 0.6235 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6093 - accuracy: 0.9375 - val_loss: 0.6420 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6067 - accuracy: 0.9375 - val_loss: 0.6405 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6050 - accuracy: 0.9583 - val_loss: 0.5935 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6023 - accuracy: 0.9583 - val_loss: 0.5905 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.6178 - accuracy: 0.8958 - val_loss: 0.6097 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6154 - accuracy: 0.8958 - val_loss: 0.6072 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5966 - accuracy: 1.0000 - val_loss: 0.6318 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5935 - accuracy: 1.0000 - val_loss: 0.6300 - val_accuracy: 0.8182\n",
            "Publisher: global iteration=7\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6131 - accuracy: 0.8958 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6107 - accuracy: 0.8958 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.6130 - accuracy: 0.8958 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6107 - accuracy: 0.8958 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5950 - accuracy: 0.9792 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5921 - accuracy: 0.9792 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6041 - accuracy: 0.9375 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6357 - accuracy: 0.7917 - val_loss: 0.6046 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6341 - accuracy: 0.7917 - val_loss: 0.6021 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5950 - accuracy: 0.9792 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5921 - accuracy: 0.9792 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6086 - accuracy: 0.9167 - val_loss: 0.6046 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.6021 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6130 - accuracy: 0.8958 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6107 - accuracy: 0.8958 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6215 - accuracy: 0.8571 - val_loss: 0.6077 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6194 - accuracy: 0.8571 - val_loss: 0.6053 - val_accuracy: 0.9091\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.6447 - accuracy: 0.7500 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6434 - accuracy: 0.7500 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6131 - accuracy: 0.8958 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6108 - accuracy: 0.8958 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6086 - accuracy: 0.9167 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5967 - accuracy: 0.9583 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6085 - accuracy: 0.9167 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6060 - accuracy: 0.9167 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.6217 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5968 - accuracy: 0.9583 - val_loss: 0.6197 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6217 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6197 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5956 - accuracy: 0.9762 - val_loss: 0.6078 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5928 - accuracy: 0.9762 - val_loss: 0.6053 - val_accuracy: 0.9091\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6085 - accuracy: 0.9167 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6086 - accuracy: 0.9167 - val_loss: 0.6391 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.6377 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6040 - accuracy: 0.9375 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6221 - accuracy: 0.8542 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6201 - accuracy: 0.8542 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.6045 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5967 - accuracy: 0.9583 - val_loss: 0.6020 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5968 - accuracy: 0.9583 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.6218 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5968 - accuracy: 0.9583 - val_loss: 0.6198 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6112 - accuracy: 0.9048 - val_loss: 0.6078 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6088 - accuracy: 0.9048 - val_loss: 0.6054 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.6218 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5967 - accuracy: 0.9583 - val_loss: 0.6198 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6046 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6021 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6041 - accuracy: 0.9375 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6040 - accuracy: 0.9375 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6045 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6019 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5994 - accuracy: 0.9583 - val_loss: 0.6045 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5966 - accuracy: 0.9583 - val_loss: 0.6019 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 0.6402 - accuracy: 0.7708 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6388 - accuracy: 0.7708 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6130 - accuracy: 0.8958 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6107 - accuracy: 0.8958 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6215 - accuracy: 0.8571 - val_loss: 0.6078 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6194 - accuracy: 0.8571 - val_loss: 0.6054 - val_accuracy: 0.9091\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5968 - accuracy: 0.9583 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5950 - accuracy: 0.9792 - val_loss: 0.6046 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5921 - accuracy: 0.9792 - val_loss: 0.6021 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6046 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6021 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6390 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6376 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6312 - accuracy: 0.8125 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6294 - accuracy: 0.8125 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.6131 - accuracy: 0.8958 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6107 - accuracy: 0.8958 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6221 - accuracy: 0.8542 - val_loss: 0.6391 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6201 - accuracy: 0.8542 - val_loss: 0.6377 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6041 - accuracy: 0.9375 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6318 - accuracy: 0.8095 - val_loss: 0.6078 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6300 - accuracy: 0.8095 - val_loss: 0.6054 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6085 - accuracy: 0.9167 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.5843 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6041 - accuracy: 0.9375 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6267 - accuracy: 0.8333 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6247 - accuracy: 0.8333 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6040 - accuracy: 0.9375 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6131 - accuracy: 0.8958 - val_loss: 0.6563 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6108 - accuracy: 0.8958 - val_loss: 0.6554 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6085 - accuracy: 0.9167 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6060 - accuracy: 0.9167 - val_loss: 0.5843 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.6060 - accuracy: 0.9286 - val_loss: 0.6078 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6034 - accuracy: 0.9286 - val_loss: 0.6054 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6040 - accuracy: 0.9375 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6085 - accuracy: 0.9167 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6060 - accuracy: 0.9167 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6085 - accuracy: 0.9167 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6060 - accuracy: 0.9167 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6041 - accuracy: 0.9375 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6176 - accuracy: 0.8750 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6154 - accuracy: 0.8750 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6267 - accuracy: 0.8333 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6248 - accuracy: 0.8333 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6130 - accuracy: 0.8958 - val_loss: 0.6046 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6107 - accuracy: 0.8958 - val_loss: 0.6021 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6214 - accuracy: 0.8571 - val_loss: 0.6282 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6194 - accuracy: 0.8571 - val_loss: 0.6264 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6041 - accuracy: 0.9375 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.6040 - accuracy: 0.9375 - val_loss: 0.6047 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6014 - accuracy: 0.9375 - val_loss: 0.6022 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6221 - accuracy: 0.8542 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6201 - accuracy: 0.8542 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.6131 - accuracy: 0.8958 - val_loss: 0.6391 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6108 - accuracy: 0.8958 - val_loss: 0.6376 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6265 - accuracy: 0.8333 - val_loss: 0.5874 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6246 - accuracy: 0.8333 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6086 - accuracy: 0.9167 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5995 - accuracy: 0.9583 - val_loss: 0.5875 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5968 - accuracy: 0.9583 - val_loss: 0.5844 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.6086 - accuracy: 0.9167 - val_loss: 0.6219 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6061 - accuracy: 0.9167 - val_loss: 0.6199 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5957 - accuracy: 0.9762 - val_loss: 0.6078 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5928 - accuracy: 0.9762 - val_loss: 0.6054 - val_accuracy: 0.9091\n",
            "Publisher: global iteration=8\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.5967 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6132 - accuracy: 0.8750 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.5968 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5892 - accuracy: 0.9792 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5863 - accuracy: 0.9792 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.6276 - accuracy: 0.8125 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6258 - accuracy: 0.8125 - val_loss: 0.6159 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.5940 - accuracy: 0.9583 - val_loss: 0.5813 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5912 - accuracy: 0.9583 - val_loss: 0.5782 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6036 - accuracy: 0.9167 - val_loss: 0.5996 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6011 - accuracy: 0.9167 - val_loss: 0.5970 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6131 - accuracy: 0.8750 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6173 - accuracy: 0.8571 - val_loss: 0.6030 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6153 - accuracy: 0.8571 - val_loss: 0.6004 - val_accuracy: 0.9091\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6421 - accuracy: 0.7500 - val_loss: 0.6177 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6407 - accuracy: 0.7500 - val_loss: 0.6156 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6085 - accuracy: 0.8958 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.5996 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.5970 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6037 - accuracy: 0.9167 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6012 - accuracy: 0.9167 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5892 - accuracy: 0.9792 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5862 - accuracy: 0.9792 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6131 - accuracy: 0.8750 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6109 - accuracy: 0.8750 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5961 - accuracy: 0.9375 - val_loss: 0.5968 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.6180 - accuracy: 0.8542 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6159 - accuracy: 0.8542 - val_loss: 0.5971 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5954 - accuracy: 0.9524 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5926 - accuracy: 0.9524 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5994 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5967 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6036 - accuracy: 0.9167 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6011 - accuracy: 0.9167 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6133 - accuracy: 0.8750 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6111 - accuracy: 0.8750 - val_loss: 0.5971 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5892 - accuracy: 0.9792 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5863 - accuracy: 0.9792 - val_loss: 0.6157 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5813 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5961 - accuracy: 0.9375 - val_loss: 0.5781 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5940 - accuracy: 0.9583 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5913 - accuracy: 0.9583 - val_loss: 0.5782 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5940 - accuracy: 0.9583 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5912 - accuracy: 0.9583 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6119 - accuracy: 0.8810 - val_loss: 0.5813 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6097 - accuracy: 0.8810 - val_loss: 0.5782 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5987 - accuracy: 0.9375 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5961 - accuracy: 0.9375 - val_loss: 0.5971 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6132 - accuracy: 0.8750 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.5967 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6036 - accuracy: 0.9167 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6011 - accuracy: 0.9167 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6180 - accuracy: 0.8542 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6159 - accuracy: 0.8542 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5987 - accuracy: 0.9375 - val_loss: 0.5808 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5960 - accuracy: 0.9375 - val_loss: 0.5776 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6325 - accuracy: 0.7917 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6309 - accuracy: 0.7917 - val_loss: 0.6347 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6060 - accuracy: 0.8958 - val_loss: 0.5971 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6174 - accuracy: 0.8571 - val_loss: 0.6029 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6153 - accuracy: 0.8571 - val_loss: 0.6004 - val_accuracy: 0.9091\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5892 - accuracy: 0.9792 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5863 - accuracy: 0.9792 - val_loss: 0.5969 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6180 - accuracy: 0.8542 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6160 - accuracy: 0.8542 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6228 - accuracy: 0.8333 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6208 - accuracy: 0.8333 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6229 - accuracy: 0.8333 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6210 - accuracy: 0.8333 - val_loss: 0.5971 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6132 - accuracy: 0.8750 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.6726 - val_accuracy: 0.6154\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.6722 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6228 - accuracy: 0.8333 - val_loss: 0.6246 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6208 - accuracy: 0.8333 - val_loss: 0.6228 - val_accuracy: 0.8182\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5961 - accuracy: 0.9375 - val_loss: 0.5969 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.6159 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6132 - accuracy: 0.8750 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6035 - accuracy: 0.9167 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6011 - accuracy: 0.9167 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6229 - accuracy: 0.8333 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6210 - accuracy: 0.8333 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.6158 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6133 - accuracy: 0.8750 - val_loss: 0.5996 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6111 - accuracy: 0.8750 - val_loss: 0.5971 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5961 - accuracy: 0.9375 - val_loss: 0.5969 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5898 - accuracy: 0.9762 - val_loss: 0.6462 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5869 - accuracy: 0.9762 - val_loss: 0.6450 - val_accuracy: 0.7273\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6085 - accuracy: 0.8958 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5940 - accuracy: 0.9583 - val_loss: 0.6175 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5912 - accuracy: 0.9583 - val_loss: 0.6154 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6036 - accuracy: 0.9167 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6011 - accuracy: 0.9167 - val_loss: 0.5783 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5940 - accuracy: 0.9583 - val_loss: 0.5996 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5913 - accuracy: 0.9583 - val_loss: 0.5970 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6181 - accuracy: 0.8542 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6160 - accuracy: 0.8542 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.6229 - accuracy: 0.8333 - val_loss: 0.5997 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6210 - accuracy: 0.8333 - val_loss: 0.5972 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6132 - accuracy: 0.8750 - val_loss: 0.5812 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.5782 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6118 - accuracy: 0.8810 - val_loss: 0.6462 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6096 - accuracy: 0.8810 - val_loss: 0.6450 - val_accuracy: 0.7273\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.6179 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.6160 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.5969 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6132 - accuracy: 0.8750 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6110 - accuracy: 0.8750 - val_loss: 0.6348 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.6348 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.6359 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6060 - accuracy: 0.8958 - val_loss: 0.6343 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6084 - accuracy: 0.8958 - val_loss: 0.5995 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6061 - accuracy: 0.8958 - val_loss: 0.5969 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5940 - accuracy: 0.9583 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5913 - accuracy: 0.9583 - val_loss: 0.5784 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5988 - accuracy: 0.9375 - val_loss: 0.6362 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5962 - accuracy: 0.9375 - val_loss: 0.6346 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5954 - accuracy: 0.9524 - val_loss: 0.5814 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5927 - accuracy: 0.9524 - val_loss: 0.5781 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=9\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6088 - accuracy: 0.8750 - val_loss: 0.5686 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6021 - accuracy: 0.8750 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6087 - accuracy: 0.8750 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6022 - accuracy: 0.8750 - val_loss: 0.5861 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5935 - accuracy: 0.9375 - val_loss: 0.5687 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5853 - accuracy: 0.9375 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5936 - accuracy: 0.9375 - val_loss: 0.5685 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5852 - accuracy: 0.9375 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6138 - accuracy: 0.8542 - val_loss: 0.6507 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6078 - accuracy: 0.8542 - val_loss: 0.6497 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5884 - accuracy: 0.9583 - val_loss: 0.5684 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5800 - accuracy: 0.9583 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.5689 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6036 - accuracy: 0.8958 - val_loss: 0.6096 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5966 - accuracy: 0.8958 - val_loss: 0.6073 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6189 - accuracy: 0.8333 - val_loss: 0.5685 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6134 - accuracy: 0.8333 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.6291 - accuracy: 0.7917 - val_loss: 0.6509 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6243 - accuracy: 0.7917 - val_loss: 0.6497 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5987 - accuracy: 0.9167 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5909 - accuracy: 0.9167 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6038 - accuracy: 0.8958 - val_loss: 0.5892 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5964 - accuracy: 0.8958 - val_loss: 0.5863 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5936 - accuracy: 0.9375 - val_loss: 0.6097 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5854 - accuracy: 0.9375 - val_loss: 0.6075 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5783 - accuracy: 1.0000 - val_loss: 0.6102 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5686 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6036 - accuracy: 0.8958 - val_loss: 0.5892 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5966 - accuracy: 0.8958 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5985 - accuracy: 0.9167 - val_loss: 0.5687 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5911 - accuracy: 0.9167 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.6139 - accuracy: 0.8542 - val_loss: 0.5892 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6075 - accuracy: 0.8542 - val_loss: 0.5863 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5898 - accuracy: 0.9524 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5814 - accuracy: 0.9524 - val_loss: 0.5651 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5935 - accuracy: 0.9375 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5854 - accuracy: 0.9375 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.5891 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.6089 - accuracy: 0.8750 - val_loss: 0.5897 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6021 - accuracy: 0.8750 - val_loss: 0.5867 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5884 - accuracy: 0.9583 - val_loss: 0.5893 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5798 - accuracy: 0.9583 - val_loss: 0.5863 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.6095 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.6073 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5884 - accuracy: 0.9583 - val_loss: 0.5893 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5797 - accuracy: 0.9583 - val_loss: 0.5864 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5885 - accuracy: 0.9583 - val_loss: 0.5687 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5797 - accuracy: 0.9583 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5986 - accuracy: 0.9167 - val_loss: 0.5686 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5909 - accuracy: 0.9167 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6015 - accuracy: 0.9048 - val_loss: 0.5927 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5941 - accuracy: 0.9048 - val_loss: 0.5900 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5985 - accuracy: 0.9167 - val_loss: 0.5684 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5911 - accuracy: 0.9167 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6086 - accuracy: 0.8750 - val_loss: 0.5892 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6023 - accuracy: 0.8750 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5936 - accuracy: 0.9375 - val_loss: 0.5895 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5854 - accuracy: 0.9375 - val_loss: 0.5864 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5987 - accuracy: 0.9167 - val_loss: 0.5895 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5908 - accuracy: 0.9167 - val_loss: 0.5865 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.6139 - accuracy: 0.8542 - val_loss: 0.5689 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6077 - accuracy: 0.8542 - val_loss: 0.5654 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 0.5934 - accuracy: 0.9375 - val_loss: 0.5695 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5856 - accuracy: 0.9375 - val_loss: 0.5656 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6292 - accuracy: 0.7917 - val_loss: 0.6301 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6244 - accuracy: 0.7917 - val_loss: 0.6285 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5986 - accuracy: 0.9167 - val_loss: 0.6097 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5908 - accuracy: 0.9167 - val_loss: 0.6073 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6131 - accuracy: 0.8571 - val_loss: 0.5927 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6072 - accuracy: 0.8571 - val_loss: 0.5900 - val_accuracy: 0.9091\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5935 - accuracy: 0.9375 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5854 - accuracy: 0.9375 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5833 - accuracy: 0.9792 - val_loss: 0.5894 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5742 - accuracy: 0.9792 - val_loss: 0.5864 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.6098 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.6075 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.6509 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5966 - accuracy: 0.8958 - val_loss: 0.6498 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.6507 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.6497 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5935 - accuracy: 0.9375 - val_loss: 0.6302 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5852 - accuracy: 0.9375 - val_loss: 0.6285 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6190 - accuracy: 0.8333 - val_loss: 0.6097 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6132 - accuracy: 0.8333 - val_loss: 0.6074 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5885 - accuracy: 0.9583 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5798 - accuracy: 0.9583 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6130 - accuracy: 0.8571 - val_loss: 0.6414 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6070 - accuracy: 0.8571 - val_loss: 0.6400 - val_accuracy: 0.7273\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5985 - accuracy: 0.9167 - val_loss: 0.5687 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5910 - accuracy: 0.9167 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.6038 - accuracy: 0.8958 - val_loss: 0.5685 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5986 - accuracy: 0.9167 - val_loss: 0.6507 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5909 - accuracy: 0.9167 - val_loss: 0.6497 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5884 - accuracy: 0.9583 - val_loss: 0.6095 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5797 - accuracy: 0.9583 - val_loss: 0.6073 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.6191 - accuracy: 0.8333 - val_loss: 0.5894 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6132 - accuracy: 0.8333 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.6097 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5964 - accuracy: 0.8958 - val_loss: 0.6074 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.6096 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5965 - accuracy: 0.8958 - val_loss: 0.6073 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5934 - accuracy: 0.9375 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5855 - accuracy: 0.9375 - val_loss: 0.5861 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5956 - accuracy: 0.9286 - val_loss: 0.5927 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5879 - accuracy: 0.9286 - val_loss: 0.5900 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5936 - accuracy: 0.9375 - val_loss: 0.5687 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5853 - accuracy: 0.9375 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.6089 - accuracy: 0.8750 - val_loss: 0.5891 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6020 - accuracy: 0.8750 - val_loss: 0.5863 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5936 - accuracy: 0.9375 - val_loss: 0.5898 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5853 - accuracy: 0.9375 - val_loss: 0.5868 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5934 - accuracy: 0.9375 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5855 - accuracy: 0.9375 - val_loss: 0.5861 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5884 - accuracy: 0.9583 - val_loss: 0.5892 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5797 - accuracy: 0.9583 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6140 - accuracy: 0.8542 - val_loss: 0.5685 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6075 - accuracy: 0.8542 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.6190 - accuracy: 0.8333 - val_loss: 0.5889 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6131 - accuracy: 0.8333 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.5891 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5964 - accuracy: 0.8958 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.6131 - accuracy: 0.8571 - val_loss: 0.6170 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6068 - accuracy: 0.8571 - val_loss: 0.6151 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5987 - accuracy: 0.9167 - val_loss: 0.5893 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5910 - accuracy: 0.9167 - val_loss: 0.5864 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5936 - accuracy: 0.9375 - val_loss: 0.5893 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5853 - accuracy: 0.9375 - val_loss: 0.5863 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6139 - accuracy: 0.8542 - val_loss: 0.6096 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6076 - accuracy: 0.8542 - val_loss: 0.6073 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.6139 - accuracy: 0.8542 - val_loss: 0.5891 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6077 - accuracy: 0.8542 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6137 - accuracy: 0.8542 - val_loss: 0.5895 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6077 - accuracy: 0.8542 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.6037 - accuracy: 0.8958 - val_loss: 0.5890 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5966 - accuracy: 0.8958 - val_loss: 0.5862 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5885 - accuracy: 0.9583 - val_loss: 0.5684 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5797 - accuracy: 0.9583 - val_loss: 0.5650 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5884 - accuracy: 0.9583 - val_loss: 0.6507 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5798 - accuracy: 0.9583 - val_loss: 0.6497 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5899 - accuracy: 0.9524 - val_loss: 0.5688 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5815 - accuracy: 0.9524 - val_loss: 0.5652 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=10\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5937 - accuracy: 0.8958 - val_loss: 0.5834 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5910 - accuracy: 0.8958 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5938 - accuracy: 0.8958 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5911 - accuracy: 0.8958 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5708 - accuracy: 0.9792 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5674 - accuracy: 0.9792 - val_loss: 0.6028 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5822 - accuracy: 0.9375 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5792 - accuracy: 0.9375 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.6167 - accuracy: 0.8125 - val_loss: 0.6053 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6146 - accuracy: 0.8125 - val_loss: 0.6031 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5765 - accuracy: 0.9583 - val_loss: 0.5616 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5734 - accuracy: 0.9583 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5938 - accuracy: 0.8958 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5911 - accuracy: 0.8958 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5938 - accuracy: 0.8958 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5912 - accuracy: 0.8958 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5913 - accuracy: 0.9048 - val_loss: 0.6390 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5885 - accuracy: 0.9048 - val_loss: 0.6376 - val_accuracy: 0.7273\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.6282 - accuracy: 0.7708 - val_loss: 0.6269 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6265 - accuracy: 0.7708 - val_loss: 0.6253 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5880 - accuracy: 0.9167 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5851 - accuracy: 0.9167 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.6269 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5792 - accuracy: 0.9375 - val_loss: 0.6253 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5937 - accuracy: 0.8958 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5910 - accuracy: 0.8958 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5709 - accuracy: 0.9792 - val_loss: 0.5834 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5675 - accuracy: 0.9792 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5996 - accuracy: 0.8750 - val_loss: 0.5618 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.5583 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.5835 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5793 - accuracy: 0.9375 - val_loss: 0.5806 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.6052 - accuracy: 0.8542 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6029 - accuracy: 0.8542 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5782 - accuracy: 0.9524 - val_loss: 0.5616 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5750 - accuracy: 0.9524 - val_loss: 0.5581 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5881 - accuracy: 0.9167 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5852 - accuracy: 0.9167 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5938 - accuracy: 0.8958 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5911 - accuracy: 0.8958 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5996 - accuracy: 0.8750 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5971 - accuracy: 0.8750 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5767 - accuracy: 0.9583 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5734 - accuracy: 0.9583 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5995 - accuracy: 0.8750 - val_loss: 0.5834 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5709 - accuracy: 0.9792 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5675 - accuracy: 0.9792 - val_loss: 0.6028 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5708 - accuracy: 0.9792 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5674 - accuracy: 0.9792 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5822 - accuracy: 0.9375 - val_loss: 0.5834 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5792 - accuracy: 0.9375 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5913 - accuracy: 0.9048 - val_loss: 0.5873 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5885 - accuracy: 0.9048 - val_loss: 0.5845 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5824 - accuracy: 0.9375 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5793 - accuracy: 0.9375 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5996 - accuracy: 0.8750 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5822 - accuracy: 0.9375 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5792 - accuracy: 0.9375 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5938 - accuracy: 0.8958 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5911 - accuracy: 0.8958 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.6489 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5793 - accuracy: 0.9375 - val_loss: 0.6479 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5769 - accuracy: 0.9583 - val_loss: 0.5834 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5736 - accuracy: 0.9583 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6281 - accuracy: 0.7708 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6264 - accuracy: 0.7708 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.5995 - accuracy: 0.8750 - val_loss: 0.5617 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.5583 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.6111 - accuracy: 0.8333 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6089 - accuracy: 0.8333 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5792 - accuracy: 0.9375 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5709 - accuracy: 0.9792 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5675 - accuracy: 0.9792 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5995 - accuracy: 0.8750 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5939 - accuracy: 0.8958 - val_loss: 0.6487 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5911 - accuracy: 0.8958 - val_loss: 0.6477 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.6109 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6087 - accuracy: 0.8333 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5938 - accuracy: 0.8958 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5911 - accuracy: 0.8958 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.6166 - accuracy: 0.8125 - val_loss: 0.5835 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6146 - accuracy: 0.8125 - val_loss: 0.5806 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5708 - accuracy: 0.9792 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5674 - accuracy: 0.9792 - val_loss: 0.6028 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.6176 - accuracy: 0.8095 - val_loss: 0.5873 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6156 - accuracy: 0.8095 - val_loss: 0.5845 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5881 - accuracy: 0.9167 - val_loss: 0.5616 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5852 - accuracy: 0.9167 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5937 - accuracy: 0.8958 - val_loss: 0.5616 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5910 - accuracy: 0.8958 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5995 - accuracy: 0.8750 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.5836 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5793 - accuracy: 0.9375 - val_loss: 0.5807 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5994 - accuracy: 0.8750 - val_loss: 0.6269 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5969 - accuracy: 0.8750 - val_loss: 0.6253 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5995 - accuracy: 0.8750 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6052 - accuracy: 0.8542 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6028 - accuracy: 0.8542 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.5824 - accuracy: 0.9375 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5794 - accuracy: 0.9375 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5914 - accuracy: 0.9048 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5886 - accuracy: 0.9048 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5793 - accuracy: 0.9375 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5937 - accuracy: 0.8958 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5910 - accuracy: 0.8958 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5882 - accuracy: 0.9167 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5853 - accuracy: 0.9167 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5823 - accuracy: 0.9375 - val_loss: 0.5834 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5793 - accuracy: 0.9375 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5765 - accuracy: 0.9583 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5733 - accuracy: 0.9583 - val_loss: 0.5805 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6052 - accuracy: 0.8542 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6028 - accuracy: 0.8542 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6109 - accuracy: 0.8333 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6087 - accuracy: 0.8333 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5881 - accuracy: 0.9167 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5852 - accuracy: 0.9167 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6043 - accuracy: 0.8571 - val_loss: 0.6134 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6020 - accuracy: 0.8571 - val_loss: 0.6114 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5765 - accuracy: 0.9583 - val_loss: 0.6269 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5733 - accuracy: 0.9583 - val_loss: 0.6253 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5880 - accuracy: 0.9167 - val_loss: 0.5616 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5851 - accuracy: 0.9167 - val_loss: 0.5581 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.5994 - accuracy: 0.8750 - val_loss: 0.6272 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5969 - accuracy: 0.8750 - val_loss: 0.6255 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5994 - accuracy: 0.8750 - val_loss: 0.6052 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5969 - accuracy: 0.8750 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5996 - accuracy: 0.8750 - val_loss: 0.6054 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5970 - accuracy: 0.8750 - val_loss: 0.6031 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5880 - accuracy: 0.9167 - val_loss: 0.6051 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5851 - accuracy: 0.9167 - val_loss: 0.6029 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5765 - accuracy: 0.9583 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5733 - accuracy: 0.9583 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5937 - accuracy: 0.8958 - val_loss: 0.5833 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5910 - accuracy: 0.8958 - val_loss: 0.5804 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5782 - accuracy: 0.9524 - val_loss: 0.5615 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5750 - accuracy: 0.9524 - val_loss: 0.5580 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=11\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5823 - accuracy: 0.9167 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5795 - accuracy: 0.9167 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5945 - accuracy: 0.8750 - val_loss: 0.5778 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5750 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5733 - accuracy: 0.9375 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5702 - accuracy: 0.9583 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5670 - accuracy: 0.9583 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.6066 - accuracy: 0.8333 - val_loss: 0.6238 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6045 - accuracy: 0.8333 - val_loss: 0.6222 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5641 - accuracy: 0.9792 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5608 - accuracy: 0.9792 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5858 - accuracy: 0.8958 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6005 - accuracy: 0.8542 - val_loss: 0.5551 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5982 - accuracy: 0.8542 - val_loss: 0.5517 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5928 - accuracy: 0.8810 - val_loss: 0.6090 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5902 - accuracy: 0.8810 - val_loss: 0.6070 - val_accuracy: 0.8182\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6248 - accuracy: 0.7708 - val_loss: 0.6237 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6232 - accuracy: 0.7708 - val_loss: 0.6221 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5762 - accuracy: 0.9375 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5732 - accuracy: 0.9375 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5945 - accuracy: 0.8750 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5857 - accuracy: 0.8958 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5703 - accuracy: 0.9583 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5671 - accuracy: 0.9583 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5885 - accuracy: 0.8958 - val_loss: 0.5779 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5858 - accuracy: 0.8958 - val_loss: 0.5750 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5823 - accuracy: 0.9167 - val_loss: 0.5547 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5795 - accuracy: 0.9167 - val_loss: 0.5512 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5823 - accuracy: 0.9167 - val_loss: 0.6469 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5795 - accuracy: 0.9167 - val_loss: 0.6460 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5650 - accuracy: 0.9762 - val_loss: 0.5818 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5617 - accuracy: 0.9762 - val_loss: 0.5790 - val_accuracy: 0.9091\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5824 - accuracy: 0.9167 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5795 - accuracy: 0.9167 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5824 - accuracy: 0.9167 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5796 - accuracy: 0.9167 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5703 - accuracy: 0.9583 - val_loss: 0.6698 - val_accuracy: 0.6154\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5672 - accuracy: 0.9583 - val_loss: 0.6694 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5734 - accuracy: 0.9375 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5858 - accuracy: 0.8958 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.5547 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5733 - accuracy: 0.9375 - val_loss: 0.5512 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5702 - accuracy: 0.9583 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5670 - accuracy: 0.9583 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.5702 - accuracy: 0.9583 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5670 - accuracy: 0.9583 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5788 - accuracy: 0.9286 - val_loss: 0.6090 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5759 - accuracy: 0.9286 - val_loss: 0.6070 - val_accuracy: 0.8182\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5824 - accuracy: 0.9167 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5796 - accuracy: 0.9167 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5945 - accuracy: 0.8750 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5823 - accuracy: 0.9167 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5795 - accuracy: 0.9167 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5733 - accuracy: 0.9375 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.6006 - accuracy: 0.8542 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5983 - accuracy: 0.8542 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5704 - accuracy: 0.9583 - val_loss: 0.5778 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5672 - accuracy: 0.9583 - val_loss: 0.5749 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6187 - accuracy: 0.7917 - val_loss: 0.6237 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6169 - accuracy: 0.7917 - val_loss: 0.6221 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.5778 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5858 - accuracy: 0.8958 - val_loss: 0.5749 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5998 - accuracy: 0.8571 - val_loss: 0.5818 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5975 - accuracy: 0.8571 - val_loss: 0.5790 - val_accuracy: 0.9091\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5702 - accuracy: 0.9583 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5670 - accuracy: 0.9583 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5641 - accuracy: 0.9792 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5608 - accuracy: 0.9792 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5945 - accuracy: 0.8750 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.6006 - accuracy: 0.8542 - val_loss: 0.6007 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5982 - accuracy: 0.8542 - val_loss: 0.5985 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.6005 - accuracy: 0.8542 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5982 - accuracy: 0.8542 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5824 - accuracy: 0.9167 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5796 - accuracy: 0.9167 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6187 - accuracy: 0.7917 - val_loss: 0.5547 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6169 - accuracy: 0.7917 - val_loss: 0.5512 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5762 - accuracy: 0.9375 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5732 - accuracy: 0.9375 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5858 - accuracy: 0.9048 - val_loss: 0.6907 - val_accuracy: 0.5455\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5831 - accuracy: 0.9048 - val_loss: 0.6910 - val_accuracy: 0.5455\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5824 - accuracy: 0.9167 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5796 - accuracy: 0.9167 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5823 - accuracy: 0.9167 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5795 - accuracy: 0.9167 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5945 - accuracy: 0.8750 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.5779 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5733 - accuracy: 0.9375 - val_loss: 0.5750 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.6127 - accuracy: 0.8125 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6107 - accuracy: 0.8125 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6006 - accuracy: 0.8542 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5983 - accuracy: 0.8542 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5857 - accuracy: 0.8958 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5733 - accuracy: 0.9375 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5789 - accuracy: 0.9286 - val_loss: 0.5818 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5760 - accuracy: 0.9286 - val_loss: 0.5790 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5702 - accuracy: 0.9583 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5670 - accuracy: 0.9583 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5857 - accuracy: 0.8958 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5764 - accuracy: 0.9375 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5734 - accuracy: 0.9375 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5824 - accuracy: 0.9167 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5796 - accuracy: 0.9167 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5580 - accuracy: 1.0000 - val_loss: 0.6237 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5545 - accuracy: 1.0000 - val_loss: 0.6221 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5944 - accuracy: 0.8750 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6066 - accuracy: 0.8333 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6045 - accuracy: 0.8333 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5946 - accuracy: 0.8750 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5921 - accuracy: 0.8750 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.6067 - accuracy: 0.8333 - val_loss: 0.5818 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6045 - accuracy: 0.8333 - val_loss: 0.5790 - val_accuracy: 0.9091\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5857 - accuracy: 0.8958 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5763 - accuracy: 0.9375 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5733 - accuracy: 0.9375 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.6006 - accuracy: 0.8542 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5983 - accuracy: 0.8542 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5884 - accuracy: 0.8958 - val_loss: 0.6237 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5857 - accuracy: 0.8958 - val_loss: 0.6221 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5946 - accuracy: 0.8750 - val_loss: 0.6006 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5922 - accuracy: 0.8750 - val_loss: 0.5984 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5944 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5511 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5641 - accuracy: 0.9792 - val_loss: 0.5776 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5608 - accuracy: 0.9792 - val_loss: 0.5747 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5945 - accuracy: 0.8750 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5920 - accuracy: 0.8750 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5719 - accuracy: 0.9524 - val_loss: 0.5545 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5688 - accuracy: 0.9524 - val_loss: 0.5510 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=12\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5896 - accuracy: 0.8750 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5871 - accuracy: 0.8750 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5574 - accuracy: 0.9792 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 0.5703 - accuracy: 0.9375 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5673 - accuracy: 0.9375 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6087 - accuracy: 0.8125 - val_loss: 0.5963 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6068 - accuracy: 0.8125 - val_loss: 0.5940 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5575 - accuracy: 0.9792 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5575 - accuracy: 0.9792 - val_loss: 0.6448 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.6438 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5897 - accuracy: 0.8750 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5872 - accuracy: 0.8750 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5950 - accuracy: 0.8571 - val_loss: 0.5763 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5927 - accuracy: 0.8571 - val_loss: 0.5735 - val_accuracy: 0.9091\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.6087 - accuracy: 0.8125 - val_loss: 0.6691 - val_accuracy: 0.6154\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6068 - accuracy: 0.8125 - val_loss: 0.6688 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5831 - accuracy: 0.8958 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5804 - accuracy: 0.8958 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 0.5831 - accuracy: 0.8958 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5574 - accuracy: 0.9792 - val_loss: 0.5723 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.5694 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5833 - accuracy: 0.8958 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5806 - accuracy: 0.8958 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5832 - accuracy: 0.8958 - val_loss: 0.6205 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.6189 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5657 - accuracy: 0.9524 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5626 - accuracy: 0.9524 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5896 - accuracy: 0.8750 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5871 - accuracy: 0.8750 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 0.5897 - accuracy: 0.8750 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5872 - accuracy: 0.8750 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5576 - accuracy: 0.9792 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5542 - accuracy: 0.9792 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 0.5895 - accuracy: 0.8750 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5870 - accuracy: 0.8750 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5704 - accuracy: 0.9375 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5674 - accuracy: 0.9375 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5574 - accuracy: 0.9792 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.5703 - accuracy: 0.9375 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5673 - accuracy: 0.9375 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5730 - accuracy: 0.9286 - val_loss: 0.6050 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5701 - accuracy: 0.9286 - val_loss: 0.6030 - val_accuracy: 0.8182\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5639 - accuracy: 0.9583 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5607 - accuracy: 0.9583 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5831 - accuracy: 0.8958 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5639 - accuracy: 0.9583 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5607 - accuracy: 0.9583 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5832 - accuracy: 0.8958 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5704 - accuracy: 0.9375 - val_loss: 0.6448 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5674 - accuracy: 0.9375 - val_loss: 0.6438 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5641 - accuracy: 0.9583 - val_loss: 0.5720 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5609 - accuracy: 0.9583 - val_loss: 0.5691 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.6216 - accuracy: 0.7708 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6200 - accuracy: 0.7708 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5768 - accuracy: 0.9167 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.6025 - accuracy: 0.8333 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6003 - accuracy: 0.8333 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5639 - accuracy: 0.9583 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5607 - accuracy: 0.9583 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.6205 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.6189 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5896 - accuracy: 0.8750 - val_loss: 0.6205 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5871 - accuracy: 0.8750 - val_loss: 0.6189 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5895 - accuracy: 0.8750 - val_loss: 0.6205 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5870 - accuracy: 0.8750 - val_loss: 0.6189 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5832 - accuracy: 0.8958 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 0.6152 - accuracy: 0.7917 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6134 - accuracy: 0.7917 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5639 - accuracy: 0.9583 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5607 - accuracy: 0.9583 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6024 - accuracy: 0.8333 - val_loss: 0.6050 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6002 - accuracy: 0.8333 - val_loss: 0.6030 - val_accuracy: 0.8182\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5703 - accuracy: 0.9375 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5673 - accuracy: 0.9375 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5959 - accuracy: 0.8542 - val_loss: 0.5719 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5936 - accuracy: 0.8542 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5704 - accuracy: 0.9375 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5674 - accuracy: 0.9375 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6023 - accuracy: 0.8333 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6002 - accuracy: 0.8333 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5959 - accuracy: 0.8542 - val_loss: 0.5479 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5936 - accuracy: 0.8542 - val_loss: 0.5444 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5895 - accuracy: 0.8750 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5870 - accuracy: 0.8750 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5703 - accuracy: 0.9375 - val_loss: 0.5720 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5673 - accuracy: 0.9375 - val_loss: 0.5692 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5730 - accuracy: 0.9286 - val_loss: 0.5763 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5701 - accuracy: 0.9286 - val_loss: 0.5735 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5703 - accuracy: 0.9375 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5673 - accuracy: 0.9375 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5831 - accuracy: 0.8958 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5804 - accuracy: 0.8958 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5704 - accuracy: 0.9375 - val_loss: 0.5720 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5674 - accuracy: 0.9375 - val_loss: 0.5692 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5639 - accuracy: 0.9583 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5607 - accuracy: 0.9583 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5639 - accuracy: 0.9583 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5607 - accuracy: 0.9583 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5959 - accuracy: 0.8542 - val_loss: 0.5475 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5936 - accuracy: 0.8542 - val_loss: 0.5440 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.6691 - val_accuracy: 0.6154\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.6688 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5767 - accuracy: 0.9167 - val_loss: 0.5966 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5739 - accuracy: 0.9167 - val_loss: 0.5944 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6024 - accuracy: 0.8333 - val_loss: 0.5763 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6003 - accuracy: 0.8333 - val_loss: 0.5735 - val_accuracy: 0.9091\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5703 - accuracy: 0.9375 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5673 - accuracy: 0.9375 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5574 - accuracy: 0.9792 - val_loss: 0.6205 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.6189 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5960 - accuracy: 0.8542 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5937 - accuracy: 0.8542 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5895 - accuracy: 0.8750 - val_loss: 0.5962 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5870 - accuracy: 0.8750 - val_loss: 0.5939 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5961 - accuracy: 0.8542 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5938 - accuracy: 0.8542 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5831 - accuracy: 0.8958 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5574 - accuracy: 0.9792 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5541 - accuracy: 0.9792 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5831 - accuracy: 0.8958 - val_loss: 0.5718 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5805 - accuracy: 0.8958 - val_loss: 0.5690 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5584 - accuracy: 0.9762 - val_loss: 0.5763 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5550 - accuracy: 0.9762 - val_loss: 0.5735 - val_accuracy: 0.9091\n",
            "Publisher: global iteration=13\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5711 - accuracy: 0.9167 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5779 - accuracy: 0.8958 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5575 - accuracy: 0.9583 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5544 - accuracy: 0.9583 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.6049 - accuracy: 0.8125 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6029 - accuracy: 0.8125 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5508 - accuracy: 0.9792 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5474 - accuracy: 0.9792 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5848 - accuracy: 0.8750 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5823 - accuracy: 0.8750 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5904 - accuracy: 0.8571 - val_loss: 0.5708 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5880 - accuracy: 0.8571 - val_loss: 0.5680 - val_accuracy: 0.9091\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.6116 - accuracy: 0.7917 - val_loss: 0.6429 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6098 - accuracy: 0.7917 - val_loss: 0.6420 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5509 - accuracy: 0.9792 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5476 - accuracy: 0.9792 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5780 - accuracy: 0.8958 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5753 - accuracy: 0.8958 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5981 - accuracy: 0.8333 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5960 - accuracy: 0.8333 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5595 - accuracy: 0.9524 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5563 - accuracy: 0.9524 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5644 - accuracy: 0.9375 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5614 - accuracy: 0.9375 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5848 - accuracy: 0.8750 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5823 - accuracy: 0.8750 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5576 - accuracy: 0.9583 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5545 - accuracy: 0.9583 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 734ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5576 - accuracy: 0.9583 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5544 - accuracy: 0.9583 - val_loss: 0.5633 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5575 - accuracy: 0.9583 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5544 - accuracy: 0.9583 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5672 - accuracy: 0.9286 - val_loss: 0.6010 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5643 - accuracy: 0.9286 - val_loss: 0.5990 - val_accuracy: 0.8182\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5711 - accuracy: 0.9167 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5913 - accuracy: 0.8542 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5890 - accuracy: 0.8542 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5711 - accuracy: 0.9167 - val_loss: 0.5663 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5634 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 729ms/step - loss: 0.5847 - accuracy: 0.8750 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5822 - accuracy: 0.8750 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5577 - accuracy: 0.9583 - val_loss: 0.5665 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5545 - accuracy: 0.9583 - val_loss: 0.5636 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.6116 - accuracy: 0.7917 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.6098 - accuracy: 0.7917 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5846 - accuracy: 0.8750 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5822 - accuracy: 0.8750 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5750 - accuracy: 0.9048 - val_loss: 0.6313 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5723 - accuracy: 0.9048 - val_loss: 0.6301 - val_accuracy: 0.7273\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5508 - accuracy: 0.9792 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5474 - accuracy: 0.9792 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5846 - accuracy: 0.8750 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5821 - accuracy: 0.8750 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5846 - accuracy: 0.8750 - val_loss: 0.6174 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5821 - accuracy: 0.8750 - val_loss: 0.6158 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5846 - accuracy: 0.8750 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5821 - accuracy: 0.8750 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 683ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.5919 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5897 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.6049 - accuracy: 0.8125 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6029 - accuracy: 0.8125 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5981 - accuracy: 0.8333 - val_loss: 0.6010 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5960 - accuracy: 0.8333 - val_loss: 0.5990 - val_accuracy: 0.8182\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5644 - accuracy: 0.9375 - val_loss: 0.5662 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5614 - accuracy: 0.9375 - val_loss: 0.5633 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5913 - accuracy: 0.8542 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5890 - accuracy: 0.8542 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5711 - accuracy: 0.9167 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5683 - accuracy: 0.9167 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5710 - accuracy: 0.9167 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5682 - accuracy: 0.9167 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5644 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5614 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5672 - accuracy: 0.9286 - val_loss: 0.5708 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5643 - accuracy: 0.9286 - val_loss: 0.5680 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5508 - accuracy: 0.9792 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5474 - accuracy: 0.9792 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5913 - accuracy: 0.8542 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5890 - accuracy: 0.8542 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5577 - accuracy: 0.9583 - val_loss: 0.5919 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5545 - accuracy: 0.9583 - val_loss: 0.5897 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5711 - accuracy: 0.9167 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5683 - accuracy: 0.9167 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5440 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5405 - accuracy: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.6429 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.6420 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5847 - accuracy: 0.8750 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5822 - accuracy: 0.8750 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5750 - accuracy: 0.9048 - val_loss: 0.6615 - val_accuracy: 0.6364\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5723 - accuracy: 0.9048 - val_loss: 0.6611 - val_accuracy: 0.6364\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5643 - accuracy: 0.9375 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5613 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.6049 - accuracy: 0.8125 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6030 - accuracy: 0.8125 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.6173 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.6157 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5848 - accuracy: 0.8750 - val_loss: 0.5917 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5823 - accuracy: 0.8750 - val_loss: 0.5895 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5508 - accuracy: 0.9792 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5474 - accuracy: 0.9792 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5778 - accuracy: 0.8958 - val_loss: 0.5661 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5752 - accuracy: 0.8958 - val_loss: 0.5632 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5595 - accuracy: 0.9524 - val_loss: 0.5405 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5563 - accuracy: 0.9524 - val_loss: 0.5370 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=14\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5725 - accuracy: 0.8958 - val_loss: 0.5875 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5852 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 0.5583 - accuracy: 0.9375 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5553 - accuracy: 0.9375 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6081 - accuracy: 0.7917 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.6063 - accuracy: 0.7917 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5797 - accuracy: 0.8750 - val_loss: 0.5607 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5773 - accuracy: 0.8750 - val_loss: 0.5579 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5939 - accuracy: 0.8333 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5918 - accuracy: 0.8333 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 0.6294 - accuracy: 0.7292 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.6282 - accuracy: 0.7292 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5725 - accuracy: 0.8958 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5725 - accuracy: 0.8958 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5441 - accuracy: 0.9792 - val_loss: 0.5609 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5407 - accuracy: 0.9792 - val_loss: 0.5580 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5656 - accuracy: 0.9167 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5627 - accuracy: 0.9167 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5726 - accuracy: 0.8958 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5532 - accuracy: 0.9524 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5501 - accuracy: 0.9524 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 0.5726 - accuracy: 0.8958 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5656 - accuracy: 0.9167 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5628 - accuracy: 0.9167 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5584 - accuracy: 0.9375 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5554 - accuracy: 0.9375 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5441 - accuracy: 0.9792 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5408 - accuracy: 0.9792 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5695 - accuracy: 0.9048 - val_loss: 0.5652 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5668 - accuracy: 0.9048 - val_loss: 0.5625 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5335 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5725 - accuracy: 0.8958 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5655 - accuracy: 0.9167 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5655 - accuracy: 0.9167 - val_loss: 0.6144 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.6128 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5514 - accuracy: 0.9583 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5482 - accuracy: 0.9583 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.6081 - accuracy: 0.7917 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.6063 - accuracy: 0.7917 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5584 - accuracy: 0.9375 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5554 - accuracy: 0.9375 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5776 - accuracy: 0.8810 - val_loss: 0.5974 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5751 - accuracy: 0.8810 - val_loss: 0.5954 - val_accuracy: 0.8182\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5868 - accuracy: 0.8542 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5845 - accuracy: 0.8542 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5939 - accuracy: 0.8333 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5918 - accuracy: 0.8333 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5726 - accuracy: 0.8958 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5868 - accuracy: 0.8542 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5845 - accuracy: 0.8542 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5583 - accuracy: 0.9375 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5553 - accuracy: 0.9375 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5939 - accuracy: 0.8333 - val_loss: 0.5971 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5918 - accuracy: 0.8333 - val_loss: 0.5951 - val_accuracy: 0.8182\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5584 - accuracy: 0.9375 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5554 - accuracy: 0.9375 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 685ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5867 - accuracy: 0.8542 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5845 - accuracy: 0.8542 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.5584 - accuracy: 0.9375 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5554 - accuracy: 0.9375 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5867 - accuracy: 0.8542 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5845 - accuracy: 0.8542 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 0.5797 - accuracy: 0.8750 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5773 - accuracy: 0.8750 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5725 - accuracy: 0.8958 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5655 - accuracy: 0.9167 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5695 - accuracy: 0.9048 - val_loss: 0.5335 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5668 - accuracy: 0.9048 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5583 - accuracy: 0.9375 - val_loss: 0.5335 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5553 - accuracy: 0.9375 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5656 - accuracy: 0.9167 - val_loss: 0.5335 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5627 - accuracy: 0.9167 - val_loss: 0.5300 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5583 - accuracy: 0.9375 - val_loss: 0.5605 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5553 - accuracy: 0.9375 - val_loss: 0.5577 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5583 - accuracy: 0.9375 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5553 - accuracy: 0.9375 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5725 - accuracy: 0.8958 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5699 - accuracy: 0.8958 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.6142 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.6126 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5797 - accuracy: 0.8750 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5773 - accuracy: 0.8750 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5858 - accuracy: 0.8571 - val_loss: 0.5971 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5835 - accuracy: 0.8571 - val_loss: 0.5951 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5654 - accuracy: 0.9167 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5626 - accuracy: 0.9167 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5583 - accuracy: 0.9375 - val_loss: 0.5604 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5553 - accuracy: 0.9375 - val_loss: 0.5575 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5868 - accuracy: 0.8542 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5845 - accuracy: 0.8542 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5798 - accuracy: 0.8750 - val_loss: 0.5873 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5774 - accuracy: 0.8750 - val_loss: 0.5851 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5512 - accuracy: 0.9583 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5480 - accuracy: 0.9583 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5796 - accuracy: 0.8750 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5772 - accuracy: 0.8750 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5532 - accuracy: 0.9524 - val_loss: 0.5334 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5501 - accuracy: 0.9524 - val_loss: 0.5299 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=15\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.6111 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.6095 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 730ms/step - loss: 0.5748 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5448 - accuracy: 0.9583 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5971 - accuracy: 0.8125 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5952 - accuracy: 0.8125 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5448 - accuracy: 0.9583 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5598 - accuracy: 0.9167 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5570 - accuracy: 0.9167 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5749 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5725 - accuracy: 0.8750 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5811 - accuracy: 0.8571 - val_loss: 0.5597 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5788 - accuracy: 0.8571 - val_loss: 0.5570 - val_accuracy: 0.9091\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.6344 - accuracy: 0.7083 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6334 - accuracy: 0.7083 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5672 - accuracy: 0.8958 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5646 - accuracy: 0.8958 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5598 - accuracy: 0.9167 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5570 - accuracy: 0.9167 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5450 - accuracy: 0.9583 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5418 - accuracy: 0.9583 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5673 - accuracy: 0.8958 - val_loss: 0.5550 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5646 - accuracy: 0.8958 - val_loss: 0.5522 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5822 - accuracy: 0.8542 - val_loss: 0.5548 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5799 - accuracy: 0.8542 - val_loss: 0.5519 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5470 - accuracy: 0.9524 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5439 - accuracy: 0.9524 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5673 - accuracy: 0.8958 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5647 - accuracy: 0.8958 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5598 - accuracy: 0.9167 - val_loss: 0.6119 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5570 - accuracy: 0.9167 - val_loss: 0.6104 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5524 - accuracy: 0.9375 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5494 - accuracy: 0.9375 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5747 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5449 - accuracy: 0.9583 - val_loss: 0.5548 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.5519 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5374 - accuracy: 0.9792 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5340 - accuracy: 0.9792 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5299 - accuracy: 1.0000 - val_loss: 0.6393 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5264 - accuracy: 1.0000 - val_loss: 0.6384 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5640 - accuracy: 0.9048 - val_loss: 0.5597 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5613 - accuracy: 0.9048 - val_loss: 0.5570 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5672 - accuracy: 0.8958 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5646 - accuracy: 0.8958 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5524 - accuracy: 0.9375 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5494 - accuracy: 0.9375 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5673 - accuracy: 0.8958 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5647 - accuracy: 0.8958 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5524 - accuracy: 0.9375 - val_loss: 0.5269 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5494 - accuracy: 0.9375 - val_loss: 0.5233 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 0.5971 - accuracy: 0.8125 - val_loss: 0.6393 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5952 - accuracy: 0.8125 - val_loss: 0.6384 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5673 - accuracy: 0.8958 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5647 - accuracy: 0.8958 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5812 - accuracy: 0.8571 - val_loss: 0.5597 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5789 - accuracy: 0.8571 - val_loss: 0.5570 - val_accuracy: 0.9091\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.5299 - accuracy: 1.0000 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5264 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5672 - accuracy: 0.8958 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5646 - accuracy: 0.8958 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5971 - accuracy: 0.8125 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5952 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5822 - accuracy: 0.8542 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5799 - accuracy: 0.8542 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5673 - accuracy: 0.8958 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5647 - accuracy: 0.8958 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5897 - accuracy: 0.8333 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5876 - accuracy: 0.8333 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5896 - accuracy: 0.8333 - val_loss: 0.5931 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5875 - accuracy: 0.8333 - val_loss: 0.5911 - val_accuracy: 0.8182\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5449 - accuracy: 0.9583 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5598 - accuracy: 0.9167 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5570 - accuracy: 0.9167 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5598 - accuracy: 0.9167 - val_loss: 0.6393 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5570 - accuracy: 0.9167 - val_loss: 0.6384 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5599 - accuracy: 0.9167 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5571 - accuracy: 0.9167 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5747 - accuracy: 0.8750 - val_loss: 0.6111 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.6095 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5748 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5724 - accuracy: 0.8750 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5672 - accuracy: 0.8958 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5646 - accuracy: 0.8958 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5598 - accuracy: 0.9167 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5570 - accuracy: 0.9167 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5555 - accuracy: 0.9286 - val_loss: 0.5597 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5526 - accuracy: 0.9286 - val_loss: 0.5570 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5747 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5450 - accuracy: 0.9583 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5418 - accuracy: 0.9583 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5449 - accuracy: 0.9583 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5747 - accuracy: 0.8750 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 0.5971 - accuracy: 0.8125 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5952 - accuracy: 0.8125 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5674 - accuracy: 0.8958 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5647 - accuracy: 0.8958 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5811 - accuracy: 0.8571 - val_loss: 0.5933 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5788 - accuracy: 0.8571 - val_loss: 0.5914 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5448 - accuracy: 0.9583 - val_loss: 0.6111 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.6095 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5523 - accuracy: 0.9375 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5493 - accuracy: 0.9375 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5822 - accuracy: 0.8542 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5799 - accuracy: 0.8542 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5747 - accuracy: 0.8750 - val_loss: 0.5828 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.5806 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5600 - accuracy: 0.9167 - val_loss: 0.6393 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5572 - accuracy: 0.9167 - val_loss: 0.6384 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5747 - accuracy: 0.8750 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5723 - accuracy: 0.8750 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5448 - accuracy: 0.9583 - val_loss: 0.5264 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5417 - accuracy: 0.9583 - val_loss: 0.5228 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5672 - accuracy: 0.8958 - val_loss: 0.5546 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5646 - accuracy: 0.8958 - val_loss: 0.5517 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5384 - accuracy: 0.9762 - val_loss: 0.5597 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5351 - accuracy: 0.9762 - val_loss: 0.5570 - val_accuracy: 0.9091\n",
            "Publisher: global iteration=16\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5777 - accuracy: 0.8542 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5754 - accuracy: 0.8542 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5776 - accuracy: 0.8542 - val_loss: 0.6376 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5754 - accuracy: 0.8542 - val_loss: 0.6367 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5541 - accuracy: 0.9167 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5513 - accuracy: 0.9167 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5777 - accuracy: 0.8542 - val_loss: 0.5197 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5755 - accuracy: 0.8542 - val_loss: 0.5162 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5855 - accuracy: 0.8333 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5834 - accuracy: 0.8333 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.6011 - accuracy: 0.7917 - val_loss: 0.6376 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5994 - accuracy: 0.7917 - val_loss: 0.6367 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5386 - accuracy: 0.9583 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5355 - accuracy: 0.9583 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5543 - accuracy: 0.9167 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5515 - accuracy: 0.9167 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5698 - accuracy: 0.8750 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5674 - accuracy: 0.8750 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5407 - accuracy: 0.9524 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5376 - accuracy: 0.9524 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 724ms/step - loss: 0.5698 - accuracy: 0.8750 - val_loss: 0.5195 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5673 - accuracy: 0.8750 - val_loss: 0.5160 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5541 - accuracy: 0.9167 - val_loss: 0.6089 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5513 - accuracy: 0.9167 - val_loss: 0.6074 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5386 - accuracy: 0.9583 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5354 - accuracy: 0.9583 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5307 - accuracy: 0.9792 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5274 - accuracy: 0.9792 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5586 - accuracy: 0.9048 - val_loss: 0.5542 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5559 - accuracy: 0.9048 - val_loss: 0.5515 - val_accuracy: 0.9091\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5698 - accuracy: 0.8750 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5673 - accuracy: 0.8750 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5541 - accuracy: 0.9167 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5513 - accuracy: 0.9167 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5594 - accuracy: 0.8958 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5621 - accuracy: 0.8958 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5594 - accuracy: 0.8958 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5387 - accuracy: 0.9583 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5355 - accuracy: 0.9583 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5933 - accuracy: 0.8125 - val_loss: 0.6376 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5914 - accuracy: 0.8125 - val_loss: 0.6367 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5594 - accuracy: 0.8958 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5676 - accuracy: 0.8810 - val_loss: 0.5894 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5651 - accuracy: 0.8810 - val_loss: 0.5875 - val_accuracy: 0.8182\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5541 - accuracy: 0.9167 - val_loss: 0.6080 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5513 - accuracy: 0.9167 - val_loss: 0.6065 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5933 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5914 - accuracy: 0.8125 - val_loss: 0.5158 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5776 - accuracy: 0.8542 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5754 - accuracy: 0.8542 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5594 - accuracy: 0.8958 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 751ms/step - loss: 0.5855 - accuracy: 0.8333 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5834 - accuracy: 0.8333 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5944 - accuracy: 0.8095 - val_loss: 0.5542 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5925 - accuracy: 0.8095 - val_loss: 0.5515 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5464 - accuracy: 0.9375 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5434 - accuracy: 0.9375 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5541 - accuracy: 0.9167 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5513 - accuracy: 0.9167 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.6080 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.6065 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5493 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5464 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5933 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5914 - accuracy: 0.8125 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5699 - accuracy: 0.8750 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5675 - accuracy: 0.8750 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5541 - accuracy: 0.9167 - val_loss: 0.5195 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5513 - accuracy: 0.9167 - val_loss: 0.5159 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5497 - accuracy: 0.9286 - val_loss: 0.5542 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5468 - accuracy: 0.9286 - val_loss: 0.5515 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5463 - accuracy: 0.9375 - val_loss: 0.6376 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5433 - accuracy: 0.9375 - val_loss: 0.6367 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5542 - accuracy: 0.9167 - val_loss: 0.5197 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5514 - accuracy: 0.9167 - val_loss: 0.5162 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5542 - accuracy: 0.9167 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5514 - accuracy: 0.9167 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 0.5776 - accuracy: 0.8542 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5754 - accuracy: 0.8542 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5855 - accuracy: 0.8333 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5834 - accuracy: 0.8333 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5464 - accuracy: 0.9375 - val_loss: 0.6080 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5434 - accuracy: 0.9375 - val_loss: 0.6065 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5766 - accuracy: 0.8571 - val_loss: 0.5892 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5743 - accuracy: 0.8571 - val_loss: 0.5872 - val_accuracy: 0.8182\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5620 - accuracy: 0.8958 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5593 - accuracy: 0.8958 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5855 - accuracy: 0.8333 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5834 - accuracy: 0.8333 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5698 - accuracy: 0.8750 - val_loss: 0.5784 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5673 - accuracy: 0.8750 - val_loss: 0.5762 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5779 - accuracy: 0.8542 - val_loss: 0.5489 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5756 - accuracy: 0.8542 - val_loss: 0.5460 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5698 - accuracy: 0.8750 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5673 - accuracy: 0.8750 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.5193 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.5157 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5385 - accuracy: 0.9583 - val_loss: 0.6376 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5353 - accuracy: 0.9583 - val_loss: 0.6367 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5318 - accuracy: 0.9762 - val_loss: 0.5542 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5284 - accuracy: 0.9762 - val_loss: 0.5515 - val_accuracy: 0.9091\n",
            "Publisher: global iteration=17\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5731 - accuracy: 0.8542 - val_loss: 0.5124 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5708 - accuracy: 0.8542 - val_loss: 0.5088 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5403 - accuracy: 0.9375 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5373 - accuracy: 0.9375 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5813 - accuracy: 0.8333 - val_loss: 0.6050 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5792 - accuracy: 0.8333 - val_loss: 0.6035 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5087 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 0.5650 - accuracy: 0.8750 - val_loss: 0.5436 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5626 - accuracy: 0.8750 - val_loss: 0.5407 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5719 - accuracy: 0.8571 - val_loss: 0.5487 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5696 - accuracy: 0.8571 - val_loss: 0.5460 - val_accuracy: 0.9091\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.6140 - accuracy: 0.7500 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.6127 - accuracy: 0.7500 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5159 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5123 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5405 - accuracy: 0.9375 - val_loss: 0.6050 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5375 - accuracy: 0.9375 - val_loss: 0.6035 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5731 - accuracy: 0.8542 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5709 - accuracy: 0.8542 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5345 - accuracy: 0.9524 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5313 - accuracy: 0.9524 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5625 - accuracy: 0.8750 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5569 - accuracy: 0.8958 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5543 - accuracy: 0.8958 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5241 - accuracy: 0.9792 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5207 - accuracy: 0.9792 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5625 - accuracy: 0.8750 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5433 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5404 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 721ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5626 - accuracy: 0.8810 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5601 - accuracy: 0.8810 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5486 - accuracy: 0.9167 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.5433 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5625 - accuracy: 0.8750 - val_loss: 0.5404 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 0.5405 - accuracy: 0.9375 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5375 - accuracy: 0.9375 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5895 - accuracy: 0.8125 - val_loss: 0.6359 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5876 - accuracy: 0.8125 - val_loss: 0.6351 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5568 - accuracy: 0.8958 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5813 - accuracy: 0.8333 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5792 - accuracy: 0.8333 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5403 - accuracy: 0.9375 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5373 - accuracy: 0.9375 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5157 - accuracy: 1.0000 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5122 - accuracy: 1.0000 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.6050 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.6035 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5895 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5876 - accuracy: 0.8125 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5731 - accuracy: 0.8542 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5708 - accuracy: 0.8542 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5486 - accuracy: 0.9167 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.6359 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5625 - accuracy: 0.8750 - val_loss: 0.6351 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 682ms/step - loss: 0.5906 - accuracy: 0.8095 - val_loss: 0.5487 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5888 - accuracy: 0.8095 - val_loss: 0.5460 - val_accuracy: 0.9091\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5404 - accuracy: 0.9375 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5374 - accuracy: 0.9375 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5485 - accuracy: 0.9167 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5457 - accuracy: 0.9167 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5813 - accuracy: 0.8333 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5792 - accuracy: 0.8333 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5403 - accuracy: 0.9375 - val_loss: 0.5436 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5373 - accuracy: 0.9375 - val_loss: 0.5407 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5731 - accuracy: 0.8542 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5708 - accuracy: 0.8542 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.5436 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5624 - accuracy: 0.8750 - val_loss: 0.5407 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5624 - accuracy: 0.8750 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5404 - accuracy: 0.9375 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5374 - accuracy: 0.9375 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5438 - accuracy: 0.9286 - val_loss: 0.5487 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5409 - accuracy: 0.9286 - val_loss: 0.5460 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5624 - accuracy: 0.8750 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5486 - accuracy: 0.9167 - val_loss: 0.5127 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5458 - accuracy: 0.9167 - val_loss: 0.5091 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5404 - accuracy: 0.9375 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5374 - accuracy: 0.9375 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5403 - accuracy: 0.9375 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5373 - accuracy: 0.9375 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5740 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5719 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5895 - accuracy: 0.8125 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5876 - accuracy: 0.8125 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5650 - accuracy: 0.8750 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5626 - accuracy: 0.8750 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5906 - accuracy: 0.8095 - val_loss: 0.5124 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5888 - accuracy: 0.8095 - val_loss: 0.5089 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5403 - accuracy: 0.9375 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5373 - accuracy: 0.9375 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 726ms/step - loss: 0.5649 - accuracy: 0.8750 - val_loss: 0.6050 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5625 - accuracy: 0.8750 - val_loss: 0.6035 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5731 - accuracy: 0.8542 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5708 - accuracy: 0.8542 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5732 - accuracy: 0.8542 - val_loss: 0.5436 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5709 - accuracy: 0.8542 - val_loss: 0.5407 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5567 - accuracy: 0.8958 - val_loss: 0.5431 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5541 - accuracy: 0.8958 - val_loss: 0.5402 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5321 - accuracy: 0.9583 - val_loss: 0.5122 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5289 - accuracy: 0.9583 - val_loss: 0.5086 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5403 - accuracy: 0.9375 - val_loss: 0.6050 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5373 - accuracy: 0.9375 - val_loss: 0.6035 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5251 - accuracy: 0.9762 - val_loss: 0.5487 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5218 - accuracy: 0.9762 - val_loss: 0.5460 - val_accuracy: 0.9091\n",
            "Publisher: global iteration=18\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5514 - accuracy: 0.8958 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5488 - accuracy: 0.8958 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5515 - accuracy: 0.8958 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5489 - accuracy: 0.8958 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5172 - accuracy: 0.9792 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5138 - accuracy: 0.9792 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.6666 - val_accuracy: 0.6154\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.6665 - val_accuracy: 0.6154\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5172 - accuracy: 0.9792 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5138 - accuracy: 0.9792 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 693ms/step - loss: 0.5688 - accuracy: 0.8542 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5666 - accuracy: 0.8542 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5576 - accuracy: 0.8810 - val_loss: 0.5814 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5551 - accuracy: 0.8810 - val_loss: 0.5795 - val_accuracy: 0.8182\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.6028 - accuracy: 0.7708 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6013 - accuracy: 0.7708 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 727ms/step - loss: 0.5172 - accuracy: 0.9792 - val_loss: 0.5380 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5138 - accuracy: 0.9792 - val_loss: 0.5351 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5516 - accuracy: 0.8958 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5490 - accuracy: 0.8958 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 704ms/step - loss: 0.5601 - accuracy: 0.8750 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5282 - accuracy: 0.9524 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5251 - accuracy: 0.9524 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5344 - accuracy: 0.9375 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5314 - accuracy: 0.9375 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5517 - accuracy: 0.8958 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5490 - accuracy: 0.8958 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5259 - accuracy: 0.9583 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5227 - accuracy: 0.9583 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5258 - accuracy: 0.9583 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5226 - accuracy: 0.9583 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5258 - accuracy: 0.9583 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5226 - accuracy: 0.9583 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5576 - accuracy: 0.8810 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5551 - accuracy: 0.8810 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5514 - accuracy: 0.8958 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5488 - accuracy: 0.8958 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.6021 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.6006 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5259 - accuracy: 0.9583 - val_loss: 0.5376 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5227 - accuracy: 0.9583 - val_loss: 0.5347 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.6028 - accuracy: 0.7708 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6013 - accuracy: 0.7708 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5344 - accuracy: 0.9375 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5314 - accuracy: 0.9375 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5772 - accuracy: 0.8333 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5751 - accuracy: 0.8333 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 689ms/step - loss: 0.5172 - accuracy: 0.9792 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5138 - accuracy: 0.9792 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5258 - accuracy: 0.9583 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5226 - accuracy: 0.9583 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 703ms/step - loss: 0.5514 - accuracy: 0.8958 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5488 - accuracy: 0.8958 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5771 - accuracy: 0.8333 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5751 - accuracy: 0.8333 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5686 - accuracy: 0.8542 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5663 - accuracy: 0.8542 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5857 - accuracy: 0.8125 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5838 - accuracy: 0.8125 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 680ms/step - loss: 0.5172 - accuracy: 0.9792 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5138 - accuracy: 0.9792 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5771 - accuracy: 0.8333 - val_loss: 0.5814 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5751 - accuracy: 0.8333 - val_loss: 0.5795 - val_accuracy: 0.8182\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 728ms/step - loss: 0.5430 - accuracy: 0.9167 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5402 - accuracy: 0.9167 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5686 - accuracy: 0.8542 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5663 - accuracy: 0.8542 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5516 - accuracy: 0.8958 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5489 - accuracy: 0.8958 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5344 - accuracy: 0.9375 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5314 - accuracy: 0.9375 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5380 - accuracy: 0.9286 - val_loss: 0.5432 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5351 - accuracy: 0.9286 - val_loss: 0.5405 - val_accuracy: 0.9091\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5056 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5020 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 725ms/step - loss: 0.5344 - accuracy: 0.9375 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5314 - accuracy: 0.9375 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 709ms/step - loss: 0.5343 - accuracy: 0.9375 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5313 - accuracy: 0.9375 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5514 - accuracy: 0.8958 - val_loss: 0.5697 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5488 - accuracy: 0.8958 - val_loss: 0.5675 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.6020 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.6005 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5516 - accuracy: 0.8958 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5489 - accuracy: 0.8958 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5870 - accuracy: 0.8095 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5851 - accuracy: 0.8095 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5429 - accuracy: 0.9167 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5401 - accuracy: 0.9167 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5772 - accuracy: 0.8333 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5751 - accuracy: 0.8333 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5686 - accuracy: 0.8542 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.5663 - accuracy: 0.8542 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5601 - accuracy: 0.8750 - val_loss: 0.5702 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5577 - accuracy: 0.8750 - val_loss: 0.5680 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5514 - accuracy: 0.8958 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5488 - accuracy: 0.8958 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5172 - accuracy: 0.9792 - val_loss: 0.5374 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5138 - accuracy: 0.9792 - val_loss: 0.5345 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5600 - accuracy: 0.8750 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5576 - accuracy: 0.8750 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 675ms/step - loss: 0.5282 - accuracy: 0.9524 - val_loss: 0.5051 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5251 - accuracy: 0.9524 - val_loss: 0.5015 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=19\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5462 - accuracy: 0.8958 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5436 - accuracy: 0.8958 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5552 - accuracy: 0.8750 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5730 - accuracy: 0.8333 - val_loss: 0.5991 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5709 - accuracy: 0.8333 - val_loss: 0.5976 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 710ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 711ms/step - loss: 0.5554 - accuracy: 0.8750 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5530 - accuracy: 0.8750 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5730 - accuracy: 0.8333 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5709 - accuracy: 0.8333 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.6087 - accuracy: 0.7500 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6074 - accuracy: 0.7500 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 720ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.5990 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.5975 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5462 - accuracy: 0.8958 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5436 - accuracy: 0.8958 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5195 - accuracy: 0.9583 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5163 - accuracy: 0.9583 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5374 - accuracy: 0.9167 - val_loss: 0.5654 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5346 - accuracy: 0.9167 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.5317 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.6327 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5345 - accuracy: 0.9167 - val_loss: 0.6319 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5117 - accuracy: 0.9762 - val_loss: 0.5378 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5084 - accuracy: 0.9762 - val_loss: 0.5350 - val_accuracy: 0.9091\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.5992 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.5977 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5554 - accuracy: 0.8750 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5529 - accuracy: 0.8750 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5195 - accuracy: 0.9583 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5163 - accuracy: 0.9583 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 0.5551 - accuracy: 0.8750 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5284 - accuracy: 0.9375 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5254 - accuracy: 0.9375 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5104 - accuracy: 0.9792 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5071 - accuracy: 0.9792 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 691ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 701ms/step - loss: 0.5219 - accuracy: 0.9524 - val_loss: 0.6174 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5188 - accuracy: 0.9524 - val_loss: 0.6163 - val_accuracy: 0.7273\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5618 - accuracy: 0.8542 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5284 - accuracy: 0.9375 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5254 - accuracy: 0.9375 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5463 - accuracy: 0.8958 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5436 - accuracy: 0.8958 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 708ms/step - loss: 0.5105 - accuracy: 0.9792 - val_loss: 0.5659 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5071 - accuracy: 0.9792 - val_loss: 0.5637 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5819 - accuracy: 0.8125 - val_loss: 0.6327 - val_accuracy: 0.6923\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5801 - accuracy: 0.8125 - val_loss: 0.6319 - val_accuracy: 0.6923\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5345 - accuracy: 0.9167 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5526 - accuracy: 0.8810 - val_loss: 0.5776 - val_accuracy: 0.8182\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5501 - accuracy: 0.8810 - val_loss: 0.5757 - val_accuracy: 0.8182\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.5990 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.5975 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5618 - accuracy: 0.8542 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 700ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5618 - accuracy: 0.8542 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5551 - accuracy: 0.8750 - val_loss: 0.4981 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.4945 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5730 - accuracy: 0.8333 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5709 - accuracy: 0.8333 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 697ms/step - loss: 0.5628 - accuracy: 0.8571 - val_loss: 0.6174 - val_accuracy: 0.7273\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5605 - accuracy: 0.8571 - val_loss: 0.6163 - val_accuracy: 0.7273\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.5318 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.5289 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5462 - accuracy: 0.8958 - val_loss: 0.5990 - val_accuracy: 0.7692\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5436 - accuracy: 0.8958 - val_loss: 0.5975 - val_accuracy: 0.7692\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 719ms/step - loss: 0.5195 - accuracy: 0.9583 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5163 - accuracy: 0.9583 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5618 - accuracy: 0.8542 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5463 - accuracy: 0.8958 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5437 - accuracy: 0.8958 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 716ms/step - loss: 0.5462 - accuracy: 0.8958 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5436 - accuracy: 0.8958 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 717ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 706ms/step - loss: 0.5424 - accuracy: 0.9048 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5397 - accuracy: 0.9048 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 696ms/step - loss: 0.5283 - accuracy: 0.9375 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5253 - accuracy: 0.9375 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 715ms/step - loss: 0.5551 - accuracy: 0.8750 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 702ms/step - loss: 0.5284 - accuracy: 0.9375 - val_loss: 0.5321 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5254 - accuracy: 0.9375 - val_loss: 0.5293 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 692ms/step - loss: 0.5284 - accuracy: 0.9375 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5254 - accuracy: 0.9375 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 705ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5551 - accuracy: 0.8750 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 707ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5618 - accuracy: 0.8542 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5463 - accuracy: 0.8958 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5437 - accuracy: 0.8958 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 698ms/step - loss: 0.5730 - accuracy: 0.8333 - val_loss: 0.5378 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5710 - accuracy: 0.8333 - val_loss: 0.5350 - val_accuracy: 0.9091\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 688ms/step - loss: 0.5373 - accuracy: 0.9167 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.5344 - accuracy: 0.9167 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 712ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.5655 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5618 - accuracy: 0.8542 - val_loss: 0.5633 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5551 - accuracy: 0.8750 - val_loss: 0.5653 - val_accuracy: 0.8462\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.5632 - val_accuracy: 0.8462\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 714ms/step - loss: 0.5643 - accuracy: 0.8542 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.5621 - accuracy: 0.8542 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 713ms/step - loss: 0.5551 - accuracy: 0.8750 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.5527 - accuracy: 0.8750 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 718ms/step - loss: 0.5194 - accuracy: 0.9583 - val_loss: 0.4979 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5162 - accuracy: 0.9583 - val_loss: 0.4944 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 695ms/step - loss: 0.5462 - accuracy: 0.8958 - val_loss: 0.5316 - val_accuracy: 0.9231\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5436 - accuracy: 0.8958 - val_loss: 0.5288 - val_accuracy: 0.9231\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 690ms/step - loss: 0.5117 - accuracy: 0.9762 - val_loss: 0.5378 - val_accuracy: 0.9091\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5084 - accuracy: 0.9762 - val_loss: 0.5350 - val_accuracy: 0.9091\n",
            "Publisher: finished all global\n",
            "Accuracy on Val Data:  [0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131]\n"
          ]
        }
      ],
      "source": [
        "# Decentralized FL\n",
        "acc_dfl_fraud = complete_xp(np.copy(x_fraud), np.copy(y_fraud), get_fraud_model(), [2,4,8], [3,6,9], 10, 3, deep_copy_fraud_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GJUnm4UsdTyC",
        "outputId": "dd52bfdf-26a1-4150-9094-c3ea3a5438ac"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-6b00b08c098b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'acc_df1_fraud'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_dfl_fraud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_accuracy_curves_xp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_dfl_fraud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-e62b5d4bcb1b>\u001b[0m in \u001b[0;36mplot_accuracy_curves_xp\u001b[0;34m(history, no_grps_list, no_peers_list)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mcombination\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_grps_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" groups, \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_peers_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" peers/group \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0midx\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (2,)"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "np.save('acc_df1_fraud', acc_dfl_fraud)\n",
        "plot_accuracy_curves_xp(acc_dfl_fraud, [2,4,8], [3,6,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hNykz7itU7MJ",
        "outputId": "bf4ccbb0-c135-4a55-9442-41277b88b60d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tmp = get_metrics(acc_dfl_fraud, [0.70, 0.8])\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[0], \"Final Accuracy\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[1], \"Max Accuracy\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[2][0], \"Rounds to 70%\")\n",
        "plot_metrics([2, 3], [2, 3, 4], tmp[2][1], \"Rounds to 80%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1VT0-tQGUON",
        "outputId": "2261bad3-3ae2-4caf-e92d-4594ccb9fe0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6501 - accuracy: 0.9231 - val_loss: 0.6501 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6475 - accuracy: 0.9231 - val_loss: 0.6477 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6595 - accuracy: 0.8333 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6575 - accuracy: 0.8333 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.6555 - accuracy: 0.8718 - val_loss: 0.6612 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6532 - accuracy: 0.8718 - val_loss: 0.6595 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6555 - accuracy: 0.8718 - val_loss: 0.6501 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6532 - accuracy: 0.8718 - val_loss: 0.6477 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6609 - accuracy: 0.8205 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6590 - accuracy: 0.8205 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6528 - accuracy: 0.8974 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6504 - accuracy: 0.8974 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6507 - accuracy: 0.9167 - val_loss: 0.6513 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6482 - accuracy: 0.9167 - val_loss: 0.6490 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6501 - accuracy: 0.9231 - val_loss: 0.6501 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6475 - accuracy: 0.9231 - val_loss: 0.6477 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6447 - accuracy: 0.9744 - val_loss: 0.6724 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6418 - accuracy: 0.9744 - val_loss: 0.6713 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6582 - accuracy: 0.8462 - val_loss: 0.6501 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6561 - accuracy: 0.8462 - val_loss: 0.6477 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6608 - accuracy: 0.8205 - val_loss: 0.6613 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6590 - accuracy: 0.8205 - val_loss: 0.6596 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6595 - accuracy: 0.8333 - val_loss: 0.6513 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6575 - accuracy: 0.8333 - val_loss: 0.6490 - val_accuracy: 0.8889\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6505 - accuracy: 0.9189 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6480 - accuracy: 0.9189 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6505 - accuracy: 0.9189 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6480 - accuracy: 0.9189 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6505 - accuracy: 0.9189 - val_loss: 0.6501 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6480 - accuracy: 0.9189 - val_loss: 0.6477 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.6505 - accuracy: 0.9189 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6480 - accuracy: 0.9189 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6451 - accuracy: 0.9706 - val_loss: 0.6389 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6422 - accuracy: 0.9706 - val_loss: 0.6359 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=7\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6392 - accuracy: 0.9722 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6363 - accuracy: 0.9722 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6556 - accuracy: 0.8333 - val_loss: 0.6468 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6536 - accuracy: 0.8333 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6540 - accuracy: 0.8462 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6520 - accuracy: 0.8462 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6571 - accuracy: 0.8205 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6552 - accuracy: 0.8205 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6571 - accuracy: 0.8205 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6552 - accuracy: 0.8205 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6490 - accuracy: 0.8889 - val_loss: 0.6467 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6467 - accuracy: 0.8889 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6457 - accuracy: 0.9167 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6432 - accuracy: 0.9167 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6540 - accuracy: 0.8462 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6520 - accuracy: 0.8462 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6523 - accuracy: 0.8611 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6501 - accuracy: 0.8611 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6457 - accuracy: 0.9167 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6432 - accuracy: 0.9167 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6392 - accuracy: 0.9722 - val_loss: 0.6467 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6363 - accuracy: 0.9722 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6571 - accuracy: 0.8205 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6552 - accuracy: 0.8205 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6389 - accuracy: 0.9744 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6360 - accuracy: 0.9744 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6490 - accuracy: 0.8889 - val_loss: 0.6467 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.6467 - accuracy: 0.8889 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6540 - accuracy: 0.8462 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6520 - accuracy: 0.8462 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6540 - accuracy: 0.8462 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6520 - accuracy: 0.8462 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6490 - accuracy: 0.8889 - val_loss: 0.6743 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6467 - accuracy: 0.8889 - val_loss: 0.6735 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6389 - accuracy: 0.9744 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6360 - accuracy: 0.9744 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6556 - accuracy: 0.8333 - val_loss: 0.6605 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6536 - accuracy: 0.8333 - val_loss: 0.6589 - val_accuracy: 0.7778\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6540 - accuracy: 0.8462 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6520 - accuracy: 0.8462 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6424 - accuracy: 0.9444 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6398 - accuracy: 0.9444 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6571 - accuracy: 0.8205 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6552 - accuracy: 0.8205 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6540 - accuracy: 0.8462 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6520 - accuracy: 0.8462 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6490 - accuracy: 0.8889 - val_loss: 0.6467 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6467 - accuracy: 0.8889 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6389 - accuracy: 0.9744 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6361 - accuracy: 0.9744 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6702 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6691 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6490 - accuracy: 0.8889 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6467 - accuracy: 0.8889 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6457 - accuracy: 0.9167 - val_loss: 0.6468 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6432 - accuracy: 0.9167 - val_loss: 0.6445 - val_accuracy: 0.8889\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6419 - accuracy: 0.9487 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6392 - accuracy: 0.9487 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6359 - accuracy: 1.0000 - val_loss: 0.6329 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6328 - accuracy: 1.0000 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6523 - accuracy: 0.8611 - val_loss: 0.6467 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6501 - accuracy: 0.8611 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6571 - accuracy: 0.8205 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6552 - accuracy: 0.8205 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6702 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6691 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6510 - accuracy: 0.8718 - val_loss: 0.6577 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6488 - accuracy: 0.8718 - val_loss: 0.6560 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6480 - accuracy: 0.8974 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6456 - accuracy: 0.8974 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6457 - accuracy: 0.9167 - val_loss: 0.6467 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6432 - accuracy: 0.9167 - val_loss: 0.6444 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 906ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6450 - accuracy: 0.9231 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6424 - accuracy: 0.9231 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.6571 - accuracy: 0.8205 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6552 - accuracy: 0.8205 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6601 - accuracy: 0.7949 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6584 - accuracy: 0.7949 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.6589 - accuracy: 0.8056 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6571 - accuracy: 0.8056 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.6423 - accuracy: 0.9459 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6396 - accuracy: 0.9459 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6423 - accuracy: 0.9459 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6396 - accuracy: 0.9459 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6455 - accuracy: 0.9189 - val_loss: 0.6453 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6429 - accuracy: 0.9189 - val_loss: 0.6429 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6455 - accuracy: 0.9189 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6429 - accuracy: 0.9189 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6394 - accuracy: 0.9706 - val_loss: 0.6328 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6365 - accuracy: 0.9706 - val_loss: 0.6298 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=8\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6334 - accuracy: 0.9722 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6306 - accuracy: 0.9722 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6669 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6332 - accuracy: 0.9744 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6303 - accuracy: 0.9744 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6408 - accuracy: 0.9167 - val_loss: 0.6879 - val_accuracy: 0.5556\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6383 - accuracy: 0.9167 - val_loss: 0.6877 - val_accuracy: 0.5556\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6567 - accuracy: 0.7949 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6550 - accuracy: 0.7949 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6533 - accuracy: 0.8205 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6514 - accuracy: 0.8205 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6407 - accuracy: 0.9167 - val_loss: 0.6573 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6382 - accuracy: 0.9167 - val_loss: 0.6557 - val_accuracy: 0.7778\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6332 - accuracy: 0.9744 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6303 - accuracy: 0.9744 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6334 - accuracy: 0.9722 - val_loss: 0.6573 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6306 - accuracy: 0.9722 - val_loss: 0.6557 - val_accuracy: 0.7778\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6669 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.6444 - accuracy: 0.8889 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6420 - accuracy: 0.8889 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.6371 - accuracy: 0.9444 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6344 - accuracy: 0.9444 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6332 - accuracy: 0.9744 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6303 - accuracy: 0.9744 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6371 - accuracy: 0.9444 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6344 - accuracy: 0.9444 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6479 - accuracy: 0.8462 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6669 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6480 - accuracy: 0.8611 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6459 - accuracy: 0.8611 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6669 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6479 - accuracy: 0.8462 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6516 - accuracy: 0.8333 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6497 - accuracy: 0.8333 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6298 - accuracy: 1.0000 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6268 - accuracy: 1.0000 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6480 - accuracy: 0.8611 - val_loss: 0.6726 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6459 - accuracy: 0.8611 - val_loss: 0.6717 - val_accuracy: 0.6667\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6334 - accuracy: 0.9722 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6306 - accuracy: 0.9722 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6533 - accuracy: 0.8205 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6514 - accuracy: 0.8205 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6480 - accuracy: 0.8611 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6459 - accuracy: 0.8611 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6374 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6669 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.6406 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6479 - accuracy: 0.8462 - val_loss: 0.6383 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6466 - accuracy: 0.8718 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6444 - accuracy: 0.8718 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.6407 - accuracy: 0.9167 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6382 - accuracy: 0.9167 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6332 - accuracy: 0.9744 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6303 - accuracy: 0.9744 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6407 - accuracy: 0.9167 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6383 - accuracy: 0.9167 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6399 - accuracy: 0.9231 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6373 - accuracy: 0.9231 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6298 - accuracy: 1.0000 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6268 - accuracy: 1.0000 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6516 - accuracy: 0.8333 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6497 - accuracy: 0.8333 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6533 - accuracy: 0.8205 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6514 - accuracy: 0.8205 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6525 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6479 - accuracy: 0.8462 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6444 - accuracy: 0.8889 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6420 - accuracy: 0.8889 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6365 - accuracy: 0.9487 - val_loss: 0.6543 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6338 - accuracy: 0.9487 - val_loss: 0.6526 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6432 - accuracy: 0.8974 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6409 - accuracy: 0.8974 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6479 - accuracy: 0.8462 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.6680 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6479 - accuracy: 0.8462 - val_loss: 0.6669 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6517 - accuracy: 0.8333 - val_loss: 0.6420 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6497 - accuracy: 0.8333 - val_loss: 0.6398 - val_accuracy: 0.8889\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6404 - accuracy: 0.9189 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6379 - accuracy: 0.9189 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6369 - accuracy: 0.9459 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6342 - accuracy: 0.9459 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6404 - accuracy: 0.9189 - val_loss: 0.6405 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6379 - accuracy: 0.9189 - val_loss: 0.6382 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6404 - accuracy: 0.9189 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6379 - accuracy: 0.9189 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6337 - accuracy: 0.9706 - val_loss: 0.6268 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6308 - accuracy: 0.9706 - val_loss: 0.6238 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=9\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6278 - accuracy: 0.9722 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6249 - accuracy: 0.9722 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6275 - accuracy: 0.9744 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6246 - accuracy: 0.9744 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6478 - accuracy: 0.8333 - val_loss: 0.6376 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6458 - accuracy: 0.8333 - val_loss: 0.6353 - val_accuracy: 0.8889\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.6459 - accuracy: 0.8462 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6439 - accuracy: 0.8462 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6496 - accuracy: 0.8205 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6478 - accuracy: 0.8205 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6398 - accuracy: 0.8889 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6375 - accuracy: 0.8889 - val_loss: 0.6352 - val_accuracy: 0.8889\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6275 - accuracy: 0.9744 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6246 - accuracy: 0.9744 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6349 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6358 - accuracy: 0.9167 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6333 - accuracy: 0.9167 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6311 - accuracy: 0.9487 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6285 - accuracy: 0.9487 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6438 - accuracy: 0.8611 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6416 - accuracy: 0.8611 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6358 - accuracy: 0.9167 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6333 - accuracy: 0.9167 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6275 - accuracy: 0.9744 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6246 - accuracy: 0.9744 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6311 - accuracy: 0.9487 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6285 - accuracy: 0.9487 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6318 - accuracy: 0.9444 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6291 - accuracy: 0.9444 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6459 - accuracy: 0.8462 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6439 - accuracy: 0.8462 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6311 - accuracy: 0.9487 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6285 - accuracy: 0.9487 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6398 - accuracy: 0.8889 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6375 - accuracy: 0.8889 - val_loss: 0.6352 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6459 - accuracy: 0.8462 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.6439 - accuracy: 0.8462 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6438 - accuracy: 0.8611 - val_loss: 0.6542 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6416 - accuracy: 0.8611 - val_loss: 0.6526 - val_accuracy: 0.7778\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6275 - accuracy: 0.9744 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6246 - accuracy: 0.9744 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6398 - accuracy: 0.8889 - val_loss: 0.6876 - val_accuracy: 0.5556\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6375 - accuracy: 0.8889 - val_loss: 0.6875 - val_accuracy: 0.5556\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6459 - accuracy: 0.8462 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6439 - accuracy: 0.8462 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6318 - accuracy: 0.9444 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6291 - accuracy: 0.9444 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6533 - accuracy: 0.7949 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6516 - accuracy: 0.7949 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6275 - accuracy: 0.9744 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6246 - accuracy: 0.9744 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6459 - accuracy: 0.8462 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6439 - accuracy: 0.8462 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6398 - accuracy: 0.8889 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6375 - accuracy: 0.8889 - val_loss: 0.6352 - val_accuracy: 0.8889\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6349 - accuracy: 0.9231 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.6496 - accuracy: 0.8205 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6478 - accuracy: 0.8205 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6358 - accuracy: 0.9167 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6333 - accuracy: 0.9167 - val_loss: 0.6352 - val_accuracy: 0.8889\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6311 - accuracy: 0.9487 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6285 - accuracy: 0.9487 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6311 - accuracy: 0.9487 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6285 - accuracy: 0.9487 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6398 - accuracy: 0.8889 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6375 - accuracy: 0.8889 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6348 - accuracy: 0.9231 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6323 - accuracy: 0.9231 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6275 - accuracy: 0.9744 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6246 - accuracy: 0.9744 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6238 - accuracy: 1.0000 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6207 - accuracy: 1.0000 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6311 - accuracy: 0.9487 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6285 - accuracy: 0.9487 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6478 - accuracy: 0.8333 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6458 - accuracy: 0.8333 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.6496 - accuracy: 0.8205 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.6478 - accuracy: 0.8205 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6358 - accuracy: 0.9167 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6333 - accuracy: 0.9167 - val_loss: 0.6352 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6385 - accuracy: 0.8974 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6362 - accuracy: 0.8974 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6422 - accuracy: 0.8718 - val_loss: 0.6508 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6400 - accuracy: 0.8718 - val_loss: 0.6491 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6459 - accuracy: 0.8462 - val_loss: 0.6659 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6439 - accuracy: 0.8462 - val_loss: 0.6648 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6478 - accuracy: 0.8333 - val_loss: 0.6375 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6458 - accuracy: 0.8333 - val_loss: 0.6352 - val_accuracy: 0.8889\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6354 - accuracy: 0.9189 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6329 - accuracy: 0.9189 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6315 - accuracy: 0.9459 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6289 - accuracy: 0.9459 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6354 - accuracy: 0.9189 - val_loss: 0.6358 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6329 - accuracy: 0.9189 - val_loss: 0.6334 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 916ms/step - loss: 0.6354 - accuracy: 0.9189 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6329 - accuracy: 0.9189 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6280 - accuracy: 0.9706 - val_loss: 0.6207 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6252 - accuracy: 0.9706 - val_loss: 0.6177 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=10\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6638 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6627 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6221 - accuracy: 0.9722 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6193 - accuracy: 0.9722 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6419 - accuracy: 0.8462 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6399 - accuracy: 0.8462 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6396 - accuracy: 0.8611 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6375 - accuracy: 0.8611 - val_loss: 0.6496 - val_accuracy: 0.7778\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6459 - accuracy: 0.8205 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6441 - accuracy: 0.8205 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6499 - accuracy: 0.7949 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6483 - accuracy: 0.7949 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6308 - accuracy: 0.9167 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6283 - accuracy: 0.9167 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6265 - accuracy: 0.9444 - val_loss: 0.6329 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6238 - accuracy: 0.9444 - val_loss: 0.6306 - val_accuracy: 0.8889\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6177 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6147 - accuracy: 1.0000 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.6352 - accuracy: 0.8889 - val_loss: 0.6329 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6329 - accuracy: 0.8889 - val_loss: 0.6306 - val_accuracy: 0.8889\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6265 - accuracy: 0.9444 - val_loss: 0.6329 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6238 - accuracy: 0.9444 - val_loss: 0.6306 - val_accuracy: 0.8889\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6265 - accuracy: 0.9444 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6238 - accuracy: 0.9444 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6308 - accuracy: 0.9167 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6283 - accuracy: 0.9167 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.6419 - accuracy: 0.8462 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6399 - accuracy: 0.8462 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6352 - accuracy: 0.8889 - val_loss: 0.6692 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6329 - accuracy: 0.8889 - val_loss: 0.6684 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.6483 - accuracy: 0.8056 - val_loss: 0.6329 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6465 - accuracy: 0.8056 - val_loss: 0.6306 - val_accuracy: 0.8889\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6638 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6627 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6419 - accuracy: 0.8462 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6399 - accuracy: 0.8462 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6265 - accuracy: 0.9444 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6238 - accuracy: 0.9444 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6419 - accuracy: 0.8462 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6399 - accuracy: 0.8462 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6638 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6627 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6308 - accuracy: 0.9167 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6283 - accuracy: 0.9167 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6459 - accuracy: 0.8205 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6441 - accuracy: 0.8205 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6339 - accuracy: 0.8974 - val_loss: 0.6638 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6627 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6352 - accuracy: 0.8889 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6329 - accuracy: 0.8889 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6218 - accuracy: 0.9744 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6189 - accuracy: 0.9744 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.6258 - accuracy: 0.9487 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6231 - accuracy: 0.9487 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6265 - accuracy: 0.9444 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6238 - accuracy: 0.9444 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6177 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6147 - accuracy: 1.0000 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6395 - accuracy: 0.8611 - val_loss: 0.6329 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6374 - accuracy: 0.8611 - val_loss: 0.6306 - val_accuracy: 0.8889\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6419 - accuracy: 0.8462 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6399 - accuracy: 0.8462 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6379 - accuracy: 0.8718 - val_loss: 0.6475 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6357 - accuracy: 0.8718 - val_loss: 0.6458 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6298 - accuracy: 0.9231 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6273 - accuracy: 0.9231 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6265 - accuracy: 0.9444 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6238 - accuracy: 0.9444 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.6338 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6315 - accuracy: 0.8974 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6459 - accuracy: 0.8205 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6441 - accuracy: 0.8205 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6459 - accuracy: 0.8205 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6441 - accuracy: 0.8205 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6396 - accuracy: 0.8611 - val_loss: 0.6511 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6375 - accuracy: 0.8611 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6305 - accuracy: 0.9189 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6280 - accuracy: 0.9189 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6262 - accuracy: 0.9459 - val_loss: 0.6311 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6236 - accuracy: 0.9459 - val_loss: 0.6287 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6347 - accuracy: 0.8919 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6324 - accuracy: 0.8919 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6220 - accuracy: 0.9730 - val_loss: 0.6474 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6191 - accuracy: 0.9730 - val_loss: 0.6457 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6224 - accuracy: 0.9706 - val_loss: 0.6147 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6195 - accuracy: 0.9706 - val_loss: 0.6117 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=11\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6164 - accuracy: 0.9722 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6136 - accuracy: 0.9722 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6422 - accuracy: 0.8205 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6404 - accuracy: 0.8205 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6354 - accuracy: 0.8611 - val_loss: 0.6480 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6333 - accuracy: 0.8611 - val_loss: 0.6464 - val_accuracy: 0.7778\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6617 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6607 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6422 - accuracy: 0.8205 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6404 - accuracy: 0.8205 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6161 - accuracy: 0.9744 - val_loss: 0.6617 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6132 - accuracy: 0.9744 - val_loss: 0.6607 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.6212 - accuracy: 0.9444 - val_loss: 0.6676 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6185 - accuracy: 0.9444 - val_loss: 0.6668 - val_accuracy: 0.6667\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6259 - accuracy: 0.9167 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6234 - accuracy: 0.9167 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6353 - accuracy: 0.8611 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6332 - accuracy: 0.8611 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6259 - accuracy: 0.9167 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6234 - accuracy: 0.9167 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6161 - accuracy: 0.9744 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6132 - accuracy: 0.9744 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6164 - accuracy: 0.9722 - val_loss: 0.6283 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6136 - accuracy: 0.9722 - val_loss: 0.6261 - val_accuracy: 0.8889\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6306 - accuracy: 0.8889 - val_loss: 0.6283 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6283 - accuracy: 0.8889 - val_loss: 0.6261 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6241 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6422 - accuracy: 0.8205 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6404 - accuracy: 0.8205 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6401 - accuracy: 0.8333 - val_loss: 0.6283 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.6382 - accuracy: 0.8333 - val_loss: 0.6261 - val_accuracy: 0.8889\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6161 - accuracy: 0.9744 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6132 - accuracy: 0.9744 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6495 - accuracy: 0.7778 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6480 - accuracy: 0.7778 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6970 - val_accuracy: 0.5000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6973 - val_accuracy: 0.5000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6422 - accuracy: 0.8205 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6404 - accuracy: 0.8205 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6212 - accuracy: 0.9444 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6185 - accuracy: 0.9444 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6466 - accuracy: 0.7949 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6450 - accuracy: 0.7949 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6161 - accuracy: 0.9744 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6132 - accuracy: 0.9744 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6353 - accuracy: 0.8611 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6332 - accuracy: 0.8611 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6265 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6241 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6335 - accuracy: 0.8718 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6314 - accuracy: 0.8718 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6306 - accuracy: 0.8889 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6283 - accuracy: 0.8889 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6204 - accuracy: 0.9487 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6178 - accuracy: 0.9487 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6212 - accuracy: 0.9444 - val_loss: 0.6480 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6185 - accuracy: 0.9444 - val_loss: 0.6464 - val_accuracy: 0.7778\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6117 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6087 - accuracy: 1.0000 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.6401 - accuracy: 0.8333 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6382 - accuracy: 0.8333 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6422 - accuracy: 0.8205 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6404 - accuracy: 0.8205 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6379 - accuracy: 0.8462 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6359 - accuracy: 0.8462 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6306 - accuracy: 0.8889 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6283 - accuracy: 0.8889 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6248 - accuracy: 0.9231 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6223 - accuracy: 0.9231 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6291 - accuracy: 0.8974 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6292 - accuracy: 0.8974 - val_loss: 0.6617 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6268 - accuracy: 0.8974 - val_loss: 0.6607 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6510 - accuracy: 0.7692 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6495 - accuracy: 0.7692 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6354 - accuracy: 0.8611 - val_loss: 0.6480 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6333 - accuracy: 0.8611 - val_loss: 0.6464 - val_accuracy: 0.7778\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6163 - accuracy: 0.9730 - val_loss: 0.6440 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.6135 - accuracy: 0.9730 - val_loss: 0.6424 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6209 - accuracy: 0.9459 - val_loss: 0.6264 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6183 - accuracy: 0.9459 - val_loss: 0.6240 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6301 - accuracy: 0.8919 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6278 - accuracy: 0.8919 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6255 - accuracy: 0.9189 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6230 - accuracy: 0.9189 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6167 - accuracy: 0.9706 - val_loss: 0.6087 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6139 - accuracy: 0.9706 - val_loss: 0.6057 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=12\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6108 - accuracy: 0.9722 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6080 - accuracy: 0.9722 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6057 - accuracy: 1.0000 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6027 - accuracy: 1.0000 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6261 - accuracy: 0.8889 - val_loss: 0.6660 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6239 - accuracy: 0.8889 - val_loss: 0.6652 - val_accuracy: 0.6667\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6339 - accuracy: 0.8462 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6319 - accuracy: 0.8462 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6339 - accuracy: 0.8462 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6319 - accuracy: 0.8462 - val_loss: 0.6587 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6587 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6312 - accuracy: 0.8611 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6291 - accuracy: 0.8611 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6587 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6104 - accuracy: 0.9744 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6076 - accuracy: 0.9744 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6449 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6434 - val_accuracy: 0.7778\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6108 - accuracy: 0.9722 - val_loss: 0.6449 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6080 - accuracy: 0.9722 - val_loss: 0.6434 - val_accuracy: 0.7778\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6104 - accuracy: 0.9744 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6076 - accuracy: 0.9744 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6108 - accuracy: 0.9722 - val_loss: 0.6238 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6080 - accuracy: 0.9722 - val_loss: 0.6216 - val_accuracy: 0.8889\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.6339 - accuracy: 0.8462 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6319 - accuracy: 0.8462 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6104 - accuracy: 0.9744 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6076 - accuracy: 0.9744 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6261 - accuracy: 0.8889 - val_loss: 0.6238 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6238 - accuracy: 0.8889 - val_loss: 0.6216 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6339 - accuracy: 0.8462 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6319 - accuracy: 0.8462 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6433 - accuracy: 0.7949 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6417 - accuracy: 0.7949 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6238 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6344 - accuracy: 0.8333 - val_loss: 0.6216 - val_accuracy: 0.8889\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6104 - accuracy: 0.9744 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6076 - accuracy: 0.9744 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6449 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6344 - accuracy: 0.8333 - val_loss: 0.6434 - val_accuracy: 0.7778\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6386 - accuracy: 0.8205 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6368 - accuracy: 0.8205 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6587 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6159 - accuracy: 0.9444 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6133 - accuracy: 0.9444 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6587 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6312 - accuracy: 0.8611 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6291 - accuracy: 0.8611 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.6386 - accuracy: 0.8205 - val_loss: 0.6028 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6368 - accuracy: 0.8205 - val_loss: 0.5998 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6238 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6216 - val_accuracy: 0.8889\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6210 - accuracy: 0.9167 - val_loss: 0.6239 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6185 - accuracy: 0.9167 - val_loss: 0.6217 - val_accuracy: 0.8889\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6057 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6027 - accuracy: 1.0000 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6363 - accuracy: 0.8333 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6344 - accuracy: 0.8333 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6597 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.6587 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.6292 - accuracy: 0.8718 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6271 - accuracy: 0.8718 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6151 - accuracy: 0.9487 - val_loss: 0.6407 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.6125 - accuracy: 0.9487 - val_loss: 0.6390 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6159 - accuracy: 0.9444 - val_loss: 0.6449 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6133 - accuracy: 0.9444 - val_loss: 0.6434 - val_accuracy: 0.7778\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6245 - accuracy: 0.8974 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6222 - accuracy: 0.8974 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6198 - accuracy: 0.9231 - val_loss: 0.6217 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.6173 - accuracy: 0.9231 - val_loss: 0.6194 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6386 - accuracy: 0.8205 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6368 - accuracy: 0.8205 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.6480 - accuracy: 0.7692 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6466 - accuracy: 0.7692 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6414 - accuracy: 0.8056 - val_loss: 0.6028 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6396 - accuracy: 0.8056 - val_loss: 0.5998 - val_accuracy: 1.0000\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6206 - accuracy: 0.9189 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6181 - accuracy: 0.9189 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6206 - accuracy: 0.9189 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6181 - accuracy: 0.9189 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6255 - accuracy: 0.8919 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6233 - accuracy: 0.8919 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6206 - accuracy: 0.9189 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6181 - accuracy: 0.9189 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6111 - accuracy: 0.9706 - val_loss: 0.6027 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6083 - accuracy: 0.9706 - val_loss: 0.5997 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=13\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6052 - accuracy: 0.9722 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6024 - accuracy: 0.9722 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6300 - accuracy: 0.8462 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6280 - accuracy: 0.8462 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6048 - accuracy: 0.9744 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6019 - accuracy: 0.9744 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6270 - accuracy: 0.8611 - val_loss: 0.6419 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6250 - accuracy: 0.8611 - val_loss: 0.6404 - val_accuracy: 0.7778\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6300 - accuracy: 0.8462 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6280 - accuracy: 0.8462 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.6350 - accuracy: 0.8205 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6332 - accuracy: 0.8205 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6350 - accuracy: 0.8205 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6332 - accuracy: 0.8205 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.6048 - accuracy: 0.9744 - val_loss: 0.6577 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6019 - accuracy: 0.9744 - val_loss: 0.6567 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6161 - accuracy: 0.9167 - val_loss: 0.6419 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6137 - accuracy: 0.9167 - val_loss: 0.6404 - val_accuracy: 0.7778\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6149 - accuracy: 0.9231 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6161 - accuracy: 0.9167 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6137 - accuracy: 0.9167 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6106 - accuracy: 0.9444 - val_loss: 0.6644 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6080 - accuracy: 0.9444 - val_loss: 0.6637 - val_accuracy: 0.6667\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6106 - accuracy: 0.9444 - val_loss: 0.6193 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6080 - accuracy: 0.9444 - val_loss: 0.6171 - val_accuracy: 0.8889\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6048 - accuracy: 0.9744 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6019 - accuracy: 0.9744 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 985ms/step - loss: 0.6106 - accuracy: 0.9444 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6080 - accuracy: 0.9444 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6373 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6270 - accuracy: 0.8611 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.6249 - accuracy: 0.8611 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6071 - accuracy: 0.9487 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.6300 - accuracy: 0.8462 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6280 - accuracy: 0.8462 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6400 - accuracy: 0.7949 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6384 - accuracy: 0.7949 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6325 - accuracy: 0.8333 - val_loss: 0.6193 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6306 - accuracy: 0.8333 - val_loss: 0.6171 - val_accuracy: 0.8889\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.5997 - accuracy: 1.0000 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5967 - accuracy: 1.0000 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.6325 - accuracy: 0.8333 - val_loss: 0.6419 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6306 - accuracy: 0.8333 - val_loss: 0.6404 - val_accuracy: 0.7778\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6350 - accuracy: 0.8205 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6332 - accuracy: 0.8205 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6300 - accuracy: 0.8462 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6280 - accuracy: 0.8462 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6106 - accuracy: 0.9444 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6080 - accuracy: 0.9444 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6577 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6567 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6300 - accuracy: 0.8462 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6280 - accuracy: 0.8462 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6216 - accuracy: 0.8889 - val_loss: 0.6193 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6193 - accuracy: 0.8889 - val_loss: 0.6171 - val_accuracy: 0.8889\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6098 - accuracy: 0.9487 - val_loss: 0.6171 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6072 - accuracy: 0.9487 - val_loss: 0.6148 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.6577 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.6567 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.6216 - accuracy: 0.8889 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6193 - accuracy: 0.8889 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6048 - accuracy: 0.9744 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6019 - accuracy: 0.9744 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6161 - accuracy: 0.9167 - val_loss: 0.6194 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6137 - accuracy: 0.9167 - val_loss: 0.6171 - val_accuracy: 0.8889\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.5997 - accuracy: 1.0000 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5967 - accuracy: 1.0000 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6148 - accuracy: 0.9231 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6124 - accuracy: 0.9231 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6325 - accuracy: 0.8333 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6306 - accuracy: 0.8333 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6350 - accuracy: 0.8205 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6332 - accuracy: 0.8205 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6300 - accuracy: 0.8462 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6280 - accuracy: 0.8462 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6161 - accuracy: 0.9167 - val_loss: 0.6193 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6137 - accuracy: 0.9167 - val_loss: 0.6171 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6199 - accuracy: 0.8974 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6176 - accuracy: 0.8974 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6249 - accuracy: 0.8718 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6228 - accuracy: 0.8718 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6401 - accuracy: 0.7949 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6384 - accuracy: 0.7949 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6161 - accuracy: 0.9167 - val_loss: 0.6870 - val_accuracy: 0.5556\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6137 - accuracy: 0.9167 - val_loss: 0.6870 - val_accuracy: 0.5556\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6157 - accuracy: 0.9189 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6132 - accuracy: 0.9189 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.6104 - accuracy: 0.9459 - val_loss: 0.6170 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6077 - accuracy: 0.9459 - val_loss: 0.6147 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6210 - accuracy: 0.8919 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6187 - accuracy: 0.8919 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6050 - accuracy: 0.9730 - val_loss: 0.6374 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6022 - accuracy: 0.9730 - val_loss: 0.6357 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6055 - accuracy: 0.9706 - val_loss: 0.5967 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6027 - accuracy: 0.9706 - val_loss: 0.5937 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=14\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.5996 - accuracy: 0.9722 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5968 - accuracy: 0.9722 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6240 - accuracy: 0.8462 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6171 - accuracy: 0.8889 - val_loss: 0.6629 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6148 - accuracy: 0.8889 - val_loss: 0.6622 - val_accuracy: 0.6667\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6240 - accuracy: 0.8462 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6368 - accuracy: 0.7949 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6352 - accuracy: 0.7949 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6314 - accuracy: 0.8205 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6296 - accuracy: 0.8205 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6229 - accuracy: 0.8611 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6208 - accuracy: 0.8611 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5991 - accuracy: 0.9744 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5963 - accuracy: 0.9744 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.6125 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6112 - accuracy: 0.9167 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6088 - accuracy: 0.9167 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6100 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6171 - accuracy: 0.8889 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6148 - accuracy: 0.8889 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 991ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6100 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6054 - accuracy: 0.9444 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6028 - accuracy: 0.9444 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5996 - accuracy: 0.9722 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5968 - accuracy: 0.9722 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6314 - accuracy: 0.8205 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6296 - accuracy: 0.8205 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5937 - accuracy: 1.0000 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5907 - accuracy: 1.0000 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6240 - accuracy: 0.8462 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.6170 - accuracy: 0.8889 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6148 - accuracy: 0.8889 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.5991 - accuracy: 0.9744 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5963 - accuracy: 0.9744 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6368 - accuracy: 0.7949 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6352 - accuracy: 0.7949 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6171 - accuracy: 0.8889 - val_loss: 0.6629 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6148 - accuracy: 0.8889 - val_loss: 0.6622 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.5937 - accuracy: 1.0000 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5907 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6345 - accuracy: 0.8056 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6328 - accuracy: 0.8056 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.5996 - accuracy: 0.9722 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5968 - accuracy: 0.9722 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 995ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6557 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6547 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.5991 - accuracy: 0.9744 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5963 - accuracy: 0.9744 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.6314 - accuracy: 0.8205 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6296 - accuracy: 0.8205 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6054 - accuracy: 0.9444 - val_loss: 0.6629 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6028 - accuracy: 0.9444 - val_loss: 0.6622 - val_accuracy: 0.6667\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.6125 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6240 - accuracy: 0.8462 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6241 - accuracy: 0.8462 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6240 - accuracy: 0.8462 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6054 - accuracy: 0.9444 - val_loss: 0.6389 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6028 - accuracy: 0.9444 - val_loss: 0.6373 - val_accuracy: 0.7778\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6171 - accuracy: 0.8889 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6148 - accuracy: 0.8889 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.5937 - accuracy: 1.0000 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5907 - accuracy: 1.0000 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6287 - accuracy: 0.8333 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6268 - accuracy: 0.8333 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6206 - accuracy: 0.8718 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6185 - accuracy: 0.8718 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6240 - accuracy: 0.8462 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6260 - accuracy: 0.8462 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6241 - accuracy: 0.8462 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6171 - accuracy: 0.8889 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6148 - accuracy: 0.8889 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6099 - accuracy: 0.9231 - val_loss: 0.6124 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6074 - accuracy: 0.9231 - val_loss: 0.6101 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6045 - accuracy: 0.9487 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6018 - accuracy: 0.9487 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6153 - accuracy: 0.8974 - val_loss: 0.6557 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6129 - accuracy: 0.8974 - val_loss: 0.6547 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.6314 - accuracy: 0.8205 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6296 - accuracy: 0.8205 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6287 - accuracy: 0.8333 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6268 - accuracy: 0.8333 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6108 - accuracy: 0.9189 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6083 - accuracy: 0.9189 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 907ms/step - loss: 0.6108 - accuracy: 0.9189 - val_loss: 0.5907 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6083 - accuracy: 0.9189 - val_loss: 0.5877 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6051 - accuracy: 0.9459 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6024 - accuracy: 0.9459 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5994 - accuracy: 0.9730 - val_loss: 0.6340 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5966 - accuracy: 0.9730 - val_loss: 0.6324 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.5937 - accuracy: 1.0000 - val_loss: 0.6148 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5907 - accuracy: 1.0000 - val_loss: 0.6125 - val_accuracy: 0.8889\n",
            "Publisher: global iteration=15\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 999ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.5939 - accuracy: 0.9722 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5911 - accuracy: 0.9722 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6767 - val_accuracy: 0.6000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6765 - val_accuracy: 0.6000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.5877 - accuracy: 1.0000 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5847 - accuracy: 1.0000 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6250 - accuracy: 0.8333 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6231 - accuracy: 0.8333 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6335 - accuracy: 0.7949 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6319 - accuracy: 0.7949 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6278 - accuracy: 0.8205 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6260 - accuracy: 0.8205 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6187 - accuracy: 0.8611 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6167 - accuracy: 0.8611 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 982ms/step - loss: 0.6001 - accuracy: 0.9444 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5975 - accuracy: 0.9444 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.6221 - accuracy: 0.8462 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.6201 - accuracy: 0.8462 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6125 - accuracy: 0.8889 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6103 - accuracy: 0.8889 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6001 - accuracy: 0.9444 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5975 - accuracy: 0.9444 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.5935 - accuracy: 0.9744 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5906 - accuracy: 0.9744 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5939 - accuracy: 0.9722 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5911 - accuracy: 0.9722 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6278 - accuracy: 0.8205 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6260 - accuracy: 0.8205 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.5935 - accuracy: 0.9744 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5906 - accuracy: 0.9744 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6125 - accuracy: 0.8889 - val_loss: 0.6102 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6103 - accuracy: 0.8889 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6221 - accuracy: 0.8462 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6201 - accuracy: 0.8462 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.6537 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.6528 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6187 - accuracy: 0.8611 - val_loss: 0.6359 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6167 - accuracy: 0.8611 - val_loss: 0.6344 - val_accuracy: 0.7778\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.5935 - accuracy: 0.9744 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5906 - accuracy: 0.9744 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6311 - accuracy: 0.8056 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6295 - accuracy: 0.8056 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.6278 - accuracy: 0.8205 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6260 - accuracy: 0.8205 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6537 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6528 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.5877 - accuracy: 1.0000 - val_loss: 0.6359 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5847 - accuracy: 1.0000 - val_loss: 0.6344 - val_accuracy: 0.7778\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6278 - accuracy: 0.8205 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6260 - accuracy: 0.8205 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6221 - accuracy: 0.8462 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6201 - accuracy: 0.8462 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6187 - accuracy: 0.8611 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6167 - accuracy: 0.8611 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6537 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6528 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6001 - accuracy: 0.9444 - val_loss: 0.6359 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5975 - accuracy: 0.9444 - val_loss: 0.6344 - val_accuracy: 0.7778\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6064 - accuracy: 0.9167 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6039 - accuracy: 0.9167 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5992 - accuracy: 0.9487 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5965 - accuracy: 0.9487 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.5877 - accuracy: 1.0000 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5847 - accuracy: 1.0000 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6125 - accuracy: 0.8889 - val_loss: 0.6359 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6103 - accuracy: 0.8889 - val_loss: 0.6344 - val_accuracy: 0.7778\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6537 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6528 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6164 - accuracy: 0.8718 - val_loss: 0.6307 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.6142 - accuracy: 0.8718 - val_loss: 0.6291 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.6063 - accuracy: 0.9167 - val_loss: 0.6103 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6039 - accuracy: 0.9167 - val_loss: 0.6080 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6106 - accuracy: 0.8974 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6083 - accuracy: 0.8974 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6049 - accuracy: 0.9231 - val_loss: 0.6767 - val_accuracy: 0.6000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6024 - accuracy: 0.9231 - val_loss: 0.6765 - val_accuracy: 0.6000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6335 - accuracy: 0.7949 - val_loss: 0.6078 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6319 - accuracy: 0.7949 - val_loss: 0.6055 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 986ms/step - loss: 0.6188 - accuracy: 0.8611 - val_loss: 0.6359 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6167 - accuracy: 0.8611 - val_loss: 0.6344 - val_accuracy: 0.7778\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.5998 - accuracy: 0.9459 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5972 - accuracy: 0.9459 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5998 - accuracy: 0.9459 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5972 - accuracy: 0.9459 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.6119 - accuracy: 0.8919 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6096 - accuracy: 0.8919 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.5998 - accuracy: 0.9459 - val_loss: 0.6077 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5972 - accuracy: 0.9459 - val_loss: 0.6054 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.5943 - accuracy: 0.9706 - val_loss: 0.5847 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5915 - accuracy: 0.9706 - val_loss: 0.5817 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=16\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 998ms/step - loss: 0.5817 - accuracy: 1.0000 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5787 - accuracy: 1.0000 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6242 - accuracy: 0.8205 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6225 - accuracy: 0.8205 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.6081 - accuracy: 0.8889 - val_loss: 0.6600 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6058 - accuracy: 0.8889 - val_loss: 0.6592 - val_accuracy: 0.6667\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6762 - val_accuracy: 0.6000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6759 - val_accuracy: 0.6000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6242 - accuracy: 0.8205 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6225 - accuracy: 0.8205 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6080 - accuracy: 0.8889 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6058 - accuracy: 0.8889 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5949 - accuracy: 0.9444 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5923 - accuracy: 0.9444 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6099 - accuracy: 0.8718 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6146 - accuracy: 0.8611 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6126 - accuracy: 0.8611 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6099 - accuracy: 0.8718 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6015 - accuracy: 0.9167 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5990 - accuracy: 0.9167 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5883 - accuracy: 0.9722 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5855 - accuracy: 0.9722 - val_loss: 0.6035 - val_accuracy: 0.8889\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6518 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6509 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6146 - accuracy: 0.8611 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6126 - accuracy: 0.8611 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6278 - accuracy: 0.8056 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6261 - accuracy: 0.8056 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.5878 - accuracy: 0.9744 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5850 - accuracy: 0.9744 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6212 - accuracy: 0.8333 - val_loss: 0.6329 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6193 - accuracy: 0.8333 - val_loss: 0.6314 - val_accuracy: 0.7778\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 994ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5883 - accuracy: 0.9722 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5855 - accuracy: 0.9722 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6518 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6509 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6007 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.5878 - accuracy: 0.9744 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5850 - accuracy: 0.9744 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.6080 - accuracy: 0.8889 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6058 - accuracy: 0.8889 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6015 - accuracy: 0.9167 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5990 - accuracy: 0.9167 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.6081 - accuracy: 0.8889 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6058 - accuracy: 0.8889 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.5817 - accuracy: 1.0000 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5787 - accuracy: 1.0000 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.5939 - accuracy: 0.9487 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5912 - accuracy: 0.9487 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6146 - accuracy: 0.8611 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6126 - accuracy: 0.8611 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6182 - accuracy: 0.8462 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6162 - accuracy: 0.8462 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 989ms/step - loss: 0.6015 - accuracy: 0.9167 - val_loss: 0.6058 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5990 - accuracy: 0.9167 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.5999 - accuracy: 0.9231 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5975 - accuracy: 0.9231 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.6060 - accuracy: 0.8974 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6037 - accuracy: 0.8974 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6121 - accuracy: 0.8718 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.6100 - accuracy: 0.8718 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6242 - accuracy: 0.8205 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6225 - accuracy: 0.8205 - val_loss: 0.6259 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6212 - accuracy: 0.8333 - val_loss: 0.6059 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6193 - accuracy: 0.8333 - val_loss: 0.6036 - val_accuracy: 0.8889\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.5945 - accuracy: 0.9459 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5919 - accuracy: 0.9459 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5945 - accuracy: 0.9459 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5919 - accuracy: 0.9459 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.5945 - accuracy: 0.9459 - val_loss: 0.6275 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5919 - accuracy: 0.9459 - val_loss: 0.6258 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.5945 - accuracy: 0.9459 - val_loss: 0.6031 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5919 - accuracy: 0.9459 - val_loss: 0.6008 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.5887 - accuracy: 0.9706 - val_loss: 0.5787 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5859 - accuracy: 0.9706 - val_loss: 0.5757 - val_accuracy: 1.0000\n",
            "Publisher: global iteration=17\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5827 - accuracy: 0.9722 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5799 - accuracy: 0.9722 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6207 - accuracy: 0.8205 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6189 - accuracy: 0.8205 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6105 - accuracy: 0.8611 - val_loss: 0.6299 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6085 - accuracy: 0.8611 - val_loss: 0.6284 - val_accuracy: 0.7778\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.6499 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.6490 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.6271 - accuracy: 0.7949 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6255 - accuracy: 0.7949 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6036 - accuracy: 0.8889 - val_loss: 0.6013 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6013 - accuracy: 0.8889 - val_loss: 0.5991 - val_accuracy: 0.8889\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 997ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.5966 - accuracy: 0.9167 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5942 - accuracy: 0.9167 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 940ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.5821 - accuracy: 0.9744 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5793 - accuracy: 0.9744 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5885 - accuracy: 0.9487 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.6105 - accuracy: 0.8611 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6085 - accuracy: 0.8611 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.5966 - accuracy: 0.9167 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5942 - accuracy: 0.9167 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.5757 - accuracy: 1.0000 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5727 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.5821 - accuracy: 0.9744 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5793 - accuracy: 0.9744 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 996ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5896 - accuracy: 0.9444 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.5870 - accuracy: 0.9444 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.6105 - accuracy: 0.8611 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.6084 - accuracy: 0.8611 - val_loss: 0.5696 - val_accuracy: 1.0000\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.6207 - accuracy: 0.8205 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6189 - accuracy: 0.8205 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 979ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6036 - accuracy: 0.8889 - val_loss: 0.6585 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6013 - accuracy: 0.8889 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.5757 - accuracy: 1.0000 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5727 - accuracy: 1.0000 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 917ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6105 - accuracy: 0.8611 - val_loss: 0.6585 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6085 - accuracy: 0.8611 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.6499 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.6490 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5896 - accuracy: 0.9444 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5870 - accuracy: 0.9444 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.6499 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.6490 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5966 - accuracy: 0.9167 - val_loss: 0.6299 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5942 - accuracy: 0.9167 - val_loss: 0.6284 - val_accuracy: 0.7778\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 992ms/step - loss: 0.6078 - accuracy: 0.8718 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6057 - accuracy: 0.8718 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.6242 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.6226 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6036 - accuracy: 0.8889 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.6013 - accuracy: 0.8889 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.5886 - accuracy: 0.9487 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5859 - accuracy: 0.9487 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.6036 - accuracy: 0.8889 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.6013 - accuracy: 0.8889 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.5757 - accuracy: 1.0000 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5727 - accuracy: 1.0000 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.5966 - accuracy: 0.9167 - val_loss: 0.6585 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5942 - accuracy: 0.9167 - val_loss: 0.6578 - val_accuracy: 0.6667\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6036 - accuracy: 0.8889 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6013 - accuracy: 0.8889 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5950 - accuracy: 0.9231 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5925 - accuracy: 0.9231 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.6014 - accuracy: 0.8974 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5991 - accuracy: 0.8974 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6143 - accuracy: 0.8462 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6123 - accuracy: 0.8462 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6271 - accuracy: 0.7949 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6255 - accuracy: 0.7949 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5896 - accuracy: 0.9444 - val_loss: 0.7157 - val_accuracy: 0.4444\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5870 - accuracy: 0.9444 - val_loss: 0.7165 - val_accuracy: 0.4444\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.5893 - accuracy: 0.9459 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5866 - accuracy: 0.9459 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.5893 - accuracy: 0.9459 - val_loss: 0.5984 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5866 - accuracy: 0.9459 - val_loss: 0.5961 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6028 - accuracy: 0.8919 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6005 - accuracy: 0.8919 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5960 - accuracy: 0.9189 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5936 - accuracy: 0.9189 - val_loss: 0.5697 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.5757 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5727 - accuracy: 1.0000 - val_loss: 0.5991 - val_accuracy: 0.8889\n",
            "Publisher: global iteration=18\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5914 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5770 - accuracy: 0.9722 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5742 - accuracy: 0.9722 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.6064 - accuracy: 0.8611 - val_loss: 0.6270 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6044 - accuracy: 0.8611 - val_loss: 0.6255 - val_accuracy: 0.7778\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.6752 - val_accuracy: 0.6000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.6239 - accuracy: 0.7949 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6223 - accuracy: 0.7949 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.5991 - accuracy: 0.8889 - val_loss: 0.5968 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5968 - accuracy: 0.8889 - val_loss: 0.5946 - val_accuracy: 0.8889\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.5917 - accuracy: 0.9167 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5893 - accuracy: 0.9167 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.6481 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.6471 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 973ms/step - loss: 0.5765 - accuracy: 0.9744 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5736 - accuracy: 0.9744 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5914 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5917 - accuracy: 0.9167 - val_loss: 0.6270 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5893 - accuracy: 0.9167 - val_loss: 0.6255 - val_accuracy: 0.7778\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 957ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 908ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.5917 - accuracy: 0.9167 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5893 - accuracy: 0.9167 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.5765 - accuracy: 0.9744 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5736 - accuracy: 0.9744 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 950ms/step - loss: 0.5844 - accuracy: 0.9444 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.5818 - accuracy: 0.9444 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 913ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6014 - accuracy: 0.8718 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 920ms/step - loss: 0.5991 - accuracy: 0.8889 - val_loss: 0.5968 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5968 - accuracy: 0.8889 - val_loss: 0.5945 - val_accuracy: 0.8889\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.5832 - accuracy: 0.9487 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.6481 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.6471 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.6064 - accuracy: 0.8611 - val_loss: 0.6270 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6044 - accuracy: 0.8611 - val_loss: 0.6255 - val_accuracy: 0.7778\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.5765 - accuracy: 0.9744 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5736 - accuracy: 0.9744 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6211 - accuracy: 0.8056 - val_loss: 0.5968 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6194 - accuracy: 0.8056 - val_loss: 0.5946 - val_accuracy: 0.8889\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 971ms/step - loss: 0.5832 - accuracy: 0.9487 - val_loss: 0.6481 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.6471 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 968ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 974ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.5770 - accuracy: 0.9722 - val_loss: 0.5968 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.5742 - accuracy: 0.9722 - val_loss: 0.5946 - val_accuracy: 0.8889\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 987ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.5917 - accuracy: 0.9167 - val_loss: 0.6270 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5893 - accuracy: 0.9167 - val_loss: 0.6255 - val_accuracy: 0.7778\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 975ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 963ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.6481 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.6471 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.5991 - accuracy: 0.8889 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5968 - accuracy: 0.8889 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5914 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 921ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 918ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.5991 - accuracy: 0.8889 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5968 - accuracy: 0.8889 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5833 - accuracy: 0.9487 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5806 - accuracy: 0.9487 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5697 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.5667 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 928ms/step - loss: 0.6137 - accuracy: 0.8333 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.6119 - accuracy: 0.8333 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6171 - accuracy: 0.8205 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6154 - accuracy: 0.8205 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5968 - accuracy: 0.8974 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5945 - accuracy: 0.8974 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.6104 - accuracy: 0.8462 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6084 - accuracy: 0.8462 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5917 - accuracy: 0.9167 - val_loss: 0.5968 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5893 - accuracy: 0.9167 - val_loss: 0.5946 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5876 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 943ms/step - loss: 0.5900 - accuracy: 0.9231 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5875 - accuracy: 0.9231 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.6209 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.6193 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 977ms/step - loss: 0.6036 - accuracy: 0.8718 - val_loss: 0.6752 - val_accuracy: 0.6000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6015 - accuracy: 0.8718 - val_loss: 0.6750 - val_accuracy: 0.6000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6211 - accuracy: 0.8056 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6194 - accuracy: 0.8056 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.5911 - accuracy: 0.9189 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5887 - accuracy: 0.9189 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5911 - accuracy: 0.9189 - val_loss: 0.5667 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5887 - accuracy: 0.9189 - val_loss: 0.5637 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 941ms/step - loss: 0.5911 - accuracy: 0.9189 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5887 - accuracy: 0.9189 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 981ms/step - loss: 0.5840 - accuracy: 0.9459 - val_loss: 0.5938 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.5813 - accuracy: 0.9459 - val_loss: 0.5915 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5697 - accuracy: 1.0000 - val_loss: 0.5968 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5667 - accuracy: 1.0000 - val_loss: 0.5946 - val_accuracy: 0.8889\n",
            "Publisher: global iteration=19\n",
            "Publisher: master=0\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 926ms/step - loss: 0.5714 - accuracy: 0.9722 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5686 - accuracy: 0.9722 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: master=1\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 930ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 969ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.5946 - accuracy: 0.8889 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5924 - accuracy: 0.8889 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Publisher: master=2\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.6462 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.6453 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 948ms/step - loss: 0.6207 - accuracy: 0.7949 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.6192 - accuracy: 0.7949 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 934ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.5946 - accuracy: 0.8889 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5924 - accuracy: 0.8889 - val_loss: 0.5901 - val_accuracy: 0.8889\n",
            "Publisher: master=3\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 990ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5891 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5868 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5869 - accuracy: 0.9167 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5844 - accuracy: 0.9167 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: master=4\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 965ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 959ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6023 - accuracy: 0.8611 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6003 - accuracy: 0.8611 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: master=5\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 980ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 983ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5891 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5868 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 0.5791 - accuracy: 0.9444 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5765 - accuracy: 0.9444 - val_loss: 0.5901 - val_accuracy: 0.8889\n",
            "Publisher: master=6\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 925ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.5791 - accuracy: 0.9444 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5765 - accuracy: 0.9444 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: master=7\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 933ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 993ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 923ms/step - loss: 0.5868 - accuracy: 0.9167 - val_loss: 0.6240 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5844 - accuracy: 0.9167 - val_loss: 0.6226 - val_accuracy: 0.7778\n",
            "Publisher: master=8\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5606 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 955ms/step - loss: 0.5946 - accuracy: 0.8889 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5924 - accuracy: 0.8889 - val_loss: 0.6551 - val_accuracy: 0.6667\n",
            "Publisher: master=9\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 970ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.5708 - accuracy: 0.9744 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5680 - accuracy: 0.9744 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 978ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.6100 - accuracy: 0.8333 - val_loss: 0.6240 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6082 - accuracy: 0.8333 - val_loss: 0.6226 - val_accuracy: 0.7778\n",
            "Publisher: master=10\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 944ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 966ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.5791 - accuracy: 0.9444 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5765 - accuracy: 0.9444 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: master=11\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 967ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 972ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 945ms/step - loss: 0.6023 - accuracy: 0.8611 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6003 - accuracy: 0.8611 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: master=12\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 927ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 939ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.6462 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.6453 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 960ms/step - loss: 0.5869 - accuracy: 0.9167 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.5844 - accuracy: 0.9167 - val_loss: 0.5901 - val_accuracy: 0.8889\n",
            "Publisher: master=13\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5891 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5868 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 951ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5791 - accuracy: 0.9444 - val_loss: 0.6240 - val_accuracy: 0.7778\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5765 - accuracy: 0.9444 - val_loss: 0.6226 - val_accuracy: 0.7778\n",
            "Publisher: master=14\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5637 - accuracy: 1.0000 - val_loss: 0.5606 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.5607 - accuracy: 1.0000 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 984ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 946ms/step - loss: 0.6023 - accuracy: 0.8611 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.6003 - accuracy: 0.8611 - val_loss: 0.5901 - val_accuracy: 0.8889\n",
            "Publisher: master=15\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 988ms/step - loss: 0.6136 - accuracy: 0.8205 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.6119 - accuracy: 0.8205 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 952ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 929ms/step - loss: 0.5851 - accuracy: 0.9231 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5826 - accuracy: 0.9231 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5869 - accuracy: 0.9167 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.5844 - accuracy: 0.9167 - val_loss: 0.5901 - val_accuracy: 0.8889\n",
            "Publisher: master=16\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5779 - accuracy: 0.9487 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.5753 - accuracy: 0.9487 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 961ms/step - loss: 0.5922 - accuracy: 0.8974 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5899 - accuracy: 0.8974 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.5993 - accuracy: 0.8718 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5972 - accuracy: 0.8718 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.6065 - accuracy: 0.8462 - val_loss: 0.6462 - val_accuracy: 0.7000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.6045 - accuracy: 0.8462 - val_loss: 0.6453 - val_accuracy: 0.7000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 958ms/step - loss: 0.6100 - accuracy: 0.8333 - val_loss: 0.5924 - val_accuracy: 0.8889\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.6082 - accuracy: 0.8333 - val_loss: 0.5902 - val_accuracy: 0.8889\n",
            "Publisher: master=17\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 938ms/step - loss: 0.5712 - accuracy: 0.9730 - val_loss: 0.6177 - val_accuracy: 0.8000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.5684 - accuracy: 0.9730 - val_loss: 0.6161 - val_accuracy: 0.8000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 915ms/step - loss: 0.5862 - accuracy: 0.9189 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.5838 - accuracy: 0.9189 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 949ms/step - loss: 0.5938 - accuracy: 0.8919 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.5915 - accuracy: 0.8919 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.5787 - accuracy: 0.9459 - val_loss: 0.5892 - val_accuracy: 0.9000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.5761 - accuracy: 0.9459 - val_loss: 0.5869 - val_accuracy: 0.9000\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 0.5719 - accuracy: 0.9706 - val_loss: 0.5607 - val_accuracy: 1.0000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.5690 - accuracy: 0.9706 - val_loss: 0.5576 - val_accuracy: 1.0000\n",
            "Publisher: finished all global\n",
            "Accuracy on Val Data:  [0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131, 0.9131]\n"
          ]
        }
      ],
      "source": [
        "acc_pdfl_fraud = pair_wise_xp(np.copy(x_fraud), np.copy(y_fraud), get_fraud_model(), [2, 3, 4, 6, 9, 12, 18], 36, 20, 2, deep_copy_fraud_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "1Se5vFExCXmK",
        "outputId": "0b2d5ec1-9a2b-47d1-fc33-455c8bac1aef"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-cc8b414acfaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpair_wise_post_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_pdfl_fraud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'acc_pdfl_fraud' is not defined"
          ]
        }
      ],
      "source": [
        "pair_wise_post_process(acc_pdfl_fraud, [2, 3, 4, 6, 9, 12, 18], 36, 40, [0.90, 0.85])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "AIC_FL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}